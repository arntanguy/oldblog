{"pages":[{"url":"http://arntanguy.github.io/blog/pages/links.html","text":"Plenty of really good cheat sheets http://www.cheat-sheets.org/ C++ C++ 11 - Features every C++ Developper Should Know Network Set up a virtual wifi access point","tags":"pages","title":"Links"},{"url":"http://arntanguy.github.io/blog/dealing-with-optimus-and-prime-issues-tearing-screen-refresh.html","text":"This is a summary of my solutions to my own issues. disqus_identifier: geenux-nvidia-prime My work has me dealing with GPU computing and OpenGL rendering on a regular basis, and most program I use daily require intensive GPU usage. Unfortunately for me, my laptop is blessed with an Optimus setup, of the worst kind, it is entirely muxless. That means that all display ports (VGA, HDMI, and internal screen) are physically wired to the Intel integrated chipset. My NVIDIA GTX 660M itself isn't wired directly to the outputs. This means that anything computed by the NVIDIA card will have to be shared with the Intel chipset for on-screen rendering. There are two common ways for doing so: bumblebee : In that case, applications are manually lanched on the NVIDIA GPU using primusrun, and the specific application buffer is then copied to the intel GPU. NVIDIA prime is a more recent attempt at solving the issue. With prime in use, everything is rendered on the NVIDIA GPU. The first solution is meant to save battery power, using the NVIDIA GPU \"on-demand\" when manually requested. This is not a practical solution for my use case, and as such, I'm stuck with NVIDIA prime solution. Here is a summary of the issues I encountered Everything is fine using the internal laptop screen only Using external screen, whether over VGA and HDMI output causes extreme tearin. Additionaly, usually either one of the screens would not be globally refreshed, leading to refresh issues with multiple trailing pointers, or in extreme cases only parts of the screen where the mouse had moved would be refreshed! Sadly I could not find any solution for the tearing. According to this NVIDIA devtalk thread, it seems that there is no synchronisation between NVIDIA and Intel as of yet, though work is under way and merely waiting to be merged. There is hope yet, keep on following this thread to see where it goes. I did find a solution for the multi-screen refresh issues. This Archlinux Reddit thread proposed replacing the bloated DDX driver from intel (x86-video-intel), with its opensource counterpart modesetting (xf86-video-modesetting). This did the trick for me, here are the steps I took to do just that: Remove the intel driver ::bash sudo apt-get remove xserver-xorg-video-intel Install modesetting ::bash sudo apt-get install xserver-xorg-video-modesetting After reboot, modesetting ought to be in use. If not, you may add it to your xorg.conf (this should not be necessary) Section \"ServerLayout\" Identifier \"layout\" Screen 0 \"nvidia\" Inactive \"intel\" EndSection Section \"Device\" Identifier \"intel\" Driver \"intel\" BusID \"PCI:0@0:2:0\" Option \"AccelMethod\" \"SNA\" Driver \"modesetting\" EndSection Section \"Screen\" Identifier \"intel\" Device \"intel\" EndSection Section \"Device\" Identifier \"nvidia\" Driver \"nvidia\" BusID \"PCI:1@0:0:0\" Option \"ConstrainCursor\" \"off\" EndSection Section \"Screen\" Identifier \"nvidia\" Device \"nvidia\" Option \"AllowEmptyInitialConfiguration\" \"on\" Option \"IgnoreDisplayDevices\" \"CRT\" EndSection To lessen the tearing issues, I also switched my window manager to compton, with the following configuration: ################################# # # Backend # ################################# # Backend to use : \"xrender\" or \"glx\" . # GLX backend is typically much faster but depends on a sane driver . backend = \"glx\" ; ################################# # # GLX backend # ################################# glx-no-stencil = true ; # GLX backend : Copy unmodified regions from front buffer instead of redrawing them all . # My tests with nvidia-drivers show a 10 % decrease in performance when the whole screen is modified , # but a 20 % increase when only 1 / 4 is . # My tests on nouveau show terrible slowdown . # Useful with --glx-swap-method , as well . glx-copy-from-front = false ; # GLX backend : Use MESA_copy_sub_buffer to do partial screen update . # My tests on nouveau shows a 200 % performance boost when only 1 / 4 of the screen is updated . # May break VSync and is not available on some drivers . # Overrides --glx-copy-from-front . # glx-use-copysubbuffermesa = true ; # GLX backend : Avoid rebinding pixmap on window damage . # Probably could improve performance on rapid window content changes , but is known to break things on some drivers ( LLVMpipe ). # Recommended if it works . # glx-no-rebind-pixmap = true ; # GLX backend : GLX buffer swap method we assume . # Could be undefined ( 0 ), copy ( 1 ), exchange ( 2 ), 3-6 , or buffer-age ( -1 ). # undefined is the slowest and the safest , and the default value . # copy is fastest , but may fail on some drivers , # 2-6 are gradually slower but safer ( 6 is still faster than 0 ). # Usually , double buffer means 2 , triple buffer means 3 . # buffer-age means auto-detect using GLX_EXT_buffer_age , supported by some drivers . # Useless with --glx-use-copysubbuffermesa . # Partially breaks --resize-damage . # Defaults to undefined . glx-swap-method = \"undefined\" ; ################################# # # Shadows # ################################# # Enabled client-side shadows on windows . shadow = true ; # Don 't draw shadows on DND windows. no-dnd-shadow = true; # Avoid drawing shadows on dock/panel windows. no-dock-shadow = true; # Zero the part of the shadow' s mask behind the window . Fix some weirdness with ARGB windows . clear-shadow = true ; # The blur radius for shadows . ( default 12 ) shadow-radius = 5 ; # The left offset for shadows . ( default -15 ) shadow-offset-x = -5 ; # The top offset for shadows . ( default -15 ) shadow-offset-y = -5 ; # The translucency for shadows . ( default .75 ) shadow-opacity = 0 .5 ; # Set if you want different colour shadows # shadow-red = 0 .0 ; # shadow-green = 0 .0 ; # shadow-blue = 0 .0 ; # The shadow exclude options are helpful if you have shadows enabled . Due to the way compton draws its shadows , certain applications will have visual glitches # ( most applications are fine , only apps that do weird things with xshapes or argb are affected ). # This list includes all the affected apps I found in my testing . The \"! name~=''\" part excludes shadows on any \"Unknown\" windows , this prevents a visual glitch with the XFWM alt tab switcher . shadow-exclude = [ \"! name~=''\" , \"name = 'Notification'\" , \"name = 'Plank'\" , \"name = 'Docky'\" , \"name = 'Kupfer'\" , \"name = 'xfce4-notifyd'\" , \"name *= 'VLC'\" , \"name *= 'compton'\" , \"name *= 'Chromium'\" , \"name *= 'Chrome'\" , \"name *= 'Firefox'\" , \"class_g = 'Conky'\" , \"class_g = 'Kupfer'\" , \"class_g = 'Synapse'\" , \"class_g ?= 'Notify-osd'\" , \"class_g ?= 'Cairo-dock'\" , \"class_g ?= 'Xfce4-notifyd'\" , \"class_g ?= 'Xfce4-power-manager'\" ] ; # Avoid drawing shadow on all shaped windows ( see also : --detect-rounded-corners ) shadow-ignore-shaped = false ; ################################# # # Opacity # ################################# menu-opacity = 1 ; inactive-opacity = 1 ; active-opacity = 1 ; frame-opacity = 1 ; inactive-opacity-override = false ; alpha-step = 0 .06 ; # Dim inactive windows . ( 0 .0 - 1 .0 ) # inactive-dim = 0 .2 ; # Do not let dimness adjust based on window opacity . # inactive-dim-fixed = true ; # Blur background of transparent windows . Bad performance with X Render backend . GLX backend is preferred . # blur-background = true ; # Blur background of opaque windows with transparent frames as well . # blur-background-frame = true ; # Do not let blur radius adjust based on window opacity . blur-background-fixed = false ; blur-background-exclude = [ \"window_type = 'dock'\" , \"window_type = 'desktop'\" ] ; ################################# # # Fading # ################################# # Fade windows during opacity changes . fading = true ; # The time between steps in a fade in milliseconds . ( default 10 ). fade-delta = 4 ; # Opacity change between steps while fading in . ( default 0 .028 ). fade-in-step = 0 .03 ; # Opacity change between steps while fading out . ( default 0 .03 ). fade-out-step = 0 .03 ; # Fade windows in / out when opening / closing # no-fading-openclose = true ; # Specify a list of conditions of windows that should not be faded . fade-exclude = [ ] ; ################################# # # Other # ################################# # Try to detect WM windows and mark them as active . mark-wmwin-focused = true ; # Mark all non-WM but override-redirect windows active ( e .g . menus ). mark-ovredir-focused = true ; # Use EWMH _NET_WM_ACTIVE_WINDOW to determine which window is focused instead of using FocusIn / Out events . # Usually more reliable but depends on a EWMH-compliant WM . use-ewmh-active-win = true ; # Detect rounded corners and treat them as rectangular when --shadow-ignore-shaped is on . detect-rounded-corners = true ; # Detect _NET_WM_OPACITY on client windows , useful for window managers not passing _NET_WM_OPACITY of client windows to frame windows . # This prevents opacity being ignored for some apps . # For example without this enabled my xfce4-notifyd is 100 % opacity no matter what . detect-client-opacity = true ; # Specify refresh rate of the screen . # If not specified or 0 , compton will try detecting this with X RandR extension . refresh-rate = 0 ; # Set VSync method . VSync methods currently available : # none : No VSync # drm : VSync with DRM_IOCTL_WAIT_VBLANK . May only work on some drivers . # opengl : Try to VSync with SGI_video_sync OpenGL extension . Only work on some drivers . # opengl-oml : Try to VSync with OML_sync_control OpenGL extension . Only work on some drivers . # opengl-swc : Try to VSync with SGI_swap_control OpenGL extension . Only work on some drivers . Works only with GLX backend . Known to be most effective on many drivers . Does not actually control paint timing , only buffer swap is affected , so it doesn ' t have the effect of --sw-opti unlike other methods . Experimental . # opengl-mswc : Try to VSync with MESA_swap_control OpenGL extension . Basically the same as opengl-swc above , except the extension we use . # ( Note some VSync methods may not be enabled at compile time .) vsync = \"opengl-swc\" ; # Enable DBE painting mode , intended to use with VSync to ( hopefully ) eliminate tearing . # Reported to have no effect , though . dbe = false ; # Painting on X Composite overlay window . Recommended . paint-on-overlay = true ; # Limit compton to repaint at most once every 1 / refresh_rate second to boost performance . # This should not be used with --vsync drm / opengl / opengl-oml as they essentially does --sw-opti ' s job already , # unless you wish to specify a lower refresh rate than the actual value . sw-opti = false ; # Unredirect all windows if a full-screen opaque window is detected , to maximize performance for full-screen windows , like games . # Known to cause flickering when redirecting / unredirecting windows . # paint-on-overlay may make the flickering less obvious . unredir-if-possible = true ; # Specify a list of conditions of windows that should always be considered focused . focus-exclude = [ ] ; # Use WM_TRANSIENT_FOR to group windows , and consider windows in the same group focused at the same time . detect-transient = true ; # Use WM_CLIENT_LEADER to group windows , and consider windows in the same group focused at the same time . # WM_TRANSIENT_FOR has higher priority if --detect-transient is enabled , too . detect-client-leader = true ; ################################# # # Window type settings # ################################# wintypes : { tooltip = { # fade : Fade the particular type of windows . fade = true ; # shadow : Give those windows shadow shadow = false ; # opacity : Default opacity for the type of windows . opacity = 0 . 85 ; # focus : Whether to always consider windows of this type focused . focus = true ; } ; } ; In summary my full setup is the following: Ubuntu 14.04 nvidia-364 driver xserver-xorg-video-modesetting (instead of intel's one) compton window manager With that, I only experience minimal tearing, and no screen refresh issues.","tags":"Linux","title":"Dealing with Optimus and PRIME issues (tearing, screen refresh...)"},{"url":"http://arntanguy.github.io/blog/multi-layered-perceptron-using-opencl.html","text":"I recently discovered neural networks , and I was instantly very interested by the topic. I am a big fan of computer vision, and have always had a feeling that this field was doomed by the sheer amount of possible combinations possible. How could we ever come up with an algorithm that wouldn't crash at the first unexpected input? How can we analyse complex behaviour, such as distinguishing distress in a metro when so much trivial noise and movements are going on? How could we ever get robots intelligent enough to cope with their environment as well, or even better than we do? I believe I'm starting to see a glimmer of hope in neural networks, that we could one day achieve such things, that at the moment seem like a daunting task. Of course a perceptron is way too simple a network for such things, but one has to start somewhere, hasn't he? I am convinced that it is utterly useless to read thousands of pages on neural networks to try and understand their behaviour. The best way to approach them is by trial and error. In this article, I will show you what a perceptron is, how to implement and train it using GPU computing with OpenCL . What is a perceptron A perceptron is basically a binary classifier: it will either tell you that the input values you provided match with the model it that has previously been learnt, or tell you that they don't. That is for a single output neuron. By providing several outputs, it is possible to use the perceptron as a classifier, effectively separating the input set in several classes. So basically, it is a linear classifier . You're probably wondering what you have to gain using a perceptron instead of SVM (Support Vector Machine), or similar algorithm. Well, actually not much. The perceptron was discovered before SVM was developped, and since then, SVM has pretty much replaced all uses of the perceptron. Even though, the perceptron can be seen as the very basis of neural networks, and is a stepping stone on which one has to walk on in order to fully understand the concepts behind neural network algorithms. As all neural networks, it requires a great amount of inter-connected neurons to provide enough capacity to learn a given model. It is thus a challenge to use a perceptron to accomplish complicated classification in real-time. Also, the training task can be a daunting computation, that might have to be ran loads of time before fine-tuning the training to achieve the expected outcome. A fully-connected perceptron is probably the simplest neural network you could ever think of. It is composed of several layers, each containing a given number of neurons. Each neuron of a layer is connected to every single neuron of the following layer. Each connection has an associated weight. It is by adjusting these weights that the network will tune himself to any linear classification problem, of course given that the network has enough complexity for the given problem (i.e has a sufficient number of neurons and layers for it to be able to learn the model). There are three types of layers: The input layer : it is the first layer, where you set the initial data that your perceptron will be working on. The hidden layers : these are all the layers between the input and output layer. They're basically the ones that will be doing all the work of learning a model and computing input values against the model in order to classify them. The output layer : composed of one or several neurons. This layer represents the result of the classification, where each neuron represent a specific class. Each neuron value in the hidden layers and the output layer is computed as the weighted sum of all the neurons' values linked to it by the weights linking them together. Hopefully, neural networks are generally highly parallel algorithm , and the perceptron is probably their king. In this article, I will present how to implement a fully-connected perceptron using OpenCL . This article will explain in detail the training algorithm, along with its naive implementation. A later article will discuss a faster training algorithm, and optimizations to the kernel presented here. Training algorithm : gradient backpropagation Training a perceptron is a minimization problem. We define a training set as a set of (input -> output) values. The goal of the training is to find the weights that minimize the distance between the output computed by the perceptron on the output corresponding to the same input in the training set. In this article we'll train a perceptron that is able to recognise a xor operation. First of all, here is the xor truth table: a b xor(a,b) 0 0 0 0 1 1 1 0 1 1 1 0 So the goal of the training will be to find the weights needed for the perceptron to give the correct output for all possible inputs a and b of the truth table. In order to train the weights, we will use an algorithm based on a gradient descent. First, let us define some notations: \\(n\\) : number of cells in layer, designed by an index \\(i\\) with \\(0 <= i <= n\\) \\(q\\) : number of layers \\(k\\) : index of an output cell \\(c_k\\) : expected output for output cell k for entry x \\(o_k\\) : computed output for output cell k for entry x \\(x_{ij}\\) : input value associated with link between cell i towards cell j \\(w_{ij}\\) : weight Succ(i) : set of cells that have the output of cell i as an input Pred(i) : set of cells whose output is an input of cell i \\(y_i\\) : weighted sum of cell i $$y_i = \\sum{w_{ij}x_{ij}}$$ \\(o_i\\) : output of cell i $$o_i = \\sigma(y_i)$$ where \\(\\sigma\\) is the sigmoid function: $$\\sigma(x) = \\frac{1}{1+e&#94;{-x}}$$ \\(S\\) : Learning set Before getting deeper into the algorithm, let's just give an overview of what we'll have to do. First, we need to compute the value of every single neuron from the input to the output layer. Once we have that, we can compare the output with the expected output, and compute the gradient \\(\\delta\\) for the output layer. Then, we compute \\(\\delta\\) for every layer based on the value of the following layer. This is a process called backpropagation. Finally we update the weight values using the neuron's and \\(\\delta\\) values previously computed. The algorithm goes as follow : Randomly initialize all weights in interval \\([-0.5, 0.5]\\) Repeat until convergence Pick example \\((x, c)\\) in \\(S\\) (x: input value, c: expected output) Compute output \\(o\\) for input \\(x\\) For each output cell \\(i\\) (in output layer) Compute \\(\\delta_i\\) for each cell of the output layer: $$\\delta_i = \\sigma'(y_i)(c_i-o_i) = o_i(1-o_i)(c_i-o_i)$$ For each layer from \\(q-1\\) to \\(1\\) Compute \\(\\delta_i\\) for each cell of the current layer: $$\\delta_i = \\sigma'(y_i)\\sum_{k\\in\\text{Succ(i)}}{\\delta_k w_{ki}} = o_i(1-o_i)\\sum_{k\\in\\text{Succ(i)}}{\\delta_k w_{ki}}$$ Update weights: for each weight \\(w_{ij}\\) $$w_{ij} = w_{ij} + \\epsilon \\delta_i x_{ij}$$ Note on thresholding The values of each layer need to be thresholded. To do so, we add a \"virtual neuron\", called bias in each layer, with a fixed value of 1. By updating the associated weights as well, this neuron can be used as an automatic threshold. Implementation Core structure We have to be able to create an arbitrary number of layers, each containing an arbitrary number of neurons. Each layer must be connected to the following layer for execution, but also to the previous layer for the training phase (backpropagation). Thus, the perceptron data structure will be implemented as a double-linked list of layers. Thus, we create two main classes: PerceptronLayer : represents a layer of the network. Each layer is composed of: an array of neuron values. an array representing the weights from this neuron to all neurons of the next layer. a pointer to the next layer a pointer to the previous layer Perceptron : manages the creation/removal of layers, training, execution of the network. It only needs to store a pointer to the first and last layers. OpenCL We are now going to see how this can be implemented using OpenCL. This section depicts a very raw and poorly implemented version of the algorithm. It is only meant to be kept simple so that it provides a clear basis onto which further optimisations can be thought of. First, let's start with the execution part of the network. Execution The execution is really straightforward. It is just a matter of computing the new value of each neuron based on the weighted sum of all neurons from the previous layer. Thus, the kernel will take as input the weights and values for each input neuron (neurons from the previous layer), and will have as output an array containing the new values of the neurons in the current layer. The kernel is thus ran in order on the 2nd, 3rd.... Nth layer. The following kernel can be used to compute the new value for each neuron. Note that it is far from optimal as local memory isn't used at all for the weighted sum! /** * @brief Computes one layer of the perceptron given the previous one and the * weights * The kernel is run once for each layer. * The work items are each tasked with computing the output of a single neuron * of the out layer. * * @param out_layer_size * Size of the output layer (number of elements in the output array that will * contain the result for each neuron). * @param in_layer_size * Number of elements of the input layer * @param in_value * Values of the neuron in the previous layer * @param in_weights * Array containing the weights for each input neuron. It is organised as a * two dimensional matrix, written by concatenating each line in the array * [ w11, w12, w13, ... * w21, w22, w23, ... * ..., ..., ..., ... * ] * Where wij is the weight linking the neuron i of the input layer to the * neuron j of the output layer * The last weights of each row represent the weights for the \"biais neuron\", * whose role is to threshold the values. * Thus, this kernel should be run with a NDRange of in_layer_size-1 * @param out_values * Computed values for the current layer */ void kernel perceptron ( const int in_layer_size , const int out_layer_size , global const float * in_value , global const float * in_weights , global float * out_values ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const int in_layer_s = in_layer_size ; private float sum = 0. ; for ( int i = 0 ; i < in_layer_s ; i ++ ) { sum += in_weights [ i + in_layer_s * global_id ] * in_value [ i ]; } out_values [ global_id ] = sigmoid ( sum ); } Training First, we initialize the weights in range \\([-0.5; 0.5]\\) . This is done on the host side, as random algorithm can be quite tricky to implement efficiently on GPU. All the rest is done in OpenCL. There is a kernel for each step of the algorithm described above. It should be fairly easy to understand by reading the code and comments. perceptron_train_output_layer : forward propagation that computes delta for the output layer perceptron_train_backpropagate : backpropagation that computes delta for every single layer perceptron_train_update_weights : update the weight based on the previously computed delta-values. perceptron_train_update_weights_intertia : another version of the algorithm, updating the weights faster when far from convergence, and getting slower and slower as the convergence zone approaches. This requires however to keep track of the weights from the two previous iterations. ::opencl float sigmoid(float x) /** * @brief Computes delta for all of the output neurons. * * @param values * Values of the output layer * @param expected_values * Values expected as output of the perceptron * @param delta * Output of the function: computes the delta needed for the training algorithm **/ void kernel perceptron_train_output_layer ( global const float * values , global const float * expected_values , global float * delta ) { private const float ci = expected_values [ get_global_id ( 0 )]; private const float oi = values [ get_global_id ( 0 )]; // Equivalent to sigmoid'(yi) * (ci-oi) delta [ get_global_id ( 0 )] = oi * ( 1 - oi ) * ( ci - oi ); } /** * @brief Computes delta for all layers (but the last one) * * @param curr_size * Size of current layer * @param succ_layer_size * Size of the output layer of current layer * @param current_layer_values * Values of current layer (calculated during forward propagation) * @param weights * @param succ_layer_delta_i * Values of delta for the next layer **/ void kernel perceptron_train_backpropagate ( const int curr_size , const int succ_layer_size , global const float * current_layer_values , global const float * weights , global const float * succ_layer_delta_i , // output global float * current_delta_out ) { private const int i = get_global_id ( 0 ); private const float oi = current_layer_values [ get_global_id ( 0 )]; private const int succ_size = succ_layer_size ; private float sum = 0.f ; for ( int k = 0 ; k < succ_size ; k ++ ) { sum += succ_layer_delta_i [ k ] * weights [ i + curr_size * k ]; } current_delta_out [ i ] = oi * ( 1 - oi ) * sum ; } /** * @brief Update the weights according to values of delta computed during backpropagation * * @param out_layer_size * @param epsilon_value * Parameter controlling the rate of convergence. * epsilon too low will lead to a very slow convergence, * epsilon too high will prevent convergence * @param pred_values * @param delta * @param weights **/ void kernel perceptron_train_update_weights ( const int out_layer_size , const float epsilon_value , global const float * pred_values , global const float * delta , global float * weights ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const float val = pred_values [ global_id % out_layer_s ]; // XXX to change private const float epsilon = epsilon_value ; // For each weight weights [ global_id ] += epsilon * delta [ global_id / out_layer_s ] * val ; } /** * @brief Update the weights according to values of delta computed during backpropagation * Uses the weights computed in the two previous training steps to accelerate convergence. * * @param out_layer_size * @param epsilon_value * Parameter controlling the rate of convergence. * epsilon too low will lead to a very slow convergence, * epsilon too high will prevent convergence * @param beta_value * Parameter controlling the non-linear convergence rate * @param pred_values * @param delta * @param previous_weights2 * Weights at the k-2 iteration * @param weights * As input, weights at the k-1 iteration. * As output, new weight at the k iteration **/ void kernel perceptron_train_update_weights_inertia ( const int out_layer_size , const float epsilon_value , const float beta_value , global const float * pred_values , global const float * delta , global const float * previous_weights2 , global float * weights ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const float val = pred_values [ global_id % out_layer_s ]; // wij(k-1) private const float w1 = weights [ global_id ]; // wij(k-2) private const float w2 = previous_weights2 [ global_id ]; // XXX to change private const float epsilon = epsilon_value ; private const float beta = beta_value ; //printf(\"w1-w2: %f\\n\", w1-w2); // For each weight weights [ global_id ] = w1 + epsilon * delta [ global_id / out_layer_s ] * val + beta * ( w1 - w2 ); } Conclusion This article showed how to easily create a perceptron neural network using OpenCL. This is one of my first OpenCL projects, and I'm perfectly aware that this is far from being an optimal code. This article was partly meant as a reminder for myself of how I implemented the perceptron, so that I can later on come back to it and improve upon it. The main thing remaining to do would be to make proper use of local memory, in order to considerably improve the efficiency of the weighted sums computations. I will describe this in another article later on. The full code is available on my github account here I want to thank Lionel Filatre , Professor at the University of Polytech'Nice-Sophia for his lectures on neural networks. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"NeuralNetworks","title":"Multi-layered Perceptron using OpenCL"},{"url":"http://arntanguy.github.io/blog/creating-a-skybox-from-a-fullscreen-quad.html","text":"Creating a skybox is commonly done by either rendering an infite cube or sphere. Both methods are working nicely, but require to set up VBOs, transfer data to the GPU... Granted, that's far from the costlier thing you can do, but then every little bit counts ;) In this article, I will show you how to create a skybox by creating a fullscreen quad in a geometry shader and applying an inverse projection to get the eye direction as it would be if we were to render a cube. Why, will you ask me? Two reasons, it's fun and it's convenient! First, let me thank \"msell\" for the idea . The result is quite interesting: Notice how the center is of perfect resolution? That's because no distortion is applied there, so whatever your environment map resolution was will be preserved. Notice how the sides are \"stretched\"? That's because the texture is virtally projected on a cube, and thus appears stretched towards us. This gives a really deep impression of depth, however it comes at the cost of a little bit of motion blur. This side effect could be very useful for designing skyboxes for racing games! For other types of games, by tweaking the matrices inverted, this effect could be lessened. Geometry shader The role of this geometry shader is to emit a fullscreen quad, and send the view vectors corresponding to each of the corners. These view vectors will be interpolated when being passed to the fragment shader, resulting in view vectors for every part of the skybox, that can be used, for instance to fetch texture information from a samplerCube. # version 330 core uniform mat4 uProjectionMatrix ; uniform mat4 uWorldToCameraMatrix ; smooth out vec3 eyeDirection ; layout ( points ) in ; layout ( triangle_strip , max_vertices = 4 ) out ; void main () { vec4 corner1 = vec4 ( 1.0 , 1.0 , 0. , 1. ); vec4 corner2 = vec4 ( - 1.0 , 1.0 , 0. , 1. ); vec4 corner3 = vec4 ( 1.0 , - 1.0 , 0. , 1. ); vec4 corner4 = vec4 ( - 1.0 , - 1.0 , 0. , 1. ); // Inverse matrix is costly, should be precalculated // This is effectively a non-issue there as it is only computed four times // and would probably be calculated slower on the CPU (unless the view is // fixed, then it's obviously faster to compute it once and for all). mat4 inverseProjection = inverse ( uProjectionMatrix ); mat3 inverseModelview = transpose ( mat3 ( uWorldToCameraMatrix )); gl_Position = corner1 ; eyeDirection = - inverseModelview * ( inverseProjection * corner1 ). xyz ; EmitVertex (); gl_Position = corner2 ; eyeDirection = - inverseModelview * ( inverseProjection * corner2 ). xyz ; EmitVertex (); gl_Position = corner3 ; eyeDirection = - inverseModelview * ( inverseProjection * corner3 ). xyz ; EmitVertex (); gl_Position = corner4 ; eyeDirection = - inverseModelview * ( inverseProjection * corner4 ). xyz ; EmitVertex (); EndPrimitive (); } Fragment shader Nothing fancy here, we only need to use the eyeDirection vector interpolated from the geometry shader to fetch the texture in a samplerCube. # version 330 uniform samplerCube cubemap ; smooth in vec3 eyeDirection ; out vec4 fragmentColor ; void main () { fragmentColor = texture ( cubemap , eyeDirection ); } Usage When rendering it, you need to disable depth testing, so that the fullscreen quad always appear behind every other object. Then just generate an empty VAO to activate it: glBindVertexArray ( vao_skybox ); glDrawArrays ( GL_POINTS , 0 , 1 ); glBindVertexArray ( 0 );","tags":"OpenGL","title":"Creating a Skybox from a fullscreen quad!"},{"url":"http://arntanguy.github.io/blog/using-c11-enum-class-to-define-bitfield-flags.html","text":"C++11 introduced the notion of enum class , which extends the notion of enum to make it closer to a struct. Using this new feature, it is quite easy to achieve bitfield flags by overriding operators. The following header contains all you need to set up a bitfield enum. All it does is wrap the enum within a structure and override some bit manipulation operators & , | and ~ . This allows you to manipulate the bitfield very easyly. # ifndef __ENUM_FLAGS_H__ # define __ENUM_FLAGS_H__ # include < type_traits > template < typename T > using Underlying = typename std :: underlying_type < T >:: type ; template < typename T > constexpr Underlying < T > underlying ( T t ) { return Underlying < T > ( t ); } template < typename T > struct Flags { T t ; constexpr Flags ( T t ) : t ( t ) { } constexpr operator T () const { return t ; } constexpr explicit operator bool () const { return underlying ( t ); } }; # define ENUM_FLAGS ( T ) \\ enum class T ; \\ constexpr Flags < T > operator & ( T l , T r ) { return T ( underlying ( l ) & underlying ( r )); } \\ constexpr T operator | ( T l , T r ) { return T ( underlying ( l ) | underlying ( r )); } \\ constexpr T operator ~ ( T c ) { return T ( ~ underlying ( c )); } # endif Here is an exemple showing how to use it. Notice the macro ENUM_FLAGS(T) above? Well, this is all you'll need to make it work. The parameter T is the name of your enum class. This macro will automatically override operators for you enum, and thus turn it into a bitfield. # include < iostream > # include \"enum_flags.h\" ENUM_FLAGS ( Type ); enum class Type { TYPE1 = 1 << 0 , TYPE2 = 1 << 1 , TYPE3 = 1 << 2 }; class Test { public: Type type ; Test ( Type t ) { type = t ; if ( type & Type :: TYPE2 ); } }; int main () { Test te ( Type :: TYPE2 ); constexpr Type testType = Type :: TYPE1 | Type :: TYPE2 ; if ( testType & te . type ) { std :: cout << \"Bit matches\" ; } } You might be wondering about the 1 << x part. It is the same as saying \\(2&#94;x\\) , that is, setting the bit at the x position to 1. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"C++","title":"Using C++11 enum class to define bitfield flags"},{"url":"http://arntanguy.github.io/blog/fullscreen-quad-with-geometry-shaders.html","text":"One question that we see pop up from time to time on various OpenGL forums concerns the creation of fullscreen quads. Most of the solutions given are sending two fullscreen triangles to a vertex shader. While this approach works, it isn't optimal for graphics card using geometry shaders. And guess what? It is much easier to do it using geometry shaders! Here are the shaders you'll need: An empty vertex shader # version 330 core void main () {} A geometry shader emitting a fullscreen quad # version 330 core /** * Emits a fullscreen quad * Make sure that the input is an empty VAO emitting a dummy GL_POINT */ layout ( points ) in ; layout ( triangle_strip , max_vertices = 4 ) out ; out vec2 UV ; void main () { gl_Position = vec4 ( 1.0 , 1.0 , 0.5 , 1.0 ); UV = vec2 ( 1.0 , 0.0 ); EmitVertex (); gl_Position = vec4 ( - 1.0 , 1.0 , 0.5 , 1.0 ); UV = vec2 ( 0.0 , 0.0 ); EmitVertex (); gl_Position = vec4 ( 1.0 , - 1.0 , 0.5 , 1.0 ); UV = vec2 ( 1.0 , 1.0 ); EmitVertex (); gl_Position = vec4 ( - 1.0 , - 1.0 , 0.5 , 1.0 ); UV = vec2 ( 0.0 , 1.0 ); EmitVertex (); EndPrimitive (); } And a dummy fragment shader # version 330 core out vec4 out_Color ; in vec2 UV ; uniform sampler2D Texture ; void main ( void ) { out_Color = texture2D ( Texture , UV ); } Now, to use it, all you need to do is bind all three shaders, and emmit an empty VAO. /** * Issue a dummy VAO call to send one point to the graphics card. * It will then be able to generate a fullscreen quad **/ glBindVertexArray ( vao ); glDrawArrays ( GL_POINTS , 0 , 1 ); // Don't forget to clear the vertex array, or you might run into some // ugly surprises, like segfaults on glDrawArray calls for instance. glBindVertexArray ( 0 ); If this doesn't work, make sure that: Your graphics card supports geometry shaders The shaders are correctly bound The geometry emitted is a point (empty VAO shown above) That's it, you can now create fullscreen quads! An exemple of post-processsing with an FBO can be found here","tags":"OpenGL","title":"Fullscreen quad with geometry shaders"},{"url":"http://arntanguy.github.io/blog/loading-a-blender-scene-in-physijs-and-threejs.html","text":"La Nuit de l'Info It is quite interesting to realize the context in which these tools have been written. It was all done during an event called \" La Nuit de l'Info \". It is a national event held every year in France in which engineers students are competing from sunset to dawn over a number of challenges. These challenges spawn an impressive number of technologies, ranging from digging up some very old protocols to using some mainstream technologies, passing through Django, Javascript, Android, WebGL... Well you get the idea, that's a lot of possibilites for just a night! Our team \".pyVerts\" won 3 challenges, sadly none of them concerns this article on WebGL. Nonetheless, what will be presented here might not have been material for winning challenges, but certainly did a lot more good than most projects out there: it led to some pretty useful code that could possibly be used by anyone! Three.js, Physijs and Blender: How to fit them together? three.js is a really good 3D WebGL engine. It contains most of what you need to create a game: shader's support, materials, texture, camera, raycasting, and much more. Physijs is a physics engine plugin for Three.js. It is based on the quite famous Bullet Physics engine. Blender is an opensource modelling tool. I will present the rest of this article in the same order as the ideas I had for the night, so that you can grasp the thought process that led me to write additional tools for Three.js. First step: Loading a blender scene in Three.js Install the JSON export plugin for Blender Hopefully, loading a blender scene in Three.js engine is pretty easy. You just need to use the JSON exporter for blender along with the JSONLoader from Three.js. I will show you a version of that with the addition of the integration of Physijs. Here is how to install my version of the blender export plugin: Update: Thanks to some user submissions, the plugin and loading code has been improved. See the updates section at the end of this article to get the newest files. The installation method is the same. Download the modified exporter for blender 2.69 Untar it in ~/.config/blender/2.69/scripts/addons Then go to Blender \"User Preferences\"->\"Addons\", and look for \"three\" in the research bar. Activate it. What's new As you can see, in the Mesh panel, there is an additionnal PHYSICS section . To use it, just select (in object mode) the mesh that you're interested in, and set its properties: Shape: the physics representation of the object (box, sphere, convex hull...). Mass: self-explanatory, set it to 0 if you want a static object Export scene Select all objects within the scene (including cameras and lights), and click on the menu \"File->Export->Threejs\" Make sure that \"scene\" and \"camera\" are checked! That's it, you should now have a JSON scene file that you can use with three.js Load scene I wrote a modified version of the JSON Loader reading the physics parameters from Blender. First, download this class . Now to load a scene, you can look at this example loader The interesting part is var loader = new PhysicsSceneLoader (); loader . callbackProgress = callbackProgress ; loader . load ( \"scene.js\" , callbackFinished ); There is two callback functions. You can use this one to show a progress bar var callbackProgress = function ( progress , result ) { } And this one to handle what to do when loading is finished var loaded = {} var callbackFinished = function ( result ) { loaded = result // Add gravity to the scene loaded . scene . setGravity ( new THREE . Vector3 ( 0 , - 9.8 , 0 )); // Start the physics simulation scene . addEventListener ( 'update' , function () { scene . simulate ( undefined , 1 ); } ); } The variable loaded now contains all the scene. You can use loaded.scene to access the scene object. For instace, if you want to render it renderer . render ( loaded . scene , loaded . camera ) You'll have access to all objects loaded through loaded.objects . Well you get the gist of it! How to improve the export script The export script is far from complete as far as physics is concerned. So here is the gist of how to improve it. If you lack properties, you can easily integrate them by following the following steps: In export_threejs.py : Modify the TEMPLATE_OBJECT variable Modify the object_string in generate_object In init .py : Define your element at the top of the file Something like bpy . types . Object . THREE_physicsShape = bpy . props . EnumProperty ( items = [( 'BoxMesh' , 'BoxMesh' , 'Cube-like mesh' ), ( 'PlaneMesh' , 'PlaneMesh' , 'Plane' ), ( 'SphereMesh' , 'SphereMesh' , 'Sphere' ), ( 'CylinderMesh' , 'CylinderMesh' , 'Cylinder' ), ( 'ConeMesh' , 'ConeMesh' , 'Cone' ), ( 'CapsuleMesh' , 'CapsuleMesh' , 'Capsule' ), ( 'ConvexMesh' , 'ConvexMesh' , 'Convex hull of object' ), ( 'ConcaveMesh' , 'ConcaveMesh' , 'Concave' ), ( 'HeightfieldMesh' , 'HeightfieldMesh' , 'matches a regular grid of height values given in the z-coordinatesHeightfield' )], name = \"Mesh Type\" ) Add it to the OBJECT_PT_physics class In the engine , add it to PhysicsLoader.js : Look for where the Physijs.Mesh are defined, and do the proper changes, that's it, you're all set! Troubleshoot My physics bounding volume seems way bigger than the real object There my friend, you probably just encountered one of the most common problems with blender. By default, exporting doesn't apply scale to your mesh, quite stupid ain't it. Hopefully it is very easy to solve: select your model in Blender, and then hit Ctrl-A -> Apply Rotation and Scale. That's it, you're done ;) Updates Kevin Bikhazi improved upon my plugin. You can find the modified exporter for blender 2.69 here Here is the changelog Adds friction and restitution parameters under an object's material tab in Blender. These parameters are very important as they affect how the model interacts with the physics world. The Blender add-on has been modified to handle the new material parameters. Currently the mods only work with standard materials and not with normal mapped materials. It should be pretty easy to get it to work with normal maps, that might come soon PhysicsSceneLoader.js modified to use the new friction and restitution parameters. To install it, just untar, and copy the files to the proper location as specified in the article. Conclusion It's probably far from the best way of loading physics within three.js: it was written during a crazy night of coding! Yet, I hope this helps to give you ideas of how to automatically load geometry and physics within your webgl application.","tags":"WebGL","title":"Loading a Blender scene in Physijs and Three.js"},{"url":"http://arntanguy.github.io/blog/using-cgengines-fbos.html","text":"Create a FBO: cg :: FBO fbo = cg :: FBO ( windowSize . x , windowSize . y , cg :: FBO :: COLOR ); Link its internal texture to rendering shader (the one used to render on a visible fullscreen quad for instance). cg :: Shader shader ; shader . loadVertexShaderFromFile ( \"../src/fullscreen_quad.vert\" ); shader . loadGeometryShaderFromFile ( \"../src/fullscreen_quad.geom\" ); shader . loadFragmentShaderFromFile ( \"../src/fullscreen_quad.frag\" ); // Activate shader shader (); // Link texture shader . setTexture ( \"Texture\" , fbo . getColorTextureId ()); Do the linking texture step only once before the rendering. There is no point in linking it every time! Anyway that wouldn't work properly if you were to do that. Now you can activate the FBO in the render loop and render on it: // Activate render to FBO fbo . renderToFBO (); // Clear the FBO (equivalent to glClear(...)) fbo . clear (); /** * drawing... * We fill the array and then activate the Vertex Attrib 0 **/ shader (); glVertexAttribPointer ( 0 , 2 , GL_FLOAT , GL_FALSE , 0 , vertices ); glEnableVertexAttribArray ( 0 ); // Draw triangles glDrawArrays ( GL_TRIANGLES , 0 , 3 ); // Disable Vertex array when not needed anymore glDisableVertexAttribArray ( 0 ); The rendering part on the FBO is finished. After this step, you should have a triangle drawn on the FBO's texture. All that's left to do is display the texture to check whether everything is fine. This can be done using a fullscreen quad. The code below uses a geometric shader to generate the quad, and a fragment shader to texture it with the previously generated texture. Note that we don't need to bind the FBO's texture to the shader since this has been done before the rendering loop. cg :: FBO :: renderToScreen (); shader (); /** * Issue a dummy VAO call to send one point to the graphics card. * It will then be able to generate a fullscreen quad * Since we've bound the FBO's render texture to the uniform Texture of * the shader, we only need a sampler2D Texture; in the fragment shader * to make it work! **/ glBindVertexArray ( vao ); glDrawArrays ( GL_POINTS , 0 , 1 ); // Don't forget to clear the vertex array, or you might run into some // ugly surprises, like segfaults on glDrawArray calls for instance. glBindVertexArray ( 0 ); You can find the fullscreen quad shaders here","tags":"OpenGL","title":"Using CGEngine's FBOs"},{"url":"http://arntanguy.github.io/blog/install-ubuntu-on-msi-ge60-0nc.html","text":"Hi, It's been a while since I last had a bit of trouble installing Ubuntu, so I decided to write a small article about it. Don't expect screenshots, I don't want to go back to the installer just for the sake of some nice images. I will here explain how I installed a dualboot Windows 8/Ubuntu on my new MSI GE60 ONC laptop. UEFI The main difference I encountered was the introduction of UEFI. Don't worry if you had never heard of that before, I discovered it while installing Ubuntu on my new laptop as well! Basically, it is meant to replace the old BIOS architecture with a more flexible one. What the Ubuntu documentation on UEFI recommends is to install both Windows and Ubuntu using the UEFI mode. Unfortunately, for some reason that I was unable to figure out, I wasn't able to properly boot the LiveUSB on UEFI mode: it kept on giving me a black screen (and from what I saw on the forums, I'm not the only one). The workaround I used consists of booting and installing in Legacy Mode. To go into legacy mode, just press \"Del.\" on startup to enter the BIOS, and change the \"Boot\" options to Legacy instead of UEFI. Then, install the dualboot as usual (reduce windows partition size, create a new one for linux, extend the Data partition, add a swap partition). You will also need to create a special partition for the BIOS support of Legacy. To do so, create a small partition using gparted (>1Mb), and set the Flag grub_bios (or something like that). You're done. Now, to start Linux, go into the BIOS and set it to Legacy to start Windows, go into the BIOS and set it to UEFI I know, it's quite an ugly workaround, but that did the trick, and I'm barely even starting windows, so for me going into the bios when I need to start it is not so much of a bother. You could try using the boot-repair utility to convert the legacy booting process to UEFI. It is supposed to work quite well, however I ran into topics of users that tried it and failed. So I didn't bother investigating any further. Let me know if you manage to do it successfully ;)","tags":"Linux","title":"Install Ubuntu on MSI-GE60 0NC"},{"url":"http://arntanguy.github.io/blog/shadermaker-fix-bug-with-geometry-shaders.html","text":"Hi! I've just tried ShaderMaker, which seemed like a great shader editor, and one of the only existing ones that is truly cross-plateform. However, I'm still an unlucky student stuck with an integrated intel chipset, which obviously doesn't support geometry shaders. Unfortunaly, when I tried editing a fragment shader I bumped into a nice Segmentation fault! I looked it up online, and the only information I could find was that ShaderMaker crashed whenever geometry shader weren't supported by the graphics card. Strangely enough, I couldn't find any patch, despite the number of people complaining about it So I decided to get my hands dirty, after all, I'm programming a physic engine and a bunch of shaders at the moment, so how hard could it be to fix a segmentation fault? Not hard at all! The bug is a mere problem of indices, that causes the program to look for a non-existing text editor. That's all. Since I didn't really have the time to delve into the code, I merely hacked the incriminated index back into behaving itself. It should work for everybody, even lucky possessors of geometry shaders enabled cards (even though they don't need this fix). So here goes the magick: Download the patched version of the sources from http://dl.free.fr/jRYRjmwEb And then build it using the usual method: qmake -unix ShaderMaker.pro make That's it, you're all set and it should work. Just in case, I'm also posting the diff file here diff --git a/src/editwindow.cpp b/src/editwindow.cpp index 703b95a..1da7461 100644 --- a/src/editwindow.cpp +++ b/src/editwindow.cpp @@ -320,7 +320,7 @@ createMenus */ void CBaseEditWindow::createMenus( IShader* ) { - // files + // files m_menuFile = menuBar()-&gt;addMenu( tr( \"&amp;File\" ) ); m_menuFile-&gt;addAction( m_actNew ); m_menuFile-&gt;addAction( m_actOpen ); @@ -449,7 +449,7 @@ void CSdiEditWindow::uploadShaderSource( IShader* shader ) { if( m_attachToShader ) { - shader-&gt;setShaderSource( m_document-&gt;shaderType(), + shader-&gt;setShaderSource( m_document-&gt;shaderType(), m_document-&gt;document()-&gt;toPlainText() ); } else // disabled by the user @@ -766,7 +766,6 @@ void CMdiEditWindow::createMenus( IShader* shader ) m_menuView-&gt;addAction( m_actToSDI ); } - /* ======================== createTabs @@ -777,6 +776,8 @@ void CMdiEditWindow::createTabs( IShader* shader ) m_tabs = new QTabWidget(); // add tabs + qDebug() &lt;&lt; \"Creating \" &lt;&lt; IShader::MAX_SHADER_TYPES &lt;&lt; \" editors\\n\" ; + m_geometryShaderAvailable = shader-&gt;isShaderTypeAvailable(IShader::TYPE_GEOMETRY); for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { m_editors[ i ] = NULL; @@ -805,14 +806,26 @@ void CMdiEditWindow::createTabs( IShader* shader ) connect( m_signalMapper, SIGNAL(mapped(int)), m_tabs, SLOT(setCurrentIndex(int)) ); } - /* ======================== positionChanged ======================== +XXX: Contains a hack to fix a bug occuring on low-end graphics card that don't support +geometry shaders... Tabs index becomes invalid, and thus causes a segfault. +The fix is merely a correction of indices in case geometry shaders aren't present. +It is not meant to be an optimal fix, I didn't have time to delve into the code. +This should still work with geometry shaders present, though this is untested. */ void CMdiEditWindow::positionChanged( void ) { - QTextCursor cursor = m_editors[m_tabs-&gt;currentIndex()]-&gt;textCursor(); + int index = m_tabs-&gt;currentIndex(); + /** + * XXX: Hack to fix geometry shader bug + **/ + if(!m_geometryShaderAvailable &amp;&amp; m_tabs-&gt;currentIndex() == 1) { + index = 2; + } + CSourceEdit *edit = m_editors[index]; + QTextCursor cursor = edit-&gt;textCursor(); int ln = cursor.blockNumber() + 1; int col = cursor.columnNumber() + 1; m_lineNumber-&gt;setText( \"Ln: \" + QString::number(ln) + \" | Col: \" + QString::number(col) ); @@ -831,7 +844,7 @@ CSourceEdit* CMdiEditWindow::activeDocument( void ) // do not type cast. does not hurt, since there are only 3 elements... for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { - if( m_editors[ i ] != NULL &amp;&amp; + if( m_editors[ i ] != NULL &amp;&amp; m_editors[ i ] == widget ) { return m_editors[ i ]; @@ -854,7 +867,7 @@ int CMdiEditWindow::tabToShader( int tabIndex ) // look up the widget... it only take 3 loops... for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { - if( m_editors[ i ] != NULL &amp;&amp; + if( m_editors[ i ] != NULL &amp;&amp; m_editors[ i ] == widget ) { return i; diff --git a/src/editwindow.h b/src/editwindow.h index 0a5fc20..33a8a9d 100644 --- a/src/editwindow.h +++ b/src/editwindow.h @@ -305,6 +305,7 @@ private: // all documents CSourceEdit** m_editors; // [ IShader::MAX_SHADER_TYPES ] bool* m_attachToShader; // [ IShader::MAX_SHADER_TYPES ] + bool m_geometryShaderAvailable; // XXX: Hack to fix geometry shader bug on low end graphics card // actions QAction* m_actNextShader;","tags":"Programmation","title":"ShaderMaker: Fix bug with geometry shaders!"},{"url":"http://arntanguy.github.io/blog/install-archlinux-on-dell-latitude-e5420.html","text":"Je ne compte pas parler de l'installation d'ArchLinux en lui-mme, bien assez de documentation existe sur le sujet. Je vais me contenter de prciser les parties spcifiques  ce laptop. Touchpad Le touchpad n'est pas un touchpad Synaptics, ce qui complique lgrement la configuration, d'autant plus qu'un bug du noyau fait qu'il n'est pas reconnu en tant que touchpad, mais en temps que souris Pour l'installer, il faut installer le paquet AUR psmouse-elantech , qui compilera un module du noyau linux permettant de corriger le bug. Voici la dmarche  suivre pour le faire : Ensuite, si vous dsirez que le module soit automatiquement compil quand c'est ncessaire (mise  jour), mettez le dans le rc.conf MODULES = \"psmouse-elantech\" Ce laptop ne dispose pas de carte graphique, seulement du chipset intgr Intel. Pour le configurer, voici la dmarche. Installer le paquet xf86-video-intel pacman -S xf86-video-intel Ensuite, il faut modifier les entre du grub, si vous dsirez disposer de toutes les performances du chipset. Pour ce faire, ditez le fichier /boot/grub/menu.lst (en root), et modifiez le ainsi # (0) Arch Linux title Arch Linux root ( hd0,2 ) kernel /boot/vmlinuz-linux root = /dev/sda3 ro i915.modeset = 1 initrd /boot/initramfs-linux.img i915.modeset=1 active le module i915.modeset=0 dsactive le module Attention : SI vous aviez des entres vga dans le menu.lst, il faut les enlever !","tags":"Linux","title":"Install ArchLinux on Dell Latitude E5420"},{"url":"http://arntanguy.github.io/blog/configure-usb-debugging-of-android-on-gnulinux.html","text":"ShaderMaker's text editor crashed. Indeed, the code tries to load a geometric shader while this isn't possible. This article provides the necessary source code to fix this issue. disqus_identifier: geenux-usb-debugging-android You want to develop your own application and test it directly your phone instead of the virtual machine? Or perhaps you just want to use some cool features of the SDK to manage your phone? Whatever the reason, here is how to do it. First, I'll assume that you have already installed the android SDK. The only thing left to do, is to set-up rules for udev. Most articles are happy with giving you a list of devices and Vendor ID. Well, I'm not. These lists are often not exhaustive, and unusual android devices are not represented. There is a really simple way of figuring out this data. Simply use the command lsusb It will give you a description of all your USB devices, find the one corresponding to your device Bus 002 Device 004: ID 04e8:689e Samsung Electronics Co., Ltd All the information you need is in this line : the vendor ID is 04e8, and the device id is 689e (this is a Samsung Galaxy Ace). You just have to declare it to udev: sudo vim /etc/udev/rules.d/51-android.rules Then put a line like: SUBSYSTEM == \"usb\" , ATTR { idVendor }== \"04e8\" , , ATTRS { idProduct }== \"689e\" , MODE = \"0666\" Obviously you need to set your own vendor and device ID here. You're all set! Next time udev will restart, your device should work!","tags":"Programmation","title":"Configure USB debugging of Android on GNU/Linux"},{"url":"http://arntanguy.github.io/blog/script-de-telechargement-pour-mangareadernet.html","text":"J'ai ralis un petit script python pour tlcharger les mangas depuis le site http://mangareader.net . Ce script fonctionne pour tous les mangas que j'ai test, je suppose qu'il fonctionne pour le reste. Le code est un peu sale, gestion des exceptions pas trs rigoureuse (si il y a une erreur durant le tlchargement, pas de souci, vous serez prvenu), appel de fonctions qui pourraient tre vits Si je suis pas trop flemmard, je modifierai a plus tard. Il n'est probablement pas lgal d'utiliser ce script sans tre en possession des mangas originaux, pensez  les acheter ! Le script est sous licence GNU GPL, vous tes libres de le modifier, l'utiliser comme bon vous semble. Si vous l'amliorez, j'apprcierai d'avoir le nouveau script. Utilisation Tout d'abord, il faut modifier quelques paramtres dans le script pour l'adapter  vos besoin. La variable DL_DIR contient le rpertoire dans lequel vous souhaitez stocker les mangas, adaptez la  vos besoin. Pour utiliser le script, il suffit de faire mangareader.py \"one piece\" 199 Cette commande tlcharge le chapitre 199 de One Piece. mangareader.py \"fairy tail\" 1-112 Cette commande tlcharge les chapitres de 1  112 de Fairy Tail Voici donc le script en question: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"A small script that downloads mangas from onemanga.com Licenced under the WTPL Licence\"\"\" import os import re import socket import sys import urllib def helper (): \"\"\"Gives help about the use of this script\"\"\" print \"\"\"Usage: - python \"\"\" + sys . argv [ 0 ] + \"\"\" manga chapter - python \"\"\" + sys . argv [ 0 ] + \"\"\" manga firstchap-lastchap \"\"\" exit ( 0 ) # Config MAXTRIES = 5 DL_DIR = \"/media/DATA/Mangas/\" MANGA_LIST = \"http://www.mangareader.net/alphabetical\" MANGA_SITE = \"http://www.mangareader.net\" CHAPTER_NUMBER_LENGTH = 3 def print_error ( text ): print \" \\033 [31;1m\" + text + \" \\033 [0m\" def print_sucess ( text ): print \" \\033 [32;40m\" + text + \" \\033 [0m\" def down ( url ): \"\"\"Download the webpage at the given url\"\"\" tries = 0 downloaded = False while tries < MAXTRIES and downloaded == False : try : ret = urllib . urlopen ( url ) downloaded = True except ( IOError , socket . error ): tries += 1 print_error ( \"Failed download, retrying...\" ) if tries == MAXTRIES : print_error ( \"Maximum tries number reached exiting...\" ) exit ( 1 ) if tries == 0 : print_sucess ( \"Downloaded !\" ) return ret def retrieve ( url , nom ): \"\"\"Retrieves a file\"\"\" tries = 0 downloaded = False while tries < MAXTRIES and downloaded == False : try : urllib . urlretrieve ( url , nom ) downloaded = True except ( socket . error , IOError ): tries += 1 if tries == MAXTRIES : print_error ( \"Maximum tries number reached exiting...\" ) exit ( 1 ) else : print_error ( \"Failed download, retrying...\" ) if tries == 0 : print_sucess ( nom + \" downloaded.\" ) def make_pretty ( name ): \"\"\"Returns the chain given, in order to have a normal name\"\"\" return str ( name ) . capitalize () . replace ( \"/\" , \"\" ) . replace ( \"_\" , \" \" ) class Mangareader : \"\"\"Manga class. Contains several attributes related to the manga. Contains also methods to download its chapters\"\"\" def __init__ ( self , manga ): self . manga = manga self . manga_p = make_pretty ( manga ) self . url = \"http://mangareader.net/\" self . nb_image = 0 # Create the download directory try : if ( os . path . isdir ( DL_DIR ) == False ): os . mkdir ( DL_DIR ) if ( os . path . isdir ( DL_DIR + self . manga_p ) == False ): os . mkdir ( DL_DIR + self . manga_p ) except OSError : print_error ( \"Unable to create the download directory\" ) exit ( 1 ) def chap_dir_name ( self , number ): \"\"\"Returns the name of the directory of the chapter. It is useful in order to organize the mass of chapters. example: 500 chaps in the manga, directory named \"001\" instead of \"1\" \"\"\" num = str ( number ) return ( CHAPTER_NUMBER_LENGTH - len ( num )) * \"0\" + num def get_chapter ( self , number ): \"\"\" Get the images page url list \"\"\" print \"Downloading chapter \" + self . chap_dir_name ( number ) url = MANGA_SITE + \"/\" + self . manga + \"/\" + str ( number ) page = down ( url ) . read () #print page exp = 'select> of ([0-9]+).*<' try : self . nb_images = int ( re . search ( exp , page ) . group ( 1 )) #print nb_images except : print_error ( \"Cannot determine the number of images in this chapter\" ) #<option value=\"/103-2057-1/one-piece/chapter-12.html\" selected=\"selected\">1</option> exp = '<option value=\"(.*)\">(.+)</option>' exp2 = '<option value=\"(.*)\" selected=\"selected\">(.+)</option>' # get the link for all pages containing chapter images img = re . findall ( exp , page ) images = [] try : images . append ( re . findall ( exp2 , page )[ 0 ][ 0 ]) except : print_error ( \"Une page n'a pas t trouve !\" ) # remove the problem with the special case of the current image for l in img : el = l [ 0 ] if ( el . find ( \"selected\" ) < 0 ): images . append ( el ) manga_dir = DL_DIR + self . manga_p + \"/\" + self . chap_dir_name ( number ) try : if ( os . path . isdir ( manga_dir ) == False ): os . mkdir ( manga_dir ) except OSError : print_error ( \"Unable to create the download directory\" ) exit ( 1 ) os . chdir ( manga_dir ) self . get_images ( images ) def get_images ( self , images_url ): #<img id=\"img\" width=\"800\" height=\"1210\" src=\"http://i28.mangareader.net/one-piece/133/one-piece-1690829.jpg\" alt=\"One Piece 133 - Page 15\" name=\"img\" /> exp = '<img id=.* width=.* height=.* src=\"(.*)\" alt=.* name=.* />' images = [] for url in images_url : print \"Parsing page \" + url page = down ( MANGA_SITE + url ) . read () img = re . findall ( exp , page ) try : images . append ( img [ 0 ]) except : print_error ( \"Un lien vers une image n'a pas t correctement rcupr!\" ) i = 1 for img in images : if len ( images ) == self . nb_images : print \"Tlchargement de l'image \" + str ( i ) + \"/\" + str ( self . nb_images ) retrieve ( img , self . manga_p + \"-\" + self . chap_dir_name ( i )) i += 1 else : print_error ( \"Le nombre d'images  tlcharger est diffrent du nombre d'images du chapitre ! Tout ne sera pas tlcharg !\" ) if len ( sys . argv ) != 1 and ( sys . argv [ 1 ] == \"-h\" or sys . argv [ 1 ] == \"--help\" ): helper () exit ( 0 ) elif len ( sys . argv ) == 1 : helper () exit ( 0 ) if (( len ( sys . argv ) == 2 ) and ( sys . argv [ 1 ] == \"Is there an easter egg in this awesome program ?\" )): print \" __/~~\\-''- _ | \" print \"__- - { \\ \" print \" / \\ \" print \" / ;o o } \" print \" | ; \" print \" ' \" print \" \\_ (..) \" print \" ''-_ _ _ / \" print \" / \" print \" / \" if len ( sys . argv ) == 3 : M = Mangareader ( sys . argv [ 1 ]) chap = sys . argv [ 2 ] if chap . find ( \"-\" ) > 0 : chap = chap . split ( \"-\" ) if ( len ( chap ) == 2 ): for i in range ( int ( chap [ 0 ]), int ( chap [ 1 ])): M . get_chapter ( i ) else : M . get_chapter ( sys . argv [ 2 ])","tags":"Programmation","title":"Script de tlchargement pour mangareader.net"},{"url":"http://arntanguy.github.io/blog/test-gallery.html","text":"You want to develop your own application and test it directly your phone instead of the virtual machine? Or perhaps you just want to use some cool features of the SDK to manage your phone? Whatever the reason, here is how to do it. First, I'll assume that you have already installed the android SDK. The only thing left to do, is to set-up rules for udev. Most articles are happy with giving you a list of devices and Vendor ID. Well, I'm not. These lists are often not exhaustive, and unusual android devices are not represented. There is a really simple way of figuring out this data. Simply use the command lsusb It will give you a description of all your USB devices, find the one corresponding to your device Bus 002 Device 004: ID 04e8:689e Samsung Electronics Co., Ltd All the information you need is in this line : the vendor ID is 04e8, and the device id is 689e (this is a Samsung Galaxy Ace). You just have to declare it to udev: sudo vim /etc/udev/rules.d/51-android.rules Then put a line like: SUBSYSTEM == \"usb\" , ATTR { idVendor }== \"04e8\" , , ATTRS { idProduct }== \"689e\" , MODE = \"0666\" Obviously you need to set your own vendor and device ID here. You're all set! Next time udev will restart, your device should work!","tags":"misc","title":"test gallery"},{"url":"http://arntanguy.github.io/blog/ripper-laudio-dune-video-avec-ffmpeg.html","text":"Bonjour, Vu que j'ai eu un peu de mal  trouver comment ripper la bande son d'une vido (en l'occurence de youtube), j'ai fait un petit script pour le faire simplement : #!/bin/bash ### libmp3lame required : to install #sudo apt-get install ffmpeg libavcodec-extra-52 for i in \"$*\" ; do #mplayer -ao pcm \"$i\" -ao pcm:file=\"$(echo \"$i\"|cut -d'.' -f1).mp3\" # -vn remove the video ffmpeg -i \"$i\" -vn -acodec libmp3lame \"$(echo \" $i \"|cut -d'.' -f1).mp3\" done Trs simple  utiliser, faites juste ripaudio.sh fichier1.flv fichier2.mpeg ...","tags":"Linux","title":"Ripper l'audio d'une vido avec FFMPEG."},{"url":"http://arntanguy.github.io/blog/useful-usages-of-dd.html","text":"Hello world, Why bother using heavy and complicated tools to create and use ISO files? Why not simply consider using the dd command? Granted, this command can sometimes look quite scary, especially because of it's impressive potential to destroy data with a misintruction. Still, it's a very useful command, just be careful how you use it! Create an ISO image of a CD Data within a CD are commonly wrapped in an ISO-9660 filesystem. An ISO image is merely a copy of this filesystem in a single file. Seen like that, the solution spawns naturally: we merely neeed to do a bit by bit copy of the CD into a file... Who said dd is meant for that? Just run dd if = /dev/cdrom of = cd.iso Mount ISO Mountin an ISO can always be useful, so here is how to do it. sudo mkdir /mnt/iso sudo mount -t iso9660 -o loop cd.iso /mnt/iso ls /mnt/iso Create bootable USB key Assuming you USB key is on /dev/sdb , and isn't mounted , you can simply run the following command to create a bootable USB key. Note that it is sd b and not sd b1 . Indeed, we do want to copy the bootloader and the partition table as well. dd bs = 4M if = bootable_iso.iso of = /dev/sdb","tags":"Linux","title":"Useful usages of dd."},{"url":"http://arntanguy.github.io/blog/create-frames-for-fotowall.html","text":"This article is a translation of Benot Blon's article (fr) concerning the frame creation for Fotowall. I'm translating this article to increase the reach of his work, and meet the ever growing reclamations for more frames. The few frames proposed as default in Fotowall aren't always enough to fill up the user's creativity. Luckily, this software uses only standards, namely SVG for the frames realisation. Thus, it is rather simple to create new frames, though two little constraints must be respected : Drawing an SVG image require the use of a SVG manipulation software, which is not that complicated, but can certainly repel more than one. Following a certain amount of indications, once again concerning the SVG, for a perfect display in Fotowall And there, I lost half my readers (which must represent an arm or a foot) Before I suggest a solution to avoid these to constraints, and thus make the integration of a \"simple drawing\" as a frame in Fotowall easier, we will see how these famous frames works. As said before, the frames are based on SVG drawings. In order to be used in Fotowall, these are cut in 9 pieces, indentified by a label inside the SVG file. The following illustration represents these 9 pieces, the pink area correspond to the position of a canvas' photo. The labels displayed on each piece, such as \"topleft\" or \"bottom\", correspond to the different ID on which Fotowall depends on. Without these ID, Fotowall won't be able to use the frame, and the outline of the photo, be it of your nephew or of Mdor, will desperately remains empty. To these 9 pieces, adds up 4 other elements, represented by arrows above. Although they appear while the vectorial drawing is edited, they are invisible inside Fotowall, but are nonetheless necessary. These, identified by the IDs \"hint-[...]-margin\", are used to define the width of the visible outline. Thus, if we take the example of the left arrow, here is its impact on the left image: If the object \"hint-left-margin\" is as long as the image \"left\", then this image appears in its whole width If the object \"hint-left-margin\" is longer than the image \"left\", then a space appears between this image and the border of the photo. This space is automatically filled with the background image \"center\", which exceed the photo's from on the left side. If the object \"hint-left-margin\" is less long than the image \"left\", then the latter is partially covered with the photo. Mathematically, the distance between the space zone and the covered zone, is the difference of length between the element \"hint-[...]-margin\" and each of the concerned images (the 3 on the left, right, top, bottom): if the frame is 5 pixels and the margin is 10 pixels, there will be a gap of 5 pixels between the frame and the photo. A little detail that is worth mentioning, the images \"top\", \"left\", \"bottom\" and \"right\" will be automatically stretched according to the photo's size. From here, we realise that unfortunately it's hard to come up with a frame composed of pattern supporting to be bent The following example illustrate rather well this problem. Never mind that ! It's already possible to do enough to have fun, and these few limitations will probably be lifted with time. We saw that a frame is composed of 9 + 4 graphical elements in an SVG file. To avoid entering the IDs of these elements manually inside a SVG file (which is a mere XML structured file), in Inkscape it is possible to enter these after a right click on each of these elements, as illustrated below. With the information we just studied, we can see that creating a frame can me done without to much difficulty, but is nonetheless a tedious work, which can really become a bother when you try to use more colour schemes for a single frame. And, of course, not everyone is confortable with vectorial drawing! In this case, why not created a bitmap (JPG, PNG) frame with an image software such as Gimp, and then convert it in an SVG frame ready to use in Fotowall? As we briefly said before, an SVG file is a mere XML file. Luckily enough, there are plenty of linux command line tools, and Bash (or any other *sh, not to be -too- sectarian) is the star when it come to create files automatically! The temptation to create such a program was way too high. Thus, here come a script which will allow us to free ourselves from the cutting and SVG conversion : fotowall_frame_compiler.zip Once uncompressed, the use of this script, though requiring the use of a dark and strange screen, the one we call \"Terminal\", is really simple to use. Just look: ./fotwall_frame_compiler.sh image.png This script can work with a unique parameter, namely the image to convert. In this case, the 9 frame's pieces will be as often as possible of equal height and width. For a better rendering, try to prefer dimensions which are multiple of 3 from the begining. In output, the SVG file is created, using the name of the original picture and replacing the extension with \".svg\" (which gives in our example image.png > image.svg). But we can as well have a frame's outline as high or wide (or both) different from the one reserved to the photo position. Taking back the example of the first illustration, we clearly see that the height of \"top\" and \"bottom\" is not the same as the height of \"center\". In this case, it will be necessary to know the exact size we want to give to \"center\" once transformed into SVG. In Gimp, it is for instance possible to measure this sone with the rectangular selection tool. Once the height and width are known, we just have to add these two parameters to the script: ./fotowall_frame_compiler.sh image.png 150 130 This script can work with a unique parameter, namely the image to convert. In this case, the 9 frame's pieces will be as often as possible of equal height and width. For a better rendering, try to prefer dimensions which are multiple of 3 from the begining. In output, the SVG file is created, using the name of the original picture and replacing the extension with \".svg\" (which gives in our example image.png > image.svg). But we can as well have a frame's outline as high or wide (or both) different from the one reserved to the photo position. Taking back the example of the first illustration, we clearly see that the height of \"top\" and \"bottom\" is not the same as the height of \"center\". In this case, it will be necessary to know the exact size we want to give to \"center\" once transformed into SVG. In Gimp, it is for instance possible to measure this sone with the rectangular selection tool. Once the height and width are known, we just have to add these two parameters to the script: ./fotowall_frame_compiler.sh image.png 150 130 The first number represents the width in pixels, the second represents the height. Considering that the \"center\" area is perfectly centred, the script is capable of calculating the width and height of each one of the 9 parts, and to place them within the SVG file. In short, there is nothing left to do, the frame is immediately usable within Fotowall! If the rendering is not perfect (a gap of 1 or 2 pixels is always possible), you just have to play directly on the two values of the command line, and reload the frame in Fotowall. To illustrate all of this, here comes a more concrete example: However, this script requires one or two programs, which are available within the repository of every good GNU/Linux distribution: base64: it should be installed by default, this software can store each of the 9 images directly inside the SVG file. ImageMagick : the convert and identify commands are overused in this script. A version 6.5.8-9 at least is required for the automatic splitting in 9 images. Inkscape is not really required anymore, but it would be too bad not to use it... Warning: this script created temporarily 9 PNG images in the directory. These 9 elements are then stored within the SVG file, after being split and numbered as follow by ImageMagick (using the example above) : image_0.png, image_1.png,  , image_8.png. Please mind not having an important picture named the same, otherwise it will be overwritten. If someone is motivated to create a proper warning and management of these kind of problems, feel free to do so, it would be greatly appreciated . After seeing how the frames works, a script allows us to free ourselves from a certain amount of boring steps (labelling, splitting), and thus we can concentrate on the pure graphical realisation of the image. Save the images in PNG, as it is the only format to benefit from both colour and transparency. By way of conclusion, we can summarise the main parts adressed here concerning the Fotowall's frames: They are in SVG format, and can be drawn using one of the vectorial manipulation programs, such as Inkscape. A frame is composed of 9 elements : the 4 corners, the 4 borders, and the center. To these 9 elements, adds up 4 others for the distance between the border of the frame and the border of the photo. Each of the elements is given a precise ID within the SVG file. The borders being stretched, the patterns are bent, which for now put a small limitation on your creativity. It is possible to avoid all the SVG part, and created a frame from bitmaps (once again, favour the PNG format) using the script fotowall_frame_compiler (needs GNU/Linux and a recent version of ImageMagik). A huge thanks to Benot Blon for this article, I hope that my approximative translation didn't rip too much of the original essence of the article.","tags":"FotoWall","title":"Create Frames For FotoWall"},{"url":"http://arntanguy.github.io/blog/creez-vos-mesh-ogre-sous-blender.html","text":"Si vous aimez le logiciel de modlisation 3D Blender, vous serez sans doute ravi de l'utiliser pour crer votre monde dans votre jeu utilisant le moteur Ogre. La bonne nouvelle, c'est que c'est d'une simplicit impressionnante, je vais profiter de ce billet pour me faire un petit mmo sur comment faire, ainsi que comment utiliser la technique de l'UV mapping avec Blender (je dbute avec la 3D, que a soit en programmation ou modlisation). L'exemple prsent ici sera fait sur un simple cube, que l'on va texturer, et intgrer dans un projet Ogre. Installation du script d'exportation OGRE Meshes Exporter Sous Ubuntu Tout d'abord, vous aurez besoin du script d'exportation pour Ogre. Sous Ubuntu pour l'installer, il suffit de faire sudo aptitude install blender-ogrexml Sous une autre distribution Si vous avez une autre distribution, voici comment installer le script. Tlchargez OGRE Meshes Exporter Copiez ogremeshesexporter.py et les sous-dossiers dans ~/.blender/scripts Note : Vous devez aussi avoir python 2.6.4 install pour que le script fonctionne. Cration du cube et UV mapping Ouvrez Blender, crez un cube dans une nouvelle scne. Dplacez votre curseur sur la limite suprieure de la zone de modlisation jusqu' voire une double flche. Clic droit, puis clic gauche sur Split Area, puis clic gauche pour valider. Maintenant, dans la nouvelle fentre cr, passez en mode UV/ImageEditor Retournez dans la vue 3D, passez en mode editing (touche tab), slectionnez tout le cube Ensuite, faites U -> Unwrap (smart projection). Smart projection est souvent la mthode de droulement donnant les meilleurs rsultats. Faites ensuite Image -> Open (Alt+O) et ouvrez une image de votre choix qui vous servira de texture. Vous pouvez en trouver dans le rpertoire OGRE/media/materials/textures Une image apparait alors dans la partie de l'UV mapping. Normallement, les vues planes des faces du cubes devraient coincider avec la taille de l'image, si ce n'est pas le cas, slectionnez toutes les faces dans la partie UV (touche A) puis redimensionnez les en utilisant la touche s. On obtient Allez dans la vue 3D, et faites Alt+Z pour passer en mode textur. Normalement vous devriez voir la texture. Il ne reste plus qu' assigner un matriau au cube, et  exporter. Ouvrez le panneau Shading (F5), puis crez un nouveau matriau. Cliquez sur Tex Face. Exportation Faites Fichier->Exporter->Ogre Meshes. L, vous avez la fentre du bas qui se modifie. Cliquez sur  Game Engine Materials  et  OgreXMLConverter . Le fait de slectionner OgreXMLConverter appellera automatiquement le programme d'Ogre du mme nom qui est charg de convertir le fichier XML du mesh en des fichiers de mesh que le moteur comprend. Cliquez sur  Exporter . Sublime, magnifique, perfect, vous venez de crer votre premier Mesh pour OGRE. Mais comment l'utiliser maintenant ? Suivez le guide. Utiliser le mesh dans OGRE Dans cette partie, je supposerai que vous connaissez au moins les bases de OGRE, c'est  dire les premiers tutoriels du wiki officiel, au moins jusqu' la partie permettant de charger un mesh. Tout d'abord, il va falloir placer les fichiers o il faut, c'est  dire o vous voulez. Je vous conseille namoins de respecter la structure habituelle de OGRE, c'est  dire - Ogre ( un dossier dans lequel vous placerez vos mesh , par exemple dans le r  pertoire de votre jeu , o  ailleurs ).  > models : vous placerez dans ce r  pertoire le fichier Cube .001 . mesh qui a  t  g  n  r  par le script d ' exportation  -> materials : ce r  pertoire contient les textures , scripts , enfin bref infos sur l ' apparence  -> textures : placez ici votre texture  -> scripts : placez ici le fichier Scene . material g  n  r  par l ' exportation Maintenant, il va falloir dire  Ogre o trouver les fichiers. Pour cel, modifiez le fichier ressource.cfg comme suitDans cette partie, je supposerai que vous connaissez au moins les bases de OGRE, c'est  dire les premiers tutoriels du wiki officiel, au moins jusqu' la partie permettant de charger un mesh. Tout d'abord, il va falloir placer les fichiers o il faut, c'est  dire o vous voulez. Je vous conseille namoins de respecter la structure habituelle de OGRE, c'est  dire - Ogre ( un dossier dans lequel vous placerez vos mesh , par exemple dans le r  pertoire de votre jeu , o  ailleurs ).  > models : vous placerez dans ce r  pertoire le fichier Cube .001 . mesh qui a  t  g  n  r  par le script d ' exportation  -> materials : ce r  pertoire contient les textures , scripts , enfin bref infos sur l ' apparence  -> textures : placez ici votre texture  -> scripts : placez ici le fichier Scene . material g  n  r  par l ' exportation Maintenant, il va falloir dire  Ogre o trouver les fichiers. Pour cel, modifiez le fichier ressource.cfg comme suit # Resources required by the sample browser and most samples. [Essential] Zip = /usr/share/OGRE/media/packs/SdkTrays.zip FileSystem=/usr/share/OGRE/media/thumbnails # Common sample resources needed by many of the samples. # Rarely used resources should be separately loaded by the # samples which require them. [Popular] FileSystem = /usr/share/OGRE/media/fonts FileSystem=/usr/share/OGRE/media/materials/programs FileSystem=/usr/share/OGRE/media/materials/scripts FileSystem=/usr/share/OGRE/media/materials/textures FileSystem=/usr/share/OGRE/media/materials/textures/nvidia FileSystem=/usr/share/OGRE/media/models FileSystem=/usr/share/OGRE/media/particle FileSystem=/usr/share/OGRE/media/DeferredShadingMedia FileSystem=/usr/share/OGRE/media/PCZAppMedia FileSystem=/usr/share/OGRE/media/RTShaderLib # MODIFIEZ ICI : mettez le chemin des rpertoires que vous venez de crer FileSystem = /media/data/programmation/3D/ogre/media/materials/scripts FileSystem=/media/data/programmation/3D/ogre/media/materials/textures FileSystem=/media/data/programmation/3D/ogre/media/models Zip = /usr/share/OGRE/media/packs/cubemap.zip Zip=/usr/share/OGRE/media/packs/cubemapsJS.zip Zip=/usr/share/OGRE/media/packs/dragon.zip Zip=/usr/share/OGRE/media/packs/fresneldemo.zip Zip=/usr/share/OGRE/media/packs/ogretestmap.zip Zip=/usr/share/OGRE/media/packs/ogredance.zip Zip=/usr/share/OGRE/media/packs/Sinbad.zip Zip=/usr/share/OGRE/media/packs/skybox.zip [General] FileSystem = /usr/share/OGRE/media Plus qu' tester a sur un exemple, prenons celui du wiki officiel : # include \"ExampleApplication.h\" class TutorialApplication : public ExampleApplication { protected: public: TutorialApplication () { } ~ TutorialApplication () { } protected: void createScene ( void ) { mSceneMgr -> setAmbientLight ( ColourValue ( 1 , 1 , 1 ) ); Entity * ent1 = mSceneMgr -> createEntity ( \"Test\" , \"Cube.001.mesh\" ); SceneNode * node1 = mSceneMgr -> getRootSceneNode () -> createChildSceneNode ( \"TestNode\" ); node1 -> attachObject ( ent1 ); } }; # if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 # define WIN32_LEAN_AND_MEAN # include \"windows.h\" INT WINAPI WinMain ( HINSTANCE hInst , HINSTANCE , LPSTR strCmdLine , INT ) # else int main ( int argc , char ** argv ) # endif { // Create application object TutorialApplication app ; try { app . go (); } catch ( Exception & e ) { # if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 MessageBox ( NULL , e . what (), \"An exception has occurred!\" , MB_OK | MB_ICONERROR | MB_TASKMODAL ); # else fprintf ( stderr , \"An exception has occurred: %s \\n \" , e . what ()); # endif } return 0 ; } Voil, plus qu' compiler, et  lancer le programme. Normallement, sous vos yeux bahis, le cube apparait, textur tout comme il faut. Problmes Voici quelques problmes que j'ai rencontr, et comment les viter : Si l'application ne dmarre pas, vous avez probablement oubli de placer le fichier mesh Cube.001.mesh dans votre rpertoire models/, ou alors vous n'avez pas spcifi correctement sa position dans le fichier ressources.cfg Si le cube n'est pas textur, vrifiez que vous avez bien un fichier Scene.material dans votre dossier script, et que son emplacement est correctement spcifi dans le fichier ressources.cfg Amusez vous bien, et si je n'ai pas t clair, n'hsitez pas  demander des prcisions dans les commentaires.","tags":"Programmation","title":"Crez Vos Mesh Ogre Sous Blender !"},{"url":"http://arntanguy.github.io/blog/using-cmake.html","text":"Je me souviens encore des premier projets pour lesquels j'ai tent de comprendre comment utiliser cmake pour crer les makefiles. La doc est tout sauf claire, et le manque de tutoriels sur la base du fonctionnement de cmake manque cruellement. Je vais tcher de remdier  ce souci, en expliquant comment compiler des projets simples avec cmake. Qu'est-ce que cmake ? Il s'agit d'un outil permettant de ne pas avoir  crire les Makefiles  la main. Il permet de rechercher automatiquement les librairies sur le systmes, de rgler les compilation en statique ou dynamique, de compiler aisment  partir d'un dossier spar. C'est un rel plus pour la portabilit (cmake fonctionne sur de nombreux systmes, et la plupart des modules peuvent trouver les lib aussi bien sous Windows, que GNU/Linux). Cmake permet de vous affranchir de la syntaxe immonde des makefiles, et de vous contenter de dcrire la manire de compilation de votre programme, de conditionner la compilation Un cmake minimal. Tout d'abord, voici un exemple de CMakeFile.txt (c'est le fichier que cmake lit pour le convertir en makefile) permettant de compiler avec Boost. cmake_minimum_required ( VERSION 2.6 FATAL_ERROR ) # search for Boost version 1.40 # Components : #filesystem, iostreams, programoptions, python, regex, serialization, signals #system, thread, wave find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) link_directories ( ${ Boost_LIBRARY_DIRS } ) include_directories ( ${ Boost_INCLUDE_DIRS } ) SET ( SOURCES main.cpp ) SET ( EXECUTABLE_NAME executable ) add_executable ( ${ EXECUTABLE_NAME } ${ SOURCES } ) target_link_libraries ( ${ EXECUTABLE_NAME } ${ Boost_LIBRARIES } ) Comme vous pouvez le constater dans cet exemple, cmake gre les variables, et sa syntaxe est assez simple. tudions plus en dtail ce fichier. cmake_minimum_required ( VERSION 2.6 FATAL_ERROR ) Cette ligne indique qu'il faut avoir la version 2.6 de cmake pour compiler, le FATAL_ERROR est facultatif, il indique  cmake de ne pas essayer de compiler et de stopper tout de suite. find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) Il s'agit d'une des fonctionnalits les plus intressantes de cmake : la recherche des librairies. La fonctionnalit find_package va chercher un fichier (appel module), permettant de rechercher la lib voulue nomme FindBoost.cmake. Chez moi ce fichier est dans \"/usr/share/cmake-2.6/Modules/FindBoost.cmake\". (si vous ne le trouvez pas, un simple locate FindBoost.cmake devrait le trouver). Pourquoi je vous indique ces dtails sur le fichier ? Eh bien, parceque la lecture du fichier en question va vous fournir une mine d'information sur ce qu'il fait, quelles variables il dfinit, bref comment l'exploiter. Voici quelques extraits du header de ce fichier : # - Try to find Boost include dirs and libraries # Usage of this module as follows: # # == Using Header-Only libraries from within Boost: == # # find_package( Boost 1.36.0 ) # if(Boost_FOUND) # include_directories(${Boost_INCLUDE_DIRS}) # add_executable(foo foo.cc) # endif() # # # == Using actual libraries from within Boost: == # # set(Boost_USE_STATIC_LIBS ON) # set(Boost_USE_MULTITHREADED ON) # find_package( Boost 1.36.0 COMPONENTS date_time filesystem system ... ) # # if(Boost_FOUND) # include_directories(${Boost_INCLUDE_DIRS}) # add_executable(foo foo.cc) # target_link_libraries(foo ${Boost_LIBRARIES}) # endif() # # # The components list needs to contain actual names of boost libraries only, # such as \"date_time\" for \"libboost_date_time\". If you're using parts of # Boost that contain header files only (e.g. foreach) you do not need to # specify COMPONENTS. # # You should provide a minimum version number that should be used. If you provide this # version number and specify the REQUIRED attribute, this module will fail if it # can't find the specified or a later version. If you specify a version number this is # automatically put into the considered list of version numbers and thus doesn't need # to be specified in the Boost_ADDITIONAL_VERSIONS variable (see below). # # NOTE for Visual Studio Users: # Automatic linking is used on MSVC &amp; Borland compilers by default when # #including things in Boost. It's important to note that setting # Boost_USE_STATIC_LIBS to OFF is NOT enough to get you dynamic linking, # should you need this feature. Automatic linking typically uses static # libraries with a few exceptions (Boost.Python is one). # # Please see the section below near Boost_LIB_DIAGNOSTIC_DEFINITIONS for # more details. Adding a TARGET_LINK_LIBRARIES() as shown in the example # above appears to cause VS to link dynamically if Boost_USE_STATIC_LIBS # gets set to OFF. It is suggested you avoid automatic linking since it # will make your application less portable. [...] # Variables used by this module, they can change the default behaviour and # need to be set before calling find_package: # # Boost_USE_MULTITHREADED Can be set to OFF to use the non-multithreaded # boost libraries. If not specified, defaults # to ON. # # Boost_USE_STATIC_LIBS Can be set to ON to force the use of the static # boost libraries. Defaults to OFF. # # Other Variables used by this module which you may want to set. # # Boost_ADDITIONAL_VERSIONS A list of version numbers to use for searching # the boost include directory. Please see # the documentation above regarding this # annoying, but necessary variable <img src=\"http://s0.wp.com/wp-includes/images/smilies/icon_sad.gif?m=1129645325g\" alt=\":(\" class=\"wp-smiley\"> # [...] # # Boost_INCLUDE_DIRS Boost include directories: not cached # # Boost_INCLUDE_DIR This is almost the same as above, but this one is # cached and may be modified by advanced users # # Boost_LIBRARIES Link to these to use the Boost libraries that you # specified: not cached # # Boost_LIBRARY_DIRS The path to where the Boost library files are. # # Boost_VERSION The version number of the boost libraries that # have been found, same as in version.hpp from Boost [...] # Boost_${COMPONENT}_FOUND True IF the Boost library \"component\" was found. # # Boost_${COMPONENT}_LIBRARY Contains the libraries for the specified Boost # \"component\" (includes debug and optimized keywords # when needed). Grce aux informations contenues ici, on pourra facilement construite un CMakeFile adapt  nos besoins. Revenons  l'exemple : find_package va utiliser le fichier indiqu plus haut pour rechercher boost, le module va dfinir de nombreuses variable (comme on voit dans le header ci-dessus), que l'on va utiliser pour la compilation. find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) link_directories ( ${ Boost_LIBRARY_DIRS } ) include_directories ( ${ Boost_INCLUDE_DIRS } ) k La ligne link_directories indique que cmake devra lier l'excutable avec la librairie boost, ${Boost_LIBRARY_DIRS} tant une variable dfinie par le module appel par find_package. La ligne include_directories fait de mme pour le rpertoire dans lequel les includes de boost sont. SET ( SOURCES main.cpp autre.cpp ) SET ( EXECUTABLE_NAME executable ) On dfinit 2 variables SOURCES et EXECUTABLE_NAME, comme a on aura juste  modifier  un seul endroit, et tout le reste sera modifi en consquence. add_executable ( ${ EXECUTABLE_NAME } ${ SOURCES } ) target_link_libraries ( ${ EXECUTABLE_NAME } ${ Boost_LIBRARIES } ) add_executable indique  cmake qu'il faut compiler les sources contenues dans la variable SOURCE et crer un excutable nomm par le nom dfini dans la variable EXECUTABLE_NAME target_link_libraries indique  cmake avec quelles librairies il doit lier. Et voil, vous avez un CMakeList pour compiler avec boost. mkdir build && cd build cmake .. make Et voil, les sources sont compils dans le dossier build.","tags":"Programmation","title":"Using CMake"},{"url":"http://arntanguy.github.io/blog/fotowall-09.html","text":"Fotowall 0.9 est enfin sorti ! Pour ceux qui ne le saurait pas encore, Fotowall permet de crer un \"patchwork\" de photos (les assembler, ajouter des effets, cadres) Nouveauts Un espace de travail simple, robuste et intgr avec un cran d'accueil. Nouveaux contenus : Canevas et \"Nuage de mots\" [Wordcloud] Effets graphiques Systme de commentaires [Likeback] Canvevas zommable, avec des barres de dfilement (enfin) Plus de 250 autres changements: Autoblend Effect for images SVG export Quick and improved property editors Cursor key movement OpenGL performance tests and auto-tuning Google Images search (by Marco Bavagnoli, reqby. Rossana) Cleanups and Refactors: Selection, Frames, Rendering, Backgrounding, DVD/CD, Print/Export Fixed relative saving (with contents auto-search) Fixed multiple Webcams and bad Colors Fixed the Exact Size modes Fixed licensing Pour le tlcharger, c'est par ici .","tags":"FotoWall","title":"FotoWall 0.9"},{"url":"http://arntanguy.github.io/blog/psp-slim-200-chicken-custom-firmware-gen-b.html","text":"J'ai pas mal galr pour avoir ma PSP Slim 2000 fonctionnelle avec un custom firmware pour pouvoir lancer des homebrew (applications non officielles), notamment bookr permettant de lire des pdf. Installer chickhen r2 Tout d'abord, qu'est-ce que chickhen ? Il s'agit d'un hack exploitant une faille de la lib tiff de la psp pour permettre le lancement d'homebrew. Une fois chickhen \"install\", une bonne partie des homebrews pourront tre lancs. Il n'y a aucun risque pour la psp  installer chicken, en effet celui-ci n'est pas rellement install, la mmoire flash de la psp n'est pas modifi. Chickhen est seulement charg en mmoire, ce qui signifie que si vous teignez totalement la psp (en maintenant le bouton off quelques secondes), il faudra le rinstaller, heureusement, cette tape est trs simple. Tlchargez Chickhen Placer le dossier Chickhen dans le dossier PSP/PHOTO Placer le fichier h.bin  la racine de votre PSP Dbrancher la psp, mettez l'adaptateur wlan sur on (a ne fonctionne pas sinon, en tout cas avec ma psp), assurez vosu que le son n'est pas coup, puis allez dans le menu Photo->memory stick, et faites croix sur le dossier Chickhen. L, ne touchez plus  rien, ne scrollez pas, attendez quelques secondes. Il y aura un cran vert qui va apparatre, et la psp va redmarrer. Il se peut que a ne fonctionne pas si la psp est en franais, si c'est le cas, mettez la en anglais (ce que j'ai fait). Vrifiez que c'est bien install, en allant dans le menu Settings->System Information, vous devriez voir 5.03 ChickHEN R2 L, normalement la plupart des homebrews devraient se lancer, mais a serait dommage de s'arrter en si bon chemin. Installer le custom firmware 5.03 gen B Il s'agit d'un hack du systme d'exploitation de la PSP pour lui ajouter des fonctionnalits et dbloquer des choses dlibrment bloques par la psp (pour viter le piratage des jeux par exemple). Il permettra de lancer les homebrews, les jeux au format iso, cso, boot Vous pouvez convertir vos UMD en iso sur votre PSP grce  ce firmware. Quel intrt ? Temps de chargement plus rapide, consommation de batterie plus faible, vos UMD ne sont pas abims. L'installation est explique assez clairement sur pspgen , je ne vais donc pas le refaire ici. Informations complmentaires sur l'utilisation. Vous pouvez accder au recovery menu, ainsi qu'au gen vsh menu, permettant de configurer la psp en appuyant sur la touche Select. Si vous dsirez lancer des jeux en iso, il est conseill de mettre UMS ISO MODE sur Sony NP9960. Si votre iso ne foncitonne pas, essayez M33 driver. J'espre que ce billet permettra d'claircir l'installation du custom firmware. Pour l'installer, j'ai t oblig de faire de nombreuses recherches, sur de nombreux sites/forum, alors que c'est extrmement simple et sur (j'avais peur de bricker ma psp, et il m'a fallu voir plusieurs sites pour tre convaincu que le flash0 n'tait pas touch).","tags":"Random","title":"Psp SLIM 200 Chicken & Custom Firmware Gen B"},{"url":"http://arntanguy.github.io/blog/vim-my-configuration.html","text":"Tant qu' m'tre fait un vim qui me convient  peu prs, je me suis dit que a pourrait tre bien de partager a. J'utilise un gestionnaire de version (git) pour suivre l'volution de ma configuration, le dpt contenant le tout est disponible sur github . Actuellement ma configuration permet : De programmer en c++ : Alternate (:A) pour passer des .cpp aux .h, Surround pour grer les parenthses, matchit pour tendre la commande \"%\" (permettant de passer de la parenthse ouvrante  la fermante)  plus d'lments (balises xml), NerdCommenter pour grer les commentaires, DoxygenToolKit pour grer la documentation. Et le plugin le plus important : OmniCppComplete qui permet de complter le code plus intelligemment que Ctrl+N (notemment en utilisant les fichiers tags, que j'ai ralis pour Qt et boost sur mon ordi). De faire de latex : la latex-suite est installe. Il y a d'autres plugins intressant, comme Arpeggio par exemple. Arpeggio permet d'utiliser des raccourcis en pressant simultanment plusieurs touches. Par exemple, en ajoutant la ligne suivante dans le .vimrc call arpeggio#map('i', '', 0, 'jk', '') a cr un raccourcis en mode insertion, de sorte que \"jk\" presss simultanment sortent du mode insertion, et que \"j\" et \"k\" presss sparment aient toujours le mme effet. Si vous dcidez d'utiliser ma configuration, tlchargez l  l'adresse indique plus haut, puis placez le contenu du dossier dans ~/.vim. Ensuite, dplacez le vimrc dans ~/.vimrc et gvimrc dans ~/.gvimrc. J'ai rdig un mini aide mmoire pour moi, faites dans vim : h arnaud ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ arnaud.txt Arnaud Vim Config 2009-06-21 Author: TANGUY Arnaud < arn . tanguy @ gmail . com > Copyright:  Copyright 2009 TANGUY Arnaud . All Rights Reserved . Licence GNU GPL v2 or later ( at your option ) ============================================================================== 1. Contents * arnaud * * arnaud - contents * {{{ 1 1. Contents ................................. : | arnaud - contents | 2. Key - mappings ............................. : | a - keys | 3. Plugins .................................. : | a - plugins | OmniCppComplete ........................ : | a - omnicppcomplete | Project ................................ : | a - project | SearchInRuntime ........................ : | a - searchinruntime | Surround ............................... : | a - surround | Alternate .............................. : | a - alternate | ManPageView ............................ : | a - manpageview | Matchit ................................ : | a - matchit | NERD_Commenter ......................... : | a - nerdcommenter | PhpDocumentor .......................... : | a - phpdocumentor | DoxygenToolkit ......................... : | a - doxygen | Markdown ............................... : | a - markdown | Indent Guides .......................... : | a - indent - guides | ============================================================================== 2. Key mappings * a - key * * a - keys * {{{ 1 , cd cd to the directory of the current view < F6 > SearchInVar and open in the current view < F7 > SearchInVar and open in a new tab < F1 > Project open the project window < F2 > Ctags rebuild . In insert and normal modes < F9 > Build the file or project . It ' s a ftplugin , so it may not be mapped in every mode < C - D > Generate doc for a function ( or class ). It is used by ftplugins , at least the php one . 3. Plugins * a - plugins * * a - plugin * {{{ 1 OMNICPPCOMPLETE * a - omnicppcomplete * {{{ 2 Omnicppcomplete is a completition plugin . It completes the code , maily the c ++ ones . It is based on ctags , so it requires a tags file , which can be created with: ctags - R -- c ++- kinds =+ p -- fields =+ iaS -- extra =+ q . Then , the autocompletition is with < C - x >< C - o > ( automatically called in my config ) See | omnicppcomplete . txt | PROJECT * a - project * * a - projects * {{{ 2 A project managment plugin . It allows to remember the project structures , and re - open it easily . - \\ c creates a new project - : w saves it - SPACE grow / reduce the project window See | project . cpp | SEARCHINRUNTIME * a - searchinruntime * * a - SIR * {{{ 2 Search a file name or a variable in the PATH . It provides an easy way to load files . See | searchInRuntime . txt | SURROUND * a - surround * {{{ 2 It is a plugin to surround text with caracters like {,(, \"... - cs ({ : replace (...) with { ... } cs (} : replace (...) with {...} ( without spaces ) cs { < q > : replace {...} with < q > ... </ q > - ds { : delete {} - ys [ text element ]{ : surround text element with {} Example : \"_Hello dear friends\" ys2w [ will give you \"[ Hello dear ] friends\" - Visual selection surrounding : press V or v , and then select text . Press S and type your surrounding character ( it can be html tags ). See | surround . txt | ALTERNATE * a - alternate * {{{ 2 Switch between . h and . cpp (. hpp / . cpp . h / . c and so on ). MANPAGEVIEW * a - manpageview * {{{ 2 View php man pages . It requires links to work . Call it with K as for unixes man pages MATCHIT * a - matchit * {{{ 2 It allows you to configure % to match more than just single characters . You can match words and even regular expressions . Also , matching treats strings and comments ( as recognized by the syntax highlighting mechanism ) intelligently . The default ftplugins include settings for several languages : Ada , ASP with VBS , Csh , DTD , Essbase , Fortran , HTML , JSP ( same as HTML ), LaTeX , Lua , Pascal , SGML , Shell , Tcsh , Vim , XML . ( I no longer keep track , so there may be others .) The documentation ( included in the zip file ) explains how to configure the script for a new language and how to modify the defaults . See | matchit . txt | NERDCOMMENTER * a - nerd * * a - nerdcommenter * {{{ 2 Nerd commenter allow to comment code according to the file type . The most useful mappings are : , cc | NERDComComment | Comments out the current line or text selected in visual mode . , cy is the same , but yank before commenting , cl OR , cr OR , cb | NERDComAlignedComment | Same as | NERDComComment | except that the delimiters are aligned down the left side (, cl ), the right side (, cr ) or both sides (, cb ). , cI | NERDComPrependComment | , cA | NERDComAppendComment | Comment before / after the current line . Adds comment delimiters to the end of line and goes into insert mode between them . , c < space > | NERDComToggleComment | Toggles the comment state of the selected line ( s ). If the topmost selected line is commented , all selected lines are uncommented and vice versa . , cu | NERDComUncommentLine | Uncomments the selected line ( s ). , cm | NERDComMinimalComment | Comments the given lines using only one set of multipart delimiters if possible . , ci | NERDComInvertComment | Toggles the comment state of the selected line ( s ) individually . Each selected line that is commented is uncommented and vice versa . , cs | NERDComSexyComment | Comments out the selected lines `` sexily '' . Useful for doc , headers ... , ca | NERDComAltDelim | /*Switches to the alternative set of delimiters.*/ See | NERDCommenter | PHPDOCUMENTOR * a - phpdocumentor * * a - phpd * {{{ 2 PhpDocumentor is a plugin for generating phpDocumentor documentation blocs . In my configuration , it is called with < C - P > , in every mode . DOXYGEN * a - doxygen * {{{ 2 It is a plugin for autocreatin doxygen commenting blocs . Move on a function declaration , and : Dox or < C - P > See http : //www.vim.org/scripts/script.php?script_id=987 for more details and configuration variables MARKDOWN * a - markdown * {{{ 2 Mappings: the following work on normal and visual modes : - ]] : go to next header - [[ : go to previous header - ][ : go to next sibling header if any - [] : go to previous sibling header if any - ] c : go to Current header - ] u : go to parent header ( Up ) INDENT GUIDES * a - indent - guides * {{{ 2 Activate with < Leader > ig (, ig ) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~","tags":"Programmation","title":"VIM : My configuration"},{"url":"http://arntanguy.github.io/blog/vim-un-essai-de-plugin-pour-la-compilation-c.html","text":"J'aime beaucoup utiliser vim pour programmer (je n'ai jamais russi  me faire  la faon de penser d'emacs et vim me convient trs bien une fois configur), mais jusqu'ici une chose me chagrinait, la compilation en c++. Les principaux points qui me drangeaient taient : La liste des erreurs de compilations qui ne reste pas La difficult pour compiler  partir d'un autre dossier. J'utilise beaucoup ceci, notemment avec l'excellent cmake qui permet de raliser simplement une compilation dans un dossier spar. Je ne savais pas trop comment faire d'extensions pour vim, je me suis dit que c'tait l'occasion de voir. J'ai donc fait un petit plugin qui rsoud partiellement ces dfauts. Il permet de Compiler  partir du dossier courant, ou d'un autre dossier Laisser la fentre de compilation (utilisation de quickfix) ouverte, et ainsi, sauter facilement aux erreurs * Et en prime, d'ajouter automatiquement une bonne partie des includes manquants ! Cette fonctionnalit est assez bancale, et ne fonctionne quand dans les cas ou le nom de la classe est le mme que le nom du fichier la contenant, ce qui correspond  mon style de programmation. L'ajout des includes se fait de faon relativement intelligente : si il y a dj des includes, c'est ajout  cet endroit, sinon, le plugin essaye de trouver la fin du header et place les includes aprs. Au pire, on peut spcifier une ligne pour l'ajout. Installation Il suffit de placer le script suivant dans le dossier ~/.vim/ftplugin/cpp, je l'ai nomm make.vim (vous pouvez mettre le nom que vous voulez, tant qu'il a l'extension .vim). \" Copyright (C) 2008 TANGUY Arnaud <arn.tanguy@gmail.com> \" * \" This program is free software; you can redistribute it and/or modify * \" it under the terms of the GNU General Public License as published by * \" the Free Software Foundation; version 3 of the License * \" * \" This program is distributed in the hope that it will be useful, * \" but WITHOUT ANY WARRANTY; without even the implied warranty of * \" MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the * \" GNU General Public License for more details. * \" * \" You should have received a copy of the GNU General Public License along * \" with this program; if not, write to the Free Software Foundation, Inc., * \" 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. * \"******************************************************************************/ \" \" This is my first vim plugin, so there might be errors or inaccuracies. If \" you see some mistakes, please let me know. \" \" *************** DESCRIPTION ********************** \" This is a make plugin for cpp files. It makes, and parse the results to add \" usefull informations, such as auto-include headers. \" \" **************** FEATURES ************************ \" Features wished but not implemented yet: \" - Auto add includes after compilation (works fine, at least for Qt). \" But : File names must be named like the class. I.e if you have a class \" named TestClass, then the file name must be TestClass.h TestClass.hpp or \" TestClass \" When other includes are already presents: add the includes with them \" Otherwise, guess where to add includes : after the header, or at a default \" position. \" - Show the quickfix window \" \" *************** CONFIGURATION ***************** \" g:default_includes_line the number of the default include line. It is \" used when not better place is found \" g:quickfix_size The number of lines of the quickfix window \" \" ************** TODO ******************* \" - Auto (or ask?) add pre-declaration (class Type;) in the header, and the include in \" the .cpp file. To switch beetween files, use a.vim plugin. \" - Seek for innacuracies, and fix them. Optimize too... let s :cpo_save = & cpo set cpo & vim \" Do not reload if already loaded if exists ( 'g:loaded_make_plugin' ) \\ && ! exists ( 'g:force_reload_make_plugin' ) finish endif let g :loaded_make_plugin = 1 \" Global variables initialisation (if not already set) if ! exists ( 'g:quickfix_size' ) let g :quickfix_size = 6 endif \" Function : SortUnique \" Purpose : Works like sort(), optionally taking in a comparator \" (just like the original), except that duplicate entries will be removed. \" Args : A list, and optionally a comparator \" Returns : The sorted list \" Author : Unknown, found on http://vim.wikia.com/wiki/Unique_sorting function ! SortUnique ( list , ... ) let dictionary = {} for i in a : list execute \"let dictionary[ '\" . i . \"' ] = ''\" endfor let result = [] if ( exists ( 'a:1' ) ) let result = sort ( keys ( dictionary ), a : 1 ) else let result = sort ( keys ( dictionary ) ) endif return result endfunction \" Function : RemoveMatching \" Purpose : Delete items in a list, when they are matching items in an \" another list \" Args : listRef: The list from which you want to remove items \" listMatch: The list to compare with \" Returns : The listRef, without matched items \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> \" Note : This can surely be improved, but I still don't know much viml function ! RemoveMatching ( listRef , listMatch ) let i = 0 let ref_list = copy ( a :listRef ) while i < len ( ref_list ) for j in a :listMatch if ref_list[ i ] == j call remove ( ref_list , i ) endif endfor let i += 1 endwhile return ref_list endfunction \" Function : GetMissingIncludes (PRIVATE) \" Purpose : Find the missing includes in the compilation error list \" Args : None \" Returns : Nothing \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> \" TODO : Check if the include is in the path, otherwise, ask the user to \" know what to do. \" Is there all possible related errors messages here ? Let me know \" if it is not the case function ! s :GetMissingIncludes () \" Get the quickfix errors let errors = getqflist () let includes = [] \" To avoid some errors with variables names let not_includes = [] let l : count = 0 for i in errors if ( i [ \"text\" ] =~ \".* was not declared in this scope\" ) \" Find the possible name in the error \"let include = substitute(i[\"text\"], '.*error:..\\(.*\\)..was not declared in this scope', '\\1', 'g') let includes += [substitute ( i [ \"text\" ] , '.*error:..\\(.*\\)..was not declared in this scope' , '\\1' , 'g' ) ] \" Check if it is really a type, and not a variable name \"let nextError = errors[l:count + 1][\"text\"] \"if(nextError =~ \".* expected .;. before .*\") \"let not_includes += [substitute(nextError, '.* expected .;. before .\\(.*\\).', '\\1', 'g')] \"let includes += [include] \"endif elseif ( i [ \"text\" ] =~ \".*variable .* has initializer but incomplete type\" ) let includes += [substitute ( i [ \"text\" ] , '.*variable .\\(.*\\) .* has initializer but incomplete type' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* aggregate .* has incomplete type and cannot be defined\" ) let includes += [substitute ( i [ \"text\" ] , '.* aggregate .\\(.*\\) .* has incomplete type and cannot be defined' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* has not been declared\" ) let includes += [substitute ( i [ \"text\" ] , '.* .\\(.*\\). has not been declared' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* incomplete type .* used in nested name specifier\" ) let includes += [substitute ( i [ \"text\" ] , '.* incomplete type .\\(.*\\). used in nested name specifier' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* invalid use of incomplete type .*\" ) let includes += [substitute ( i [ \"text\" ] , '.* invalid use of incomplete type .struct \\(.*\\).' , '\\1' , 'g' ) ] endif let l : count += 1 endfor \" Return the found includes name, and sort them, remove doubles let tmpReturn = RemoveMatching ( includes , not_includes ) let tmpReturn = SortUnique ( tmpReturn ) return s :CheckInPath ( tmpReturn ) endfunction \" Function : CheckInPath \" Purpose : Check if an include exists in path \" Args : The includes names list \" Returns : A dictionnary of the found entry : \" \"global\" => List : The global entry (those included with \" #include <...>) \" \"local\" => List : The local entry (those included with \" #include \"...\" \" \"unmatched\" => List : The includes not found \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function ! s :CheckInPath ( includesList ) let includes = copy ( a :includesList ) let results = { \"global\" : [] , \\ \"local\" : [] , \\ \"unmatched\" : [] } for inc in includes let mpath = \"**,/usr/include/**\" let found = findfile ( inc , mpath ) if found != \"\" let results[ \"global\" ] += [ inc ] else \" XXX : strange, why regex don't works with findfile ? let found = findfile ( inc . \".h\" , mpath ) if ( found != \"\" ) let results[ \"local\" ] += [found] else let found = findfile ( inc . \".hpp\" , mpath ) if found != \"\" let results[ \"local\" ] += [found] else let results[ \"unmatched\" ] += [ inc ] endif endif endif endfor for i in results[ \"global\" ] echomsg \"global : \" . i endfor for j in results[ \"local\" ] echomsg \"local : \" . j endfor for h in results[ \"unmatched\" ] echomsg \"unmatched : \" . h endfor return results endfunction \" Function : SeekPosition \" Purpose : Find the best position where the includes will be placed \" Args : None \" Returns : The found line \" Author : TANGUY Arnaud function ! s :SeekPosition () exe \"normal gg\" \" Seek the existing includes, to add it here if they exists let line = search ( \"&#94;#include\" ) if line > 0 return line endif \" Otherwise, find a default location. Usually, C files are written with a \" header, and space is left between header and code. So, we'll seek the \" first line without anything but white character on it let line = search ( '&#94;\\( ?\\)*$' ) if line > 0 return line endif \" If not found, set a default value if exists ( \"g:default_includes_line\" ) return g :default_includes_line else return 1 endif endfunction \" Function : AddIncludes (PRIVATE) \" Purpose : Add the includes given in args in the file \" Args : includesDict: A list containing the includes name and type \" \"global\" => global includes \" \"local\" => local includes \" \"unmatched\" => not found, so ask \" Returns : Nothing \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function s :AddIncludes ( includesDict ) if ( len ( a :includesDict ) > 0 ) let l = s :SeekPosition () for include in a :includesDict[ \"local\" ] exe \"normal \" . l . 'GO#include \"' . include . '\"' endfor for inc in a :includesDict[ \"global\" ] exe \"normal \" . l . 'GO#include <' . inc . '>' endfor for i in a :includesDict[ \"unmatched\" ] echomsg \"unmatched \" . i endfor \" Once the includes are added, rebuild silent ! execute & makeprg endif endfunction \" Function : MyMake \" Purpose : Build a cpp project, using make, and doing some more cool stuff. \" This function call everything needed for this plugin : autoadd \" includes... \" Args : None \" Returns : 1 if path1 is equal to path2, 0 otherwise. \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function ! s :MakeIncludes ( dir ) \"exe &makeprg call s :Make ( a : dir ) let includes = s :GetMissingIncludes () call s :AddIncludes ( includes ) endf \" Function : s:Make \" Purpose : \" Args : \" Returns : \" Author : TANGUY Arnaud function s :Make ( dir ) \" Save the old directory, and go to the new one let olddir = getcwd () if ( a : dir != \"\" ) execute \":lcd \" . a : dir endif silent ! exe & makeprg execute \":lcd \" .olddir let winnum = winnr () \" get current window number \" g:quickfix_size lines big for the quickfix window exe \"cope \" . g :quickfix_size \" Open the quickfix window cw \" Go to the first error execute winnum . \"wincmd w\" endfunction com ! - nargs = 0 Mi call s :MakeIncludes ( \".\" ) com ! - nargs = 0 Mid call s :MakeIncludes (< args >) com ! - nargs = 0 Mm call s :Make ( \".\" ) \" Make in an other directory com ! - nargs = 1 Mmd call s :Make (< args >) let & cpo = s :cpo_save Utilisation Le script s'utilise en mode commande: :Mm compile dans le dossier courant :Mmd \"build/\" compile dans le sous dossier. Vous devez mettre le chemin du dossier de compilation dans les guillemets. Le chemin peut tre relatif ou absolu. :Mi compile et ajoute les includes :Mid \"build/\" compile dans un autre dossier, et ajoute les includes Il s'agit de mon premier plugin vim, par consquent il est probablement cod maladroitement par moments. La fonctionnalit permettant d'ajouter automatiquement des includes est loin d'tre parfaite, il se peut que vous ayez besoin d'en ajouter manuellement. Parfois, trop d'includes sont ajouts (par exemple quand un include en inclut un autre, les 2 sont quand mme ajout alors que ce n'est pas ncessaire). Ce systme fonctionne bien avec le framwork Qt avec lequel je travaille beaucoup. J'essayerai d'amliorer a  l'occasion, pour l'instant a me suffit pour compiler. Une chose que j'aimerai faire, c'est pouvoir faire une compilation non bloquante : pouvoir continuer  utiliser vim durant le temps de compilation, mais a me semble assez compliqu","tags":"Programmation","title":"VIM : Un Essai de plugin pour la compilation C++"},{"url":"http://arntanguy.github.io/blog/fotowall-100-000.html","text":"Aujourd'hui, Fotowall a atteind les 100 000 tlcharments ! C'est un rsultat impressionnant, et c'est encore plus incroyable en considrant que nous n'avons pas de page d'accueil, pas de publicit autre que le bouche  oreille. Et ces tlchargements ne concernent que la version XP/Vista. Il est trs difficile d'valuer le nombre d'utilisateurs parmis les autres sytmes, en particulier GNU/Linux avec les divers gestionnaires de paquets, clones git, installations  partir des sources Rien que sur kde-apps , on dnombre plus 5183 tlchargements, il semble donc que Fotowall rencontre un certain succs auprs des utilisateurs de logiciel libres. Pour clbrer ce rsultat, voici une petite vido de la prochaine version (qui sortira d'ici une semaine) : Un grand merci  toute l'quipe : Enrico Ros, Arnaud Tanguy , Alessandro Portale, Andreas Brech, Georges Dubus, ainsi qu'aux traducteurs Martin Zimmermann and Marcio Moraes.","tags":"FotoWall","title":"FOTOWALL : 100 000 !"},{"url":"http://arntanguy.github.io/blog/fotowall-07.html","text":"FotoWall est un logiciel libre disponible sous licence GPL dvelopp par Enrico Ros et moi-mme. Il vous permet de prsenter simplement vos photos, en les disposant aisment, appliquant des transformations (rotations, perspectives, effets). Nous venons de raliser une nouvelle version, d'o cet article pour vous faire dcouvrir FotoWall pour ceux qui ne connaissent pas, et informer les autres. Voici la liste des principales fonctionnalits (non exhaustive) : disposer facilement vos images redimensionner, faire pivoter des images appliquer des effets aux images : niveau de gris, noir et blanc, inverser les couleurs, contrastes chaque image peut tre enregistre sparment, ce qui permet d'utiliser ce logiciel pour d'autres usages que celui initial. mettre la photo dans un \"cadre\" (cur, carr color). imprimer un poster (grce au logiciel libre posterazor). imprimer vos crations au format voulu (taille relle, cd, dvd) faire une recherche sur flickr Pour installer fotowall sous Ubuntu, suivez les instructions de la documentation Ubuntu-fr . La mthode est similaire pour les autres systmes. Les utilisateurs de Windows trouverons un xcutable sur google code","tags":"FotoWall","title":"FotoWall 0.7"}]}