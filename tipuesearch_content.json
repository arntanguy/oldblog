{"pages":[{"url":"http://arntanguy.no-ip.org/pages/links.html","text":"Plenty of really good cheat sheets http://www.cheat-sheets.org/ C++ C++ 11 - Features every C++ Developper Should Know Network Set up a virtual wifi access point","tags":"pages","title":"Links"},{"url":"http://arntanguy.no-ip.org/multi-layered-perceptron-using-opencl.html","text":"I recently discovered neural networks , and I was instantly very interested by the topic. I am a big fan of computer vision, and have always had a feeling that this field was doomed by the sheer amount of possible combinations possible. How could we ever come up with an algorithm that wouldn't crash at the first unexpected input? How can we analyse complex behaviour, such as distinguishing distress in a metro when so much trivial noise and movements are going on? How could we ever get robots intelligent enough to cope with their environment as well, or even better than we do? I believe I'm starting to see a glimmer of hope in neural networks, that we could one day achieve such things, that at the moment seem like a daunting task. Of course a perceptron is way too simple a network for such things, but one has to start somewhere, hasn't he? I am convinced that it is utterly useless to read thousands of pages on neural networks to try and understand their behaviour. The best way to approach them is by trial and error. In this article, I will show you what a perceptron is, how to implement and train it using GPU computing with OpenCL . What is a perceptron A perceptron is basically a binary classifier: it will either tell you that the input values you provided match with the model it that has previously been learnt, or tell you that they don't. That is for a single output neuron. By providing several outputs, it is possible to use the perceptron as a classifier, effectively separating the input set in several classes. So basically, it is a linear classifier . You're probably wondering what you have to gain using a perceptron instead of SVM (Support Vector Machine), or similar algorithm. Well, actually not much. The perceptron was discovered before SVM was developped, and since then, SVM has pretty much replaced all uses of the perceptron. Even though, the perceptron can be seen as the very basis of neural networks, and is a stepping stone on which one has to walk on in order to fully understand the concepts behind neural network algorithms. As all neural networks, it requires a great amount of inter-connected neurons to provide enough capacity to learn a given model. It is thus a challenge to use a perceptron to accomplish complicated classification in real-time. Also, the training task can be a daunting computation, that might have to be ran loads of time before fine-tuning the training to achieve the expected outcome. A fully-connected perceptron is probably the simplest neural network you could ever think of. It is composed of several layers, each containing a given number of neurons. Each neuron of a layer is connected to every single neuron of the following layer. Each connection has an associated weight. It is by adjusting these weights that the network will tune himself to any linear classification problem, of course given that the network has enough complexity for the given problem (i.e has a sufficient number of neurons and layers for it to be able to learn the model). There are three types of layers: The input layer : it is the first layer, where you set the initial data that your perceptron will be working on. The hidden layers : these are all the layers between the input and output layer. They're basically the ones that will be doing all the work of learning a model and computing input values against the model in order to classify them. The output layer : composed of one or several neurons. This layer represents the result of the classification, where each neuron represent a specific class. Each neuron value in the hidden layers and the output layer is computed as the weighted sum of all the neurons' values linked to it by the weights linking them together. Hopefully, neural networks are generally highly parallel algorithm , and the perceptron is probably their king. In this article, I will present how to implement a fully-connected perceptron using OpenCL . This article will explain in detail the training algorithm, along with its naive implementation. A later article will discuss a faster training algorithm, and optimizations to the kernel presented here. Training algorithm : gradient backpropagation Training a perceptron is a minimization problem. We define a training set as a set of (input -> output) values. The goal of the training is to find the weights that minimize the distance between the output computed by the perceptron on the output corresponding to the same input in the training set. In this article we'll train a perceptron that is able to recognise a xor operation. First of all, here is the xor truth table: a b xor(a,b) 0 0 0 0 1 1 1 0 1 1 1 0 So the goal of the training will be to find the weights needed for the perceptron to give the correct output for all possible inputs a and b of the truth table. In order to train the weights, we will use an algorithm based on a gradient descent. First, let us define some notations: \\(n\\) : number of cells in layer, designed by an index \\(i\\) with \\(0 <= i <= n\\) \\(q\\) : number of layers \\(k\\) : index of an output cell \\(c_k\\) : expected output for output cell k for entry x \\(o_k\\) : computed output for output cell k for entry x \\(x_{ij}\\) : input value associated with link between cell i towards cell j \\(w_{ij}\\) : weight Succ(i) : set of cells that have the output of cell i as an input Pred(i) : set of cells whose output is an input of cell i \\(y_i\\) : weighted sum of cell i $$y_i = \\sum{w_{ij}x_{ij}}$$ \\(o_i\\) : output of cell i $$o_i = \\sigma(y_i)$$ where \\(\\sigma\\) is the sigmoid function: $$\\sigma(x) = \\frac{1}{1+e&#94;{-x}}$$ \\(S\\) : Learning set Before getting deeper into the algorithm, let's just give an overview of what we'll have to do. First, we need to compute the value of every single neuron from the input to the output layer. Once we have that, we can compare the output with the expected output, and compute the gradient \\(\\delta\\) for the output layer. Then, we compute \\(\\delta\\) for every layer based on the value of the following layer. This is a process called backpropagation. Finally we update the weight values using the neuron's and \\(\\delta\\) values previously computed. The algorithm goes as follow : Randomly initialize all weights in interval \\([-0.5, 0.5]\\) Repeat until convergence Pick example \\((x, c)\\) in \\(S\\) (x: input value, c: expected output) Compute output \\(o\\) for input \\(x\\) For each output cell \\(i\\) (in output layer) Compute \\(\\delta_i\\) for each cell of the output layer: $$\\delta_i = \\sigma'(y_i)(c_i-o_i) = o_i(1-o_i)(c_i-o_i)$$ For each layer from \\(q-1\\) to \\(1\\) Compute \\(\\delta_i\\) for each cell of the current layer: $$\\delta_i = \\sigma'(y_i)\\sum_{k\\in\\text{Succ(i)}}{\\delta_k w_{ki}} = o_i(1-o_i)\\sum_{k\\in\\text{Succ(i)}}{\\delta_k w_{ki}}$$ Update weights: for each weight \\(w_{ij}\\) $$w_{ij} = w_{ij} + \\epsilon \\delta_i x_{ij}$$ Note on thresholding The values of each layer need to be thresholded. To do so, we add a \"virtual neuron\", called bias in each layer, with a fixed value of 1. By updating the associated weights as well, this neuron can be used as an automatic threshold. Implementation Core structure We have to be able to create an arbitrary number of layers, each containing an arbitrary number of neurons. Each layer must be connected to the following layer for execution, but also to the previous layer for the training phase (backpropagation). Thus, the perceptron data structure will be implemented as a double-linked list of layers. Thus, we create two main classes: PerceptronLayer : represents a layer of the network. Each layer is composed of: an array of neuron values. an array representing the weights from this neuron to all neurons of the next layer. a pointer to the next layer a pointer to the previous layer Perceptron : manages the creation/removal of layers, training, execution of the network. It only needs to store a pointer to the first and last layers. OpenCL We are now going to see how this can be implemented using OpenCL. This section depicts a very raw and poorly implemented version of the algorithm. It is only meant to be kept simple so that it provides a clear basis onto which further optimisations can be thought of. First, let's start with the execution part of the network. Execution The execution is really straightforward. It is just a matter of computing the new value of each neuron based on the weighted sum of all neurons from the previous layer. Thus, the kernel will take as input the weights and values for each input neuron (neurons from the previous layer), and will have as output an array containing the new values of the neurons in the current layer. The kernel is thus ran in order on the 2nd, 3rd.... Nth layer. The following kernel can be used to compute the new value for each neuron. Note that it is far from optimal as local memory isn't used at all for the weighted sum! /** * @brief Computes one layer of the perceptron given the previous one and the * weights * The kernel is run once for each layer. * The work items are each tasked with computing the output of a single neuron * of the out layer. * * @param out_layer_size * Size of the output layer (number of elements in the output array that will * contain the result for each neuron). * @param in_layer_size * Number of elements of the input layer * @param in_value * Values of the neuron in the previous layer * @param in_weights * Array containing the weights for each input neuron. It is organised as a * two dimensional matrix, written by concatenating each line in the array * [ w11, w12, w13, ... * w21, w22, w23, ... * ..., ..., ..., ... * ] * Where wij is the weight linking the neuron i of the input layer to the * neuron j of the output layer * The last weights of each row represent the weights for the \"biais neuron\", * whose role is to threshold the values. * Thus, this kernel should be run with a NDRange of in_layer_size-1 * @param out_values * Computed values for the current layer */ void kernel perceptron ( const int in_layer_size , const int out_layer_size , global const float * in_value , global const float * in_weights , global float * out_values ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const int in_layer_s = in_layer_size ; private float sum = 0. ; for ( int i = 0 ; i < in_layer_s ; i ++ ) { sum += in_weights [ i + in_layer_s * global_id ] * in_value [ i ]; } out_values [ global_id ] = sigmoid ( sum ); } Training First, we initialize the weights in range \\([-0.5; 0.5]\\) . This is done on the host side, as random algorithm can be quite tricky to implement efficiently on GPU. All the rest is done in OpenCL. There is a kernel for each step of the algorithm described above. It should be fairly easy to understand by reading the code and comments. perceptron_train_output_layer : forward propagation that computes delta for the output layer perceptron_train_backpropagate : backpropagation that computes delta for every single layer perceptron_train_update_weights : update the weight based on the previously computed delta-values. perceptron_train_update_weights_intertia : another version of the algorithm, updating the weights faster when far from convergence, and getting slower and slower as the convergence zone approaches. This requires however to keep track of the weights from the two previous iterations. ::opencl float sigmoid(float x) /** * @brief Computes delta for all of the output neurons. * * @param values * Values of the output layer * @param expected_values * Values expected as output of the perceptron * @param delta * Output of the function: computes the delta needed for the training algorithm **/ void kernel perceptron_train_output_layer ( global const float * values , global const float * expected_values , global float * delta ) { private const float ci = expected_values [ get_global_id ( 0 )]; private const float oi = values [ get_global_id ( 0 )]; // Equivalent to sigmoid'(yi) * (ci-oi) delta [ get_global_id ( 0 )] = oi * ( 1 - oi ) * ( ci - oi ); } /** * @brief Computes delta for all layers (but the last one) * * @param curr_size * Size of current layer * @param succ_layer_size * Size of the output layer of current layer * @param current_layer_values * Values of current layer (calculated during forward propagation) * @param weights * @param succ_layer_delta_i * Values of delta for the next layer **/ void kernel perceptron_train_backpropagate ( const int curr_size , const int succ_layer_size , global const float * current_layer_values , global const float * weights , global const float * succ_layer_delta_i , // output global float * current_delta_out ) { private const int i = get_global_id ( 0 ); private const float oi = current_layer_values [ get_global_id ( 0 )]; private const int succ_size = succ_layer_size ; private float sum = 0.f ; for ( int k = 0 ; k < succ_size ; k ++ ) { sum += succ_layer_delta_i [ k ] * weights [ i + curr_size * k ]; } current_delta_out [ i ] = oi * ( 1 - oi ) * sum ; } /** * @brief Update the weights according to values of delta computed during backpropagation * * @param out_layer_size * @param epsilon_value * Parameter controlling the rate of convergence. * epsilon too low will lead to a very slow convergence, * epsilon too high will prevent convergence * @param pred_values * @param delta * @param weights **/ void kernel perceptron_train_update_weights ( const int out_layer_size , const float epsilon_value , global const float * pred_values , global const float * delta , global float * weights ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const float val = pred_values [ global_id % out_layer_s ]; // XXX to change private const float epsilon = epsilon_value ; // For each weight weights [ global_id ] += epsilon * delta [ global_id / out_layer_s ] * val ; } /** * @brief Update the weights according to values of delta computed during backpropagation * Uses the weights computed in the two previous training steps to accelerate convergence. * * @param out_layer_size * @param epsilon_value * Parameter controlling the rate of convergence. * epsilon too low will lead to a very slow convergence, * epsilon too high will prevent convergence * @param beta_value * Parameter controlling the non-linear convergence rate * @param pred_values * @param delta * @param previous_weights2 * Weights at the k-2 iteration * @param weights * As input, weights at the k-1 iteration. * As output, new weight at the k iteration **/ void kernel perceptron_train_update_weights_inertia ( const int out_layer_size , const float epsilon_value , const float beta_value , global const float * pred_values , global const float * delta , global const float * previous_weights2 , global float * weights ) { private const int global_id = get_global_id ( 0 ); private const int out_layer_s = out_layer_size ; private const float val = pred_values [ global_id % out_layer_s ]; // wij(k-1) private const float w1 = weights [ global_id ]; // wij(k-2) private const float w2 = previous_weights2 [ global_id ]; // XXX to change private const float epsilon = epsilon_value ; private const float beta = beta_value ; //printf(\"w1-w2: %f\\n\", w1-w2); // For each weight weights [ global_id ] = w1 + epsilon * delta [ global_id / out_layer_s ] * val + beta * ( w1 - w2 ); } Conclusion This article showed how to easily create a perceptron neural network using OpenCL. This is one of my first OpenCL projects, and I'm perfectly aware that this is far from being an optimal code. This article was partly meant as a reminder for myself of how I implemented the perceptron, so that I can later on come back to it and improve upon it. The main thing remaining to do would be to make proper use of local memory, in order to considerably improve the efficiency of the weighted sums computations. I will describe this in another article later on. The full code is available on my github account here I want to thank Lionel Filatre , Professor at the University of Polytech'Nice-Sophia for his lectures on neural networks. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"NeuralNetworks","title":"Multi-layered Perceptron using OpenCL"},{"url":"http://arntanguy.no-ip.org/creating-a-skybox-from-a-fullscreen-quad.html","text":"Creating a skybox is commonly done by either rendering an infite cube or sphere. Both methods are working nicely, but require to set up VBOs, transfer data to the GPU... Granted, that's far from the costlier thing you can do, but then every little bit counts ;) In this article, I will show you how to create a skybox by creating a fullscreen quad in a geometry shader and applying an inverse projection to get the eye direction as it would be if we were to render a cube. Why, will you ask me? Two reasons, it's fun and it's convenient! First, let me thank \"msell\" for the idea . The result is quite interesting: Notice how the center is of perfect resolution? That's because no distortion is applied there, so whatever your environment map resolution was will be preserved. Notice how the sides are \"stretched\"? That's because the texture is virtally projected on a cube, and thus appears stretched towards us. This gives a really deep impression of depth, however it comes at the cost of a little bit of motion blur. This side effect could be very useful for designing skyboxes for racing games! For other types of games, by tweaking the matrices inverted, this effect could be lessened. Geometry shader The role of this geometry shader is to emit a fullscreen quad, and send the view vectors corresponding to each of the corners. These view vectors will be interpolated when being passed to the fragment shader, resulting in view vectors for every part of the skybox, that can be used, for instance to fetch texture information from a samplerCube. # version 330 core uniform mat4 uProjectionMatrix ; uniform mat4 uWorldToCameraMatrix ; smooth out vec3 eyeDirection ; layout ( points ) in ; layout ( triangle_strip , max_vertices = 4 ) out ; void main () { vec4 corner1 = vec4 ( 1.0 , 1.0 , 0. , 1. ); vec4 corner2 = vec4 ( - 1.0 , 1.0 , 0. , 1. ); vec4 corner3 = vec4 ( 1.0 , - 1.0 , 0. , 1. ); vec4 corner4 = vec4 ( - 1.0 , - 1.0 , 0. , 1. ); // Inverse matrix is costly, should be precalculated // This is effectively a non-issue there as it is only computed four times // and would probably be calculated slower on the CPU (unless the view is // fixed, then it's obviously faster to compute it once and for all). mat4 inverseProjection = inverse ( uProjectionMatrix ); mat3 inverseModelview = transpose ( mat3 ( uWorldToCameraMatrix )); gl_Position = corner1 ; eyeDirection = - inverseModelview * ( inverseProjection * corner1 ). xyz ; EmitVertex (); gl_Position = corner2 ; eyeDirection = - inverseModelview * ( inverseProjection * corner2 ). xyz ; EmitVertex (); gl_Position = corner3 ; eyeDirection = - inverseModelview * ( inverseProjection * corner3 ). xyz ; EmitVertex (); gl_Position = corner4 ; eyeDirection = - inverseModelview * ( inverseProjection * corner4 ). xyz ; EmitVertex (); EndPrimitive (); } Fragment shader Nothing fancy here, we only need to use the eyeDirection vector interpolated from the geometry shader to fetch the texture in a samplerCube. # version 330 uniform samplerCube cubemap ; smooth in vec3 eyeDirection ; out vec4 fragmentColor ; void main () { fragmentColor = texture ( cubemap , eyeDirection ); } Usage When rendering it, you need to disable depth testing, so that the fullscreen quad always appear behind every other object. Then just generate an empty VAO to activate it: glBindVertexArray ( vao_skybox ); glDrawArrays ( GL_POINTS , 0 , 1 ); glBindVertexArray ( 0 );","tags":"OpenGL","title":"Creating a Skybox from a fullscreen quad!"},{"url":"http://arntanguy.no-ip.org/using-c11-enum-class-to-define-bitfield-flags.html","text":"C++11 introduced the notion of enum class , which extends the notion of enum to make it closer to a struct. Using this new feature, it is quite easy to achieve bitfield flags by overriding operators. The following header contains all you need to set up a bitfield enum. All it does is wrap the enum within a structure and override some bit manipulation operators & , | and ~ . This allows you to manipulate the bitfield very easyly. # ifndef __ENUM_FLAGS_H__ # define __ENUM_FLAGS_H__ # include < type_traits > template < typename T > using Underlying = typename std :: underlying_type < T >:: type ; template < typename T > constexpr Underlying < T > underlying ( T t ) { return Underlying < T > ( t ); } template < typename T > struct Flags { T t ; constexpr Flags ( T t ) : t ( t ) { } constexpr operator T () const { return t ; } constexpr explicit operator bool () const { return underlying ( t ); } }; # define ENUM_FLAGS ( T ) \\ enum class T ; \\ constexpr Flags < T > operator & ( T l , T r ) { return T ( underlying ( l ) & underlying ( r )); } \\ constexpr T operator | ( T l , T r ) { return T ( underlying ( l ) | underlying ( r )); } \\ constexpr T operator ~ ( T c ) { return T ( ~ underlying ( c )); } # endif Here is an exemple showing how to use it. Notice the macro ENUM_FLAGS(T) above? Well, this is all you'll need to make it work. The parameter T is the name of your enum class. This macro will automatically override operators for you enum, and thus turn it into a bitfield. # include < iostream > # include \"enum_flags.h\" ENUM_FLAGS ( Type ); enum class Type { TYPE1 = 1 << 0 , TYPE2 = 1 << 1 , TYPE3 = 1 << 2 }; class Test { public: Type type ; Test ( Type t ) { type = t ; if ( type & Type :: TYPE2 ); } }; int main () { Test te ( Type :: TYPE2 ); constexpr Type testType = Type :: TYPE1 | Type :: TYPE2 ; if ( testType & te . type ) { std :: cout << \"Bit matches\" ; } } You might be wondering about the 1 << x part. It is the same as saying \\(2&#94;x\\) , that is, setting the bit at the x position to 1. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"C++","title":"Using C++11 enum class to define bitfield flags"},{"url":"http://arntanguy.no-ip.org/fullscreen-quad-with-geometry-shaders.html","text":"One question that we see pop up from time to time on various OpenGL forums concerns the creation of fullscreen quads. Most of the solutions given are sending two fullscreen triangles to a vertex shader. While this approach works, it isn't optimal for graphics card using geometry shaders. And guess what? It is much easier to do it using geometry shaders! Here are the shaders you'll need: An empty vertex shader # version 330 core void main () {} A geometry shader emitting a fullscreen quad # version 330 core /** * Emits a fullscreen quad * Make sure that the input is an empty VAO emitting a dummy GL_POINT */ layout ( points ) in ; layout ( triangle_strip , max_vertices = 4 ) out ; out vec2 UV ; void main () { gl_Position = vec4 ( 1.0 , 1.0 , 0.5 , 1.0 ); UV = vec2 ( 1.0 , 0.0 ); EmitVertex (); gl_Position = vec4 ( - 1.0 , 1.0 , 0.5 , 1.0 ); UV = vec2 ( 0.0 , 0.0 ); EmitVertex (); gl_Position = vec4 ( 1.0 , - 1.0 , 0.5 , 1.0 ); UV = vec2 ( 1.0 , 1.0 ); EmitVertex (); gl_Position = vec4 ( - 1.0 , - 1.0 , 0.5 , 1.0 ); UV = vec2 ( 0.0 , 1.0 ); EmitVertex (); EndPrimitive (); } And a dummy fragment shader # version 330 core out vec4 out_Color ; in vec2 UV ; uniform sampler2D Texture ; void main ( void ) { out_Color = texture2D ( Texture , UV ); } Now, to use it, all you need to do is bind all three shaders, and emmit an empty VAO. /** * Issue a dummy VAO call to send one point to the graphics card. * It will then be able to generate a fullscreen quad **/ glBindVertexArray ( vao ); glDrawArrays ( GL_POINTS , 0 , 1 ); // Don't forget to clear the vertex array, or you might run into some // ugly surprises, like segfaults on glDrawArray calls for instance. glBindVertexArray ( 0 ); If this doesn't work, make sure that: Your graphics card supports geometry shaders The shaders are correctly bound The geometry emitted is a point (empty VAO shown above) That's it, you can now create fullscreen quads! An exemple of post-processsing with an FBO can be found here","tags":"OpenGL","title":"Fullscreen quad with geometry shaders"},{"url":"http://arntanguy.no-ip.org/loading-a-blender-scene-in-physijs-and-threejs.html","text":"La Nuit de l'Info It is quite interesting to realize the context in which these tools have been written. It was all done during an event called \" La Nuit de l'Info \". It is a national event held every year in France in which engineers students are competing from sunset to dawn over a number of challenges. These challenges spawn an impressive number of technologies, ranging from digging up some very old protocols to using some mainstream technologies, passing through Django, Javascript, Android, WebGL... Well you get the idea, that's a lot of possibilites for just a night! Our team \".pyVerts\" won 3 challenges, sadly none of them concerns this article on WebGL. Nonetheless, what will be presented here might not have been material for winning challenges, but certainly did a lot more good than most projects out there: it led to some pretty useful code that could possibly be used by anyone! Three.js, Physijs and Blender: How to fit them together? three.js is a really good 3D WebGL engine. It contains most of what you need to create a game: shader's support, materials, texture, camera, raycasting, and much more. Physijs is a physics engine plugin for Three.js. It is based on the quite famous Bullet Physics engine. Blender is an opensource modelling tool. I will present the rest of this article in the same order as the ideas I had for the night, so that you can grasp the thought process that led me to write additional tools for Three.js. First step: Loading a blender scene in Three.js Install the JSON export plugin for Blender Hopefully, loading a blender scene in Three.js engine is pretty easy. You just need to use the JSON exporter for blender along with the JSONLoader from Three.js. I will show you a version of that with the addition of the integration of Physijs. Here is how to install my version of the blender export plugin: Update: Thanks to some user submissions, the plugin and loading code has been improved. See the updates section at the end of this article to get the newest files. The installation method is the same. Download the modified exporter for blender 2.69 Untar it in ~/.config/blender/2.69/scripts/addons Then go to Blender \"User Preferences\"->\"Addons\", and look for \"three\" in the research bar. Activate it. What's new As you can see, in the Mesh panel, there is an additionnal PHYSICS section . To use it, just select (in object mode) the mesh that you're interested in, and set its properties: Shape: the physics representation of the object (box, sphere, convex hull...). Mass: self-explanatory, set it to 0 if you want a static object Export scene Select all objects within the scene (including cameras and lights), and click on the menu \"File->Export->Threejs\" Make sure that \"scene\" and \"camera\" are checked! That's it, you should now have a JSON scene file that you can use with three.js Load scene I wrote a modified version of the JSON Loader reading the physics parameters from Blender. First, download this class . Now to load a scene, you can look at this example loader The interesting part is var loader = new PhysicsSceneLoader (); loader . callbackProgress = callbackProgress ; loader . load ( \"scene.js\" , callbackFinished ); There is two callback functions. You can use this one to show a progress bar var callbackProgress = function ( progress , result ) { } And this one to handle what to do when loading is finished var loaded = {} var callbackFinished = function ( result ) { loaded = result // Add gravity to the scene loaded . scene . setGravity ( new THREE . Vector3 ( 0 , - 9.8 , 0 )); // Start the physics simulation scene . addEventListener ( 'update' , function () { scene . simulate ( undefined , 1 ); } ); } The variable loaded now contains all the scene. You can use loaded.scene to access the scene object. For instace, if you want to render it renderer . render ( loaded . scene , loaded . camera ) You'll have access to all objects loaded through loaded.objects . Well you get the gist of it! How to improve the export script The export script is far from complete as far as physics is concerned. So here is the gist of how to improve it. If you lack properties, you can easily integrate them by following the following steps: In export_threejs.py : Modify the TEMPLATE_OBJECT variable Modify the object_string in generate_object In init .py : Define your element at the top of the file Something like bpy . types . Object . THREE_physicsShape = bpy . props . EnumProperty ( items = [( 'BoxMesh' , 'BoxMesh' , 'Cube-like mesh' ), ( 'PlaneMesh' , 'PlaneMesh' , 'Plane' ), ( 'SphereMesh' , 'SphereMesh' , 'Sphere' ), ( 'CylinderMesh' , 'CylinderMesh' , 'Cylinder' ), ( 'ConeMesh' , 'ConeMesh' , 'Cone' ), ( 'CapsuleMesh' , 'CapsuleMesh' , 'Capsule' ), ( 'ConvexMesh' , 'ConvexMesh' , 'Convex hull of object' ), ( 'ConcaveMesh' , 'ConcaveMesh' , 'Concave' ), ( 'HeightfieldMesh' , 'HeightfieldMesh' , 'matches a regular grid of height values given in the z-coordinatesHeightfield' )], name = \"Mesh Type\" ) Add it to the OBJECT_PT_physics class In the engine , add it to PhysicsLoader.js : Look for where the Physijs.Mesh are defined, and do the proper changes, that's it, you're all set! Troubleshoot My physics bounding volume seems way bigger than the real object There my friend, you probably just encountered one of the most common problems with blender. By default, exporting doesn't apply scale to your mesh, quite stupid ain't it. Hopefully it is very easy to solve: select your model in Blender, and then hit Ctrl-A -> Apply Rotation and Scale. That's it, you're done ;) Updates Kevin Bikhazi improved upon my plugin. You can find the modified exporter for blender 2.69 here Here is the changelog Adds friction and restitution parameters under an object's material tab in Blender. These parameters are very important as they affect how the model interacts with the physics world. The Blender add-on has been modified to handle the new material parameters. Currently the mods only work with standard materials and not with normal mapped materials. It should be pretty easy to get it to work with normal maps, that might come soon PhysicsSceneLoader.js modified to use the new friction and restitution parameters. To install it, just untar, and copy the files to the proper location as specified in the article. Conclusion It's probably far from the best way of loading physics within three.js: it was written during a crazy night of coding! Yet, I hope this helps to give you ideas of how to automatically load geometry and physics within your webgl application.","tags":"WebGL","title":"Loading a Blender scene in Physijs and Three.js"},{"url":"http://arntanguy.no-ip.org/using-cgengines-fbos.html","text":"Create a FBO: cg :: FBO fbo = cg :: FBO ( windowSize . x , windowSize . y , cg :: FBO :: COLOR ); Link its internal texture to rendering shader (the one used to render on a visible fullscreen quad for instance). cg :: Shader shader ; shader . loadVertexShaderFromFile ( \"../src/fullscreen_quad.vert\" ); shader . loadGeometryShaderFromFile ( \"../src/fullscreen_quad.geom\" ); shader . loadFragmentShaderFromFile ( \"../src/fullscreen_quad.frag\" ); // Activate shader shader (); // Link texture shader . setTexture ( \"Texture\" , fbo . getColorTextureId ()); Do the linking texture step only once before the rendering. There is no point in linking it every time! Anyway that wouldn't work properly if you were to do that. Now you can activate the FBO in the render loop and render on it: // Activate render to FBO fbo . renderToFBO (); // Clear the FBO (equivalent to glClear(...)) fbo . clear (); /** * drawing... * We fill the array and then activate the Vertex Attrib 0 **/ shader (); glVertexAttribPointer ( 0 , 2 , GL_FLOAT , GL_FALSE , 0 , vertices ); glEnableVertexAttribArray ( 0 ); // Draw triangles glDrawArrays ( GL_TRIANGLES , 0 , 3 ); // Disable Vertex array when not needed anymore glDisableVertexAttribArray ( 0 ); The rendering part on the FBO is finished. After this step, you should have a triangle drawn on the FBO's texture. All that's left to do is display the texture to check whether everything is fine. This can be done using a fullscreen quad. The code below uses a geometric shader to generate the quad, and a fragment shader to texture it with the previously generated texture. Note that we don't need to bind the FBO's texture to the shader since this has been done before the rendering loop. cg :: FBO :: renderToScreen (); shader (); /** * Issue a dummy VAO call to send one point to the graphics card. * It will then be able to generate a fullscreen quad * Since we've bound the FBO's render texture to the uniform Texture of * the shader, we only need a sampler2D Texture; in the fragment shader * to make it work! **/ glBindVertexArray ( vao ); glDrawArrays ( GL_POINTS , 0 , 1 ); // Don't forget to clear the vertex array, or you might run into some // ugly surprises, like segfaults on glDrawArray calls for instance. glBindVertexArray ( 0 ); You can find the fullscreen quad shaders here","tags":"OpenGL","title":"Using CGEngine's FBOs"},{"url":"http://arntanguy.no-ip.org/install-ubuntu-on-msi-ge60-0nc.html","text":"Hi, It's been a while since I last had a bit of trouble installing Ubuntu, so I decided to write a small article about it. Don't expect screenshots, I don't want to go back to the installer just for the sake of some nice images. I will here explain how I installed a dualboot Windows 8/Ubuntu on my new MSI GE60 ONC laptop. UEFI The main difference I encountered was the introduction of UEFI. Don't worry if you had never heard of that before, I discovered it while installing Ubuntu on my new laptop as well! Basically, it is meant to replace the old BIOS architecture with a more flexible one. What the Ubuntu documentation on UEFI recommends is to install both Windows and Ubuntu using the UEFI mode. Unfortunately, for some reason that I was unable to figure out, I wasn't able to properly boot the LiveUSB on UEFI mode: it kept on giving me a black screen (and from what I saw on the forums, I'm not the only one). The workaround I used consists of booting and installing in Legacy Mode. To go into legacy mode, just press \"Del.\" on startup to enter the BIOS, and change the \"Boot\" options to Legacy instead of UEFI. Then, install the dualboot as usual (reduce windows partition size, create a new one for linux, extend the Data partition, add a swap partition). You will also need to create a special partition for the BIOS support of Legacy. To do so, create a small partition using gparted (>1Mb), and set the Flag grub_bios (or something like that). You're done. Now, to start Linux, go into the BIOS and set it to Legacy to start Windows, go into the BIOS and set it to UEFI I know, it's quite an ugly workaround, but that did the trick, and I'm barely even starting windows, so for me going into the bios when I need to start it is not so much of a bother. You could try using the boot-repair utility to convert the legacy booting process to UEFI. It is supposed to work quite well, however I ran into topics of users that tried it and failed. So I didn't bother investigating any further. Let me know if you manage to do it successfully ;)","tags":"Linux","title":"Install Ubuntu on MSI-GE60 0NC"},{"url":"http://arntanguy.no-ip.org/shadermaker-fix-bug-with-geometry-shaders.html","text":"Hi! I've just tried ShaderMaker, which seemed like a great shader editor, and one of the only existing ones that is truly cross-plateform. However, I'm still an unlucky student stuck with an integrated intel chipset, which obviously doesn't support geometry shaders. Unfortunaly, when I tried editing a fragment shader I bumped into a nice Segmentation fault! I looked it up online, and the only information I could find was that ShaderMaker crashed whenever geometry shader weren't supported by the graphics card. Strangely enough, I couldn't find any patch, despite the number of people complaining about it… So I decided to get my hands dirty, after all, I'm programming a physic engine and a bunch of shaders at the moment, so how hard could it be to fix a segmentation fault? Not hard at all! The bug is a mere problem of indices, that causes the program to look for a non-existing text editor. That's all. Since I didn't really have the time to delve into the code, I merely hacked the incriminated index back into behaving itself. It should work for everybody, even lucky possessors of geometry shaders enabled cards (even though they don't need this fix). So here goes the magick: Download the patched version of the sources from http://dl.free.fr/jRYRjmwEb And then build it using the usual method: qmake -unix ShaderMaker.pro make That's it, you're all set and it should work. Just in case, I'm also posting the diff file here diff --git a/src/editwindow.cpp b/src/editwindow.cpp index 703b95a..1da7461 100644 --- a/src/editwindow.cpp +++ b/src/editwindow.cpp @@ -320,7 +320,7 @@ createMenus */ void CBaseEditWindow::createMenus( IShader* ) { - // files + // files m_menuFile = menuBar()-&gt;addMenu( tr( \"&amp;File\" ) ); m_menuFile-&gt;addAction( m_actNew ); m_menuFile-&gt;addAction( m_actOpen ); @@ -449,7 +449,7 @@ void CSdiEditWindow::uploadShaderSource( IShader* shader ) { if( m_attachToShader ) { - shader-&gt;setShaderSource( m_document-&gt;shaderType(), + shader-&gt;setShaderSource( m_document-&gt;shaderType(), m_document-&gt;document()-&gt;toPlainText() ); } else // disabled by the user @@ -766,7 +766,6 @@ void CMdiEditWindow::createMenus( IShader* shader ) m_menuView-&gt;addAction( m_actToSDI ); } - /* ======================== createTabs @@ -777,6 +776,8 @@ void CMdiEditWindow::createTabs( IShader* shader ) m_tabs = new QTabWidget(); // add tabs + qDebug() &lt;&lt; \"Creating \" &lt;&lt; IShader::MAX_SHADER_TYPES &lt;&lt; \" editors\\n\" ; + m_geometryShaderAvailable = shader-&gt;isShaderTypeAvailable(IShader::TYPE_GEOMETRY); for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { m_editors[ i ] = NULL; @@ -805,14 +806,26 @@ void CMdiEditWindow::createTabs( IShader* shader ) connect( m_signalMapper, SIGNAL(mapped(int)), m_tabs, SLOT(setCurrentIndex(int)) ); } - /* ======================== positionChanged ======================== +XXX: Contains a hack to fix a bug occuring on low-end graphics card that don't support +geometry shaders... Tabs index becomes invalid, and thus causes a segfault. +The fix is merely a correction of indices in case geometry shaders aren't present. +It is not meant to be an optimal fix, I didn't have time to delve into the code. +This should still work with geometry shaders present, though this is untested. */ void CMdiEditWindow::positionChanged( void ) { - QTextCursor cursor = m_editors[m_tabs-&gt;currentIndex()]-&gt;textCursor(); + int index = m_tabs-&gt;currentIndex(); + /** + * XXX: Hack to fix geometry shader bug + **/ + if(!m_geometryShaderAvailable &amp;&amp; m_tabs-&gt;currentIndex() == 1) { + index = 2; + } + CSourceEdit *edit = m_editors[index]; + QTextCursor cursor = edit-&gt;textCursor(); int ln = cursor.blockNumber() + 1; int col = cursor.columnNumber() + 1; m_lineNumber-&gt;setText( \"Ln: \" + QString::number(ln) + \" | Col: \" + QString::number(col) ); @@ -831,7 +844,7 @@ CSourceEdit* CMdiEditWindow::activeDocument( void ) // do not type cast. does not hurt, since there are only 3 elements... for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { - if( m_editors[ i ] != NULL &amp;&amp; + if( m_editors[ i ] != NULL &amp;&amp; m_editors[ i ] == widget ) { return m_editors[ i ]; @@ -854,7 +867,7 @@ int CMdiEditWindow::tabToShader( int tabIndex ) // look up the widget... it only take 3 loops... for( int i = 0 ; i &lt; IShader::MAX_SHADER_TYPES ; i++ ) { - if( m_editors[ i ] != NULL &amp;&amp; + if( m_editors[ i ] != NULL &amp;&amp; m_editors[ i ] == widget ) { return i; diff --git a/src/editwindow.h b/src/editwindow.h index 0a5fc20..33a8a9d 100644 --- a/src/editwindow.h +++ b/src/editwindow.h @@ -305,6 +305,7 @@ private: // all documents CSourceEdit** m_editors; // [ IShader::MAX_SHADER_TYPES ] bool* m_attachToShader; // [ IShader::MAX_SHADER_TYPES ] + bool m_geometryShaderAvailable; // XXX: Hack to fix geometry shader bug on low end graphics card // actions QAction* m_actNextShader;","tags":"Programmation","title":"ShaderMaker: Fix bug with geometry shaders!"},{"url":"http://arntanguy.no-ip.org/install-archlinux-on-dell-latitude-e5420.html","text":"Je ne compte pas parler de l'installation d'ArchLinux en lui-même, bien assez de documentation existe sur le sujet. Je vais me contenter de préciser les parties spécifiques à ce laptop. Touchpad Le touchpad n'est pas un touchpad Synaptics, ce qui complique légèrement la configuration, d'autant plus qu'un bug du noyau fait qu'il n'est pas reconnu en tant que touchpad, mais en temps que souris… Pour l'installer, il faut installer le paquet AUR psmouse-elantech , qui compilera un module du noyau linux permettant de corriger le bug. Voici la démarche à suivre pour le faire : Ensuite, si vous désirez que le module soit automatiquement compilé quand c'est nécessaire (mise à jour…), mettez le dans le rc.conf MODULES = \"psmouse-elantech\" Ce laptop ne dispose pas de carte graphique, seulement du chipset intégré Intel. Pour le configurer, voici la démarche. Installer le paquet xf86-video-intel pacman -S xf86-video-intel Ensuite, il faut modifier les entrée du grub, si vous désirez disposer de toutes les performances du chipset. Pour ce faire, éditez le fichier /boot/grub/menu.lst (en root), et modifiez le ainsi # (0) Arch Linux title Arch Linux root ( hd0,2 ) kernel /boot/vmlinuz-linux root = /dev/sda3 ro i915.modeset = 1 initrd /boot/initramfs-linux.img i915.modeset=1 active le module i915.modeset=0 désactive le module Attention : SI vous aviez des entrées vga dans le menu.lst, il faut les enlever !","tags":"Linux","title":"Install ArchLinux on Dell Latitude E5420"},{"url":"http://arntanguy.no-ip.org/configure-usb-debugging-of-android-on-gnulinux.html","text":"ShaderMaker's text editor crashed. Indeed, the code tries to load a geometric shader while this isn't possible. This article provides the necessary source code to fix this issue. disqus_identifier: geenux-usb-debugging-android You want to develop your own application and test it directly your phone instead of the virtual machine? Or perhaps you just want to use some cool features of the SDK to manage your phone? Whatever the reason, here is how to do it. First, I'll assume that you have already installed the android SDK. The only thing left to do, is to set-up rules for udev. Most articles are happy with giving you a list of devices and Vendor ID. Well, I'm not. These lists are often not exhaustive, and unusual android devices are not represented. There is a really simple way of figuring out this data. Simply use the command lsusb It will give you a description of all your USB devices, find the one corresponding to your device Bus 002 Device 004: ID 04e8:689e Samsung Electronics Co., Ltd All the information you need is in this line : the vendor ID is 04e8, and the device id is 689e (this is a Samsung Galaxy Ace). You just have to declare it to udev: sudo vim /etc/udev/rules.d/51-android.rules Then put a line like: SUBSYSTEM == \"usb\" , ATTR { idVendor }== \"04e8\" , , ATTRS { idProduct }== \"689e\" , MODE = \"0666\" Obviously you need to set your own vendor and device ID here. You're all set! Next time udev will restart, your device should work!","tags":"Programmation","title":"Configure USB debugging of Android on GNU/Linux"},{"url":"http://arntanguy.no-ip.org/script-de-telechargement-pour-mangareadernet.html","text":"J'ai réalisé un petit script python pour télécharger les mangas depuis le site http://mangareader.net . Ce script fonctionne pour tous les mangas que j'ai testé, je suppose qu'il fonctionne pour le reste. Le code est un peu sale, gestion des exceptions pas très rigoureuse (si il y a une erreur durant le téléchargement, pas de souci, vous serez prévenu), appel de fonctions qui pourraient être évités… Si je suis pas trop flemmard, je modifierai ça plus tard. Il n'est probablement pas légal d'utiliser ce script sans être en possession des mangas originaux, pensez à les acheter ! Le script est sous licence GNU GPL, vous êtes libres de le modifier, l'utiliser comme bon vous semble. Si vous l'améliorez, j'apprécierai d'avoir le nouveau script. Utilisation Tout d'abord, il faut modifier quelques paramètres dans le script pour l'adapter à vos besoin. La variable DL_DIR contient le répertoire dans lequel vous souhaitez stocker les mangas, adaptez la à vos besoin. Pour utiliser le script, il suffit de faire mangareader.py \"one piece\" 199 Cette commande télécharge le chapitre 199 de One Piece. mangareader.py \"fairy tail\" 1-112 Cette commande télécharge les chapitres de 1 à 112 de Fairy Tail Voici donc le script en question: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"A small script that downloads mangas from onemanga.com Licenced under the WTPL Licence\"\"\" import os import re import socket import sys import urllib def helper (): \"\"\"Gives help about the use of this script\"\"\" print \"\"\"Usage: - python \"\"\" + sys . argv [ 0 ] + \"\"\" manga chapter - python \"\"\" + sys . argv [ 0 ] + \"\"\" manga firstchap-lastchap \"\"\" exit ( 0 ) # Config MAXTRIES = 5 DL_DIR = \"/media/DATA/Mangas/\" MANGA_LIST = \"http://www.mangareader.net/alphabetical\" MANGA_SITE = \"http://www.mangareader.net\" CHAPTER_NUMBER_LENGTH = 3 def print_error ( text ): print \" \\033 [31;1m\" + text + \" \\033 [0m\" def print_sucess ( text ): print \" \\033 [32;40m\" + text + \" \\033 [0m\" def down ( url ): \"\"\"Download the webpage at the given url\"\"\" tries = 0 downloaded = False while tries < MAXTRIES and downloaded == False : try : ret = urllib . urlopen ( url ) downloaded = True except ( IOError , socket . error ): tries += 1 print_error ( \"Failed download, retrying...\" ) if tries == MAXTRIES : print_error ( \"Maximum tries number reached exiting...\" ) exit ( 1 ) if tries == 0 : print_sucess ( \"Downloaded !\" ) return ret def retrieve ( url , nom ): \"\"\"Retrieves a file\"\"\" tries = 0 downloaded = False while tries < MAXTRIES and downloaded == False : try : urllib . urlretrieve ( url , nom ) downloaded = True except ( socket . error , IOError ): tries += 1 if tries == MAXTRIES : print_error ( \"Maximum tries number reached exiting...\" ) exit ( 1 ) else : print_error ( \"Failed download, retrying...\" ) if tries == 0 : print_sucess ( nom + \" downloaded.\" ) def make_pretty ( name ): \"\"\"Returns the chain given, in order to have a normal name\"\"\" return str ( name ) . capitalize () . replace ( \"/\" , \"\" ) . replace ( \"_\" , \" \" ) class Mangareader : \"\"\"Manga class. Contains several attributes related to the manga. Contains also methods to download its chapters\"\"\" def __init__ ( self , manga ): self . manga = manga self . manga_p = make_pretty ( manga ) self . url = \"http://mangareader.net/\" self . nb_image = 0 # Create the download directory try : if ( os . path . isdir ( DL_DIR ) == False ): os . mkdir ( DL_DIR ) if ( os . path . isdir ( DL_DIR + self . manga_p ) == False ): os . mkdir ( DL_DIR + self . manga_p ) except OSError : print_error ( \"Unable to create the download directory\" ) exit ( 1 ) def chap_dir_name ( self , number ): \"\"\"Returns the name of the directory of the chapter. It is useful in order to organize the mass of chapters. example: 500 chaps in the manga, directory named \"001\" instead of \"1\" \"\"\" num = str ( number ) return ( CHAPTER_NUMBER_LENGTH - len ( num )) * \"0\" + num def get_chapter ( self , number ): \"\"\" Get the images page url list \"\"\" print \"Downloading chapter \" + self . chap_dir_name ( number ) url = MANGA_SITE + \"/\" + self . manga + \"/\" + str ( number ) page = down ( url ) . read () #print page exp = 'select> of ([0-9]+).*<' try : self . nb_images = int ( re . search ( exp , page ) . group ( 1 )) #print nb_images except : print_error ( \"Cannot determine the number of images in this chapter\" ) #<option value=\"/103-2057-1/one-piece/chapter-12.html\" selected=\"selected\">1</option> exp = '<option value=\"(.*)\">(.+)</option>' exp2 = '<option value=\"(.*)\" selected=\"selected\">(.+)</option>' # get the link for all pages containing chapter images img = re . findall ( exp , page ) images = [] try : images . append ( re . findall ( exp2 , page )[ 0 ][ 0 ]) except : print_error ( \"Une page n'a pas été trouvée !\" ) # remove the problem with the special case of the current image for l in img : el = l [ 0 ] if ( el . find ( \"selected\" ) < 0 ): images . append ( el ) manga_dir = DL_DIR + self . manga_p + \"/\" + self . chap_dir_name ( number ) try : if ( os . path . isdir ( manga_dir ) == False ): os . mkdir ( manga_dir ) except OSError : print_error ( \"Unable to create the download directory\" ) exit ( 1 ) os . chdir ( manga_dir ) self . get_images ( images ) def get_images ( self , images_url ): #<img id=\"img\" width=\"800\" height=\"1210\" src=\"http://i28.mangareader.net/one-piece/133/one-piece-1690829.jpg\" alt=\"One Piece 133 - Page 15\" name=\"img\" /> exp = '<img id=.* width=.* height=.* src=\"(.*)\" alt=.* name=.* />' images = [] for url in images_url : print \"Parsing page \" + url page = down ( MANGA_SITE + url ) . read () img = re . findall ( exp , page ) try : images . append ( img [ 0 ]) except : print_error ( \"Un lien vers une image n'a pas été correctement récupéré!\" ) i = 1 for img in images : if len ( images ) == self . nb_images : print \"Téléchargement de l'image \" + str ( i ) + \"/\" + str ( self . nb_images ) retrieve ( img , self . manga_p + \"-\" + self . chap_dir_name ( i )) i += 1 else : print_error ( \"Le nombre d'images à télécharger est différent du nombre d'images du chapitre ! Tout ne sera pas téléchargé !\" ) if len ( sys . argv ) != 1 and ( sys . argv [ 1 ] == \"-h\" or sys . argv [ 1 ] == \"--help\" ): helper () exit ( 0 ) elif len ( sys . argv ) == 1 : helper () exit ( 0 ) if (( len ( sys . argv ) == 2 ) and ( sys . argv [ 1 ] == \"Is there an easter egg in this awesome program ?\" )): print \" __/~~\\-''- _ | \" print \"__- - { \\ \" print \" / \\ \" print \" / ;o o } \" print \" | ; \" print \" ' \" print \" \\_ (..) \" print \" ''-_ _ _ / \" print \" / \" print \" / \" if len ( sys . argv ) == 3 : M = Mangareader ( sys . argv [ 1 ]) chap = sys . argv [ 2 ] if chap . find ( \"-\" ) > 0 : chap = chap . split ( \"-\" ) if ( len ( chap ) == 2 ): for i in range ( int ( chap [ 0 ]), int ( chap [ 1 ])): M . get_chapter ( i ) else : M . get_chapter ( sys . argv [ 2 ])","tags":"Programmation","title":"Script de téléchargement pour mangareader.net"},{"url":"http://arntanguy.no-ip.org/test-gallery.html","text":"You want to develop your own application and test it directly your phone instead of the virtual machine? Or perhaps you just want to use some cool features of the SDK to manage your phone? Whatever the reason, here is how to do it. First, I'll assume that you have already installed the android SDK. The only thing left to do, is to set-up rules for udev. Most articles are happy with giving you a list of devices and Vendor ID. Well, I'm not. These lists are often not exhaustive, and unusual android devices are not represented. There is a really simple way of figuring out this data. Simply use the command lsusb It will give you a description of all your USB devices, find the one corresponding to your device Bus 002 Device 004: ID 04e8:689e Samsung Electronics Co., Ltd All the information you need is in this line : the vendor ID is 04e8, and the device id is 689e (this is a Samsung Galaxy Ace). You just have to declare it to udev: sudo vim /etc/udev/rules.d/51-android.rules Then put a line like: SUBSYSTEM == \"usb\" , ATTR { idVendor }== \"04e8\" , , ATTRS { idProduct }== \"689e\" , MODE = \"0666\" Obviously you need to set your own vendor and device ID here. You're all set! Next time udev will restart, your device should work!","tags":"misc","title":"test gallery"},{"url":"http://arntanguy.no-ip.org/ripper-laudio-dune-video-avec-ffmpeg.html","text":"Bonjour, Vu que j'ai eu un peu de mal à trouver comment ripper la bande son d'une vidéo (en l'occurence de youtube), j'ai fait un petit script pour le faire simplement : #!/bin/bash ### libmp3lame required : to install #sudo apt-get install ffmpeg libavcodec-extra-52 for i in \"$*\" ; do #mplayer -ao pcm \"$i\" -ao pcm:file=\"$(echo \"$i\"|cut -d'.' -f1).mp3\" # -vn remove the video ffmpeg -i \"$i\" -vn -acodec libmp3lame \"$(echo \" $i \"|cut -d'.' -f1).mp3\" done Très simple à utiliser, faites juste ripaudio.sh fichier1.flv fichier2.mpeg ...","tags":"Linux","title":"Ripper l'audio d'une vidéo avec FFMPEG."},{"url":"http://arntanguy.no-ip.org/useful-usages-of-dd.html","text":"Hello world, Why bother using heavy and complicated tools to create and use ISO files? Why not simply consider using the dd command? Granted, this command can sometimes look quite scary, especially because of it's impressive potential to destroy data with a misintruction. Still, it's a very useful command, just be careful how you use it! Create an ISO image of a CD Data within a CD are commonly wrapped in an ISO-9660 filesystem. An ISO image is merely a copy of this filesystem in a single file. Seen like that, the solution spawns naturally: we merely neeed to do a bit by bit copy of the CD into a file... Who said dd is meant for that? Just run dd if = /dev/cdrom of = cd.iso Mount ISO Mountin an ISO can always be useful, so here is how to do it. sudo mkdir /mnt/iso sudo mount -t iso9660 -o loop cd.iso /mnt/iso ls /mnt/iso Create bootable USB key Assuming you USB key is on /dev/sdb , and isn't mounted , you can simply run the following command to create a bootable USB key. Note that it is sd b and not sd b1 . Indeed, we do want to copy the bootloader and the partition table as well. dd bs = 4M if = bootable_iso.iso of = /dev/sdb","tags":"Linux","title":"Useful usages of dd."},{"url":"http://arntanguy.no-ip.org/create-frames-for-fotowall.html","text":"This article is a translation of Benoît Bâlon's article (fr) concerning the frame creation for Fotowall. I'm translating this article to increase the reach of his work, and meet the ever growing reclamations for more frames. The few frames proposed as default in Fotowall aren't always enough to fill up the user's creativity. Luckily, this software uses only standards, namely SVG for the frames realisation. Thus, it is rather simple to create new frames, though… two little constraints must be respected : Drawing an SVG image require the use of a SVG manipulation software, which is not that complicated, but can certainly repel more than one. Following a certain amount of indications, once again concerning the SVG, for a perfect display in Fotowall… And there, I lost half my readers (which must represent an arm or a foot)… Before I suggest a solution to avoid these to constraints, and thus make the integration of a \"simple drawing\" as a frame in Fotowall easier, we will see how these famous frames works. As said before, the frames are based on SVG drawings. In order to be used in Fotowall, these are cut in 9 pieces, indentified by a label inside the SVG file. The following illustration represents these 9 pieces, the pink area correspond to the position of a canvas' photo. The labels displayed on each piece, such as \"topleft\" or \"bottom\", correspond to the different ID on which Fotowall depends on. Without these ID, Fotowall won't be able to use the frame, and the outline of the photo, be it of your nephew or of Médor, will desperately remains empty. To these 9 pieces, adds up 4 other elements, represented by arrows above. Although they appear while the vectorial drawing is edited, they are invisible inside Fotowall, but are nonetheless necessary. These, identified by the IDs \"hint-[...]-margin\", are used to define the width of the visible outline. Thus, if we take the example of the left arrow, here is its impact on the left image: If the object \"hint-left-margin\" is as long as the image \"left\", then this image appears in its whole width If the object \"hint-left-margin\" is longer than the image \"left\", then a space appears between this image and the border of the photo. This space is automatically filled with the background image \"center\", which exceed the photo's from on the left side. If the object \"hint-left-margin\" is less long than the image \"left\", then the latter is partially covered with the photo. Mathematically, the distance between the space zone and the covered zone, is the difference of length between the element \"hint-[...]-margin\" and each of the concerned images (the 3 on the left, right, top, bottom): if the frame is 5 pixels and the margin is 10 pixels, there will be a gap of 5 pixels between the frame and the photo. A little detail that is worth mentioning, the images \"top\", \"left\", \"bottom\" and \"right\" will be automatically stretched according to the photo's size. From here, we realise that unfortunately it's hard to come up with a frame composed of pattern supporting to be bent… The following example illustrate rather well this problem. Never mind that ! It's already possible to do enough to have fun, and these few limitations will probably be lifted with time. We saw that a frame is composed of 9 + 4 graphical elements in an SVG file. To avoid entering the IDs of these elements manually inside a SVG file (which is a mere XML structured file), in Inkscape it is possible to enter these after a right click on each of these elements, as illustrated below. With the information we just studied, we can see that creating a frame can me done without to much difficulty, but is nonetheless a tedious work, which can really become a bother when you try to use more colour schemes for a single frame. And, of course, not everyone is confortable with vectorial drawing! In this case, why not created a bitmap (JPG, PNG…) frame with an image software such as Gimp, and then convert it in an SVG frame ready to use in Fotowall? As we briefly said before, an SVG file is a mere XML file. Luckily enough, there are plenty of linux command line tools, and Bash (or any other *sh, not to be -too- sectarian) is the star when it come to create files automatically! The temptation to create such a program was way too high. Thus, here come a script which will allow us to free ourselves from the cutting and SVG conversion : fotowall_frame_compiler.zip Once uncompressed, the use of this script, though requiring the use of a dark and strange screen, the one we call \"Terminal\", is really simple to use. Just look: ./fotwall_frame_compiler.sh image.png This script can work with a unique parameter, namely the image to convert. In this case, the 9 frame's pieces will be as often as possible of equal height and width. For a better rendering, try to prefer dimensions which are multiple of 3 from the begining. In output, the SVG file is created, using the name of the original picture and replacing the extension with \".svg\" (which gives in our example image.png > image.svg). But we can as well have a frame's outline as high or wide (or both) different from the one reserved to the photo position. Taking back the example of the first illustration, we clearly see that the height of \"top\" and \"bottom\" is not the same as the height of \"center\". In this case, it will be necessary to know the exact size we want to give to \"center\" once transformed into SVG. In Gimp, it is for instance possible to measure this sone with the rectangular selection tool. Once the height and width are known, we just have to add these two parameters to the script: ./fotowall_frame_compiler.sh image.png 150 130 This script can work with a unique parameter, namely the image to convert. In this case, the 9 frame's pieces will be as often as possible of equal height and width. For a better rendering, try to prefer dimensions which are multiple of 3 from the begining. In output, the SVG file is created, using the name of the original picture and replacing the extension with \".svg\" (which gives in our example image.png > image.svg). But we can as well have a frame's outline as high or wide (or both) different from the one reserved to the photo position. Taking back the example of the first illustration, we clearly see that the height of \"top\" and \"bottom\" is not the same as the height of \"center\". In this case, it will be necessary to know the exact size we want to give to \"center\" once transformed into SVG. In Gimp, it is for instance possible to measure this sone with the rectangular selection tool. Once the height and width are known, we just have to add these two parameters to the script: ./fotowall_frame_compiler.sh image.png 150 130 The first number represents the width in pixels, the second represents the height. Considering that the \"center\" area is perfectly centred, the script is capable of calculating the width and height of each one of the 9 parts, and to place them within the SVG file. In short, there is nothing left to do, the frame is immediately usable within Fotowall! If the rendering is not perfect (a gap of 1 or 2 pixels is always possible), you just have to play directly on the two values of the command line, and reload the frame in Fotowall. To illustrate all of this, here comes a more concrete example: However, this script requires one or two programs, which are available within the repository of every good GNU/Linux distribution: base64: it should be installed by default, this software can store each of the 9 images directly inside the SVG file. ImageMagick : the convert and identify commands are overused in this script. A version 6.5.8-9 at least is required for the automatic splitting in 9 images. Inkscape is not really required anymore, but it would be too bad not to use it... Warning: this script created temporarily 9 PNG images in the directory. These 9 elements are then stored within the SVG file, after being split and numbered as follow by ImageMagick (using the example above) : image_0.png, image_1.png, … , image_8.png. Please mind not having an important picture named the same, otherwise it will be overwritten. If someone is motivated to create a proper warning and management of these kind of problems, feel free to do so, it would be greatly appreciated . After seeing how the frames works, a script allows us to free ourselves from a certain amount of boring steps (labelling, splitting…), and thus we can concentrate on the pure graphical realisation of the image. Save the images in PNG, as it is the only format to benefit from both colour and transparency. By way of conclusion, we can summarise the main parts adressed here concerning the Fotowall's frames: They are in SVG format, and can be drawn using one of the vectorial manipulation programs, such as Inkscape. A frame is composed of 9 elements : the 4 corners, the 4 borders, and the center. To these 9 elements, adds up 4 others for the distance between the border of the frame and the border of the photo. Each of the elements is given a precise ID within the SVG file. The borders being stretched, the patterns are bent, which for now put a small limitation on your creativity. It is possible to avoid all the SVG part, and created a frame from bitmaps (once again, favour the PNG format) using the script fotowall_frame_compiler (needs GNU/Linux and a recent version of ImageMagik). A huge thanks to Benoît Bâlon for this article, I hope that my approximative translation didn't rip too much of the original essence of the article.","tags":"FotoWall","title":"Create Frames For FotoWall"},{"url":"http://arntanguy.no-ip.org/creez-vos-mesh-ogre-sous-blender.html","text":"Si vous aimez le logiciel de modélisation 3D Blender, vous serez sans doute ravi de l'utiliser pour créer votre monde dans votre jeu utilisant le moteur Ogre. La bonne nouvelle, c'est que c'est d'une simplicité impressionnante, je vais profiter de ce billet pour me faire un petit mémo sur comment faire, ainsi que comment utiliser la technique de l'UV mapping avec Blender (je débute avec la 3D, que ça soit en programmation ou modélisation). L'exemple présenté ici sera fait sur un simple cube, que l'on va texturer, et intégrer dans un projet Ogre. Installation du script d'exportation OGRE Meshes Exporter Sous Ubuntu Tout d'abord, vous aurez besoin du script d'exportation pour Ogre. Sous Ubuntu pour l'installer, il suffit de faire sudo aptitude install blender-ogrexml Sous une autre distribution Si vous avez une autre distribution, voici comment installer le script. Téléchargez OGRE Meshes Exporter Copiez ogremeshesexporter.py et les sous-dossiers dans ~/.blender/scripts Note : Vous devez aussi avoir python 2.6.4 installé pour que le script fonctionne. Création du cube et UV mapping Ouvrez Blender, créez un cube dans une nouvelle scène. Déplacez votre curseur sur la limite supérieure de la zone de modélisation jusqu'à voire une double flèche. Clic droit, puis clic gauche sur Split Area, puis clic gauche pour valider. Maintenant, dans la nouvelle fenêtre créé, passez en mode UV/ImageEditor Retournez dans la vue 3D, passez en mode editing (touche tab), sélectionnez tout le cube Ensuite, faites U -> Unwrap (smart projection). Smart projection est souvent la méthode de déroulement donnant les meilleurs résultats. Faites ensuite Image -> Open (Alt+O) et ouvrez une image de votre choix qui vous servira de texture. Vous pouvez en trouver dans le répertoire OGRE/media/materials/textures… Une image apparait alors dans la partie de l'UV mapping. Normallement, les vues planes des faces du cubes devraient coincider avec la taille de l'image, si ce n'est pas le cas, sélectionnez toutes les faces dans la partie UV (touche A) puis redimensionnez les en utilisant la touche s. On obtient Allez dans la vue 3D, et faites Alt+Z pour passer en mode texturé. Normalement vous devriez voir la texture. Il ne reste plus qu'à assigner un matériau au cube, et à exporter. Ouvrez le panneau Shading (F5), puis créez un nouveau matériau. Cliquez sur Tex Face. Exportation Faites Fichier->Exporter->Ogre Meshes. Là, vous avez la fenêtre du bas qui se modifie. Cliquez sur « Game Engine Materials » et « OgreXMLConverter ». Le fait de sélectionner OgreXMLConverter appellera automatiquement le programme d'Ogre du même nom qui est chargé de convertir le fichier XML du mesh en des fichiers de mesh que le moteur comprend. Cliquez sur « Exporter ». Sublime, magnifique, perfect, vous venez de créer votre premier Mesh pour OGRE. Mais comment l'utiliser maintenant ? Suivez le guide. Utiliser le mesh dans OGRE Dans cette partie, je supposerai que vous connaissez au moins les bases de OGRE, c'est à dire les premiers tutoriels du wiki officiel, au moins jusqu'à la partie permettant de charger un mesh. Tout d'abord, il va falloir placer les fichiers où il faut, c'est à dire… où vous voulez. Je vous conseille néamoins de respecter la structure habituelle de OGRE, c'est à dire - Ogre ( un dossier dans lequel vous placerez vos mesh , par exemple dans le r é pertoire de votre jeu , o ù ailleurs ). — > models : vous placerez dans ce r é pertoire le fichier Cube .001 . mesh qui a é t é g é n é r é par le script d ' exportation — -> materials : ce r é pertoire contient les textures , scripts , enfin bref infos sur l ' apparence ——— -> textures : placez ici votre texture ——— -> scripts : placez ici le fichier Scene . material g é n é r é par l ' exportation Maintenant, il va falloir dire à Ogre où trouver les fichiers. Pour celà, modifiez le fichier ressource.cfg comme suitDans cette partie, je supposerai que vous connaissez au moins les bases de OGRE, c'est à dire les premiers tutoriels du wiki officiel, au moins jusqu'à la partie permettant de charger un mesh. Tout d'abord, il va falloir placer les fichiers où il faut, c'est à dire… où vous voulez. Je vous conseille néamoins de respecter la structure habituelle de OGRE, c'est à dire - Ogre ( un dossier dans lequel vous placerez vos mesh , par exemple dans le r é pertoire de votre jeu , o ù ailleurs ). — > models : vous placerez dans ce r é pertoire le fichier Cube .001 . mesh qui a é t é g é n é r é par le script d ' exportation — -> materials : ce r é pertoire contient les textures , scripts , enfin bref infos sur l ' apparence ——— -> textures : placez ici votre texture ——— -> scripts : placez ici le fichier Scene . material g é n é r é par l ' exportation Maintenant, il va falloir dire à Ogre où trouver les fichiers. Pour celà, modifiez le fichier ressource.cfg comme suit # Resources required by the sample browser and most samples. [Essential] Zip = /usr/share/OGRE/media/packs/SdkTrays.zip FileSystem=/usr/share/OGRE/media/thumbnails # Common sample resources needed by many of the samples. # Rarely used resources should be separately loaded by the # samples which require them. [Popular] FileSystem = /usr/share/OGRE/media/fonts FileSystem=/usr/share/OGRE/media/materials/programs FileSystem=/usr/share/OGRE/media/materials/scripts FileSystem=/usr/share/OGRE/media/materials/textures FileSystem=/usr/share/OGRE/media/materials/textures/nvidia FileSystem=/usr/share/OGRE/media/models FileSystem=/usr/share/OGRE/media/particle FileSystem=/usr/share/OGRE/media/DeferredShadingMedia FileSystem=/usr/share/OGRE/media/PCZAppMedia FileSystem=/usr/share/OGRE/media/RTShaderLib # MODIFIEZ ICI : mettez le chemin des répertoires que vous venez de créer FileSystem = /media/data/programmation/3D/ogre/media/materials/scripts FileSystem=/media/data/programmation/3D/ogre/media/materials/textures FileSystem=/media/data/programmation/3D/ogre/media/models Zip = /usr/share/OGRE/media/packs/cubemap.zip Zip=/usr/share/OGRE/media/packs/cubemapsJS.zip Zip=/usr/share/OGRE/media/packs/dragon.zip Zip=/usr/share/OGRE/media/packs/fresneldemo.zip Zip=/usr/share/OGRE/media/packs/ogretestmap.zip Zip=/usr/share/OGRE/media/packs/ogredance.zip Zip=/usr/share/OGRE/media/packs/Sinbad.zip Zip=/usr/share/OGRE/media/packs/skybox.zip [General] FileSystem = /usr/share/OGRE/media Plus qu'à tester ça sur un exemple, prenons celui du wiki officiel : # include \"ExampleApplication.h\" class TutorialApplication : public ExampleApplication { protected: public: TutorialApplication () { } ~ TutorialApplication () { } protected: void createScene ( void ) { mSceneMgr -> setAmbientLight ( ColourValue ( 1 , 1 , 1 ) ); Entity * ent1 = mSceneMgr -> createEntity ( \"Test\" , \"Cube.001.mesh\" ); SceneNode * node1 = mSceneMgr -> getRootSceneNode () -> createChildSceneNode ( \"TestNode\" ); node1 -> attachObject ( ent1 ); } }; # if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 # define WIN32_LEAN_AND_MEAN # include \"windows.h\" INT WINAPI WinMain ( HINSTANCE hInst , HINSTANCE , LPSTR strCmdLine , INT ) # else int main ( int argc , char ** argv ) # endif { // Create application object TutorialApplication app ; try { app . go (); } catch ( Exception & e ) { # if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 MessageBox ( NULL , e . what (), \"An exception has occurred!\" , MB_OK | MB_ICONERROR | MB_TASKMODAL ); # else fprintf ( stderr , \"An exception has occurred: %s \\n \" , e . what ()); # endif } return 0 ; } Voilà, plus qu'à compiler, et à lancer le programme. Normallement, sous vos yeux ébahis, le cube apparait, texturé tout comme il faut. Problèmes Voici quelques problèmes que j'ai rencontré, et comment les éviter : Si l'application ne démarre pas, vous avez probablement oublié de placer le fichier mesh Cube.001.mesh dans votre répertoire models/, ou alors vous n'avez pas spécifié correctement sa position dans le fichier ressources.cfg Si le cube n'est pas texturé, vérifiez que vous avez bien un fichier Scene.material dans votre dossier script, et que son emplacement est correctement spécifié dans le fichier ressources.cfg Amusez vous bien, et si je n'ai pas été clair, n'hésitez pas à demander des précisions dans les commentaires.","tags":"Programmation","title":"Créez Vos Mesh Ogre Sous Blender !"},{"url":"http://arntanguy.no-ip.org/using-cmake.html","text":"Je me souviens encore des premier projets pour lesquels j'ai tenté de comprendre comment utiliser cmake pour créer les makefiles. La doc est tout sauf claire, et le manque de tutoriels sur la base du fonctionnement de cmake manque cruellement. Je vais tâcher de remédier à ce souci, en expliquant comment compiler des projets simples avec cmake. Qu'est-ce que cmake ? Il s'agit d'un outil permettant de ne pas avoir à écrire les Makefiles à la main. Il permet de rechercher automatiquement les librairies sur le systèmes, de régler les compilation en statique ou dynamique, de compiler aisément à partir d'un dossier séparé. C'est un réel plus pour la portabilité (cmake fonctionne sur de nombreux systèmes, et la plupart des modules peuvent trouver les lib aussi bien sous Windows, que GNU/Linux…). Cmake permet de vous affranchir de la syntaxe immonde des makefiles, et de vous contenter de décrire la manière de compilation de votre programme, de conditionner la compilation… Un cmake minimal. Tout d'abord, voici un exemple de CMakeFile.txt (c'est le fichier que cmake lit pour le convertir en makefile) permettant de compiler avec Boost. cmake_minimum_required ( VERSION 2.6 FATAL_ERROR ) # search for Boost version 1.40 # Components : #filesystem, iostreams, programoptions, python, regex, serialization, signals #system, thread, wave find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) link_directories ( ${ Boost_LIBRARY_DIRS } ) include_directories ( ${ Boost_INCLUDE_DIRS } ) SET ( SOURCES main.cpp ) SET ( EXECUTABLE_NAME executable ) add_executable ( ${ EXECUTABLE_NAME } ${ SOURCES } ) target_link_libraries ( ${ EXECUTABLE_NAME } ${ Boost_LIBRARIES } ) Comme vous pouvez le constater dans cet exemple, cmake gère les variables, et sa syntaxe est assez simple. Étudions plus en détail ce fichier. cmake_minimum_required ( VERSION 2.6 FATAL_ERROR ) Cette ligne indique qu'il faut avoir la version 2.6 de cmake pour compiler, le FATAL_ERROR est facultatif, il indique à cmake de ne pas essayer de compiler et de stopper tout de suite. find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) Il s'agit d'une des fonctionnalités les plus intéressantes de cmake : la recherche des librairies. La fonctionnalité find_package va chercher un fichier (appelé module), permettant de rechercher la lib voulue nommée FindBoost.cmake. Chez moi ce fichier est dans \"/usr/share/cmake-2.6/Modules/FindBoost.cmake\". (si vous ne le trouvez pas, un simple locate FindBoost.cmake devrait le trouver). Pourquoi je vous indique ces détails sur le fichier ? Eh bien, parceque la lecture du fichier en question va vous fournir une mine d'information sur ce qu'il fait, quelles variables il définit, bref comment l'exploiter. Voici quelques extraits du header de ce fichier : # - Try to find Boost include dirs and libraries # Usage of this module as follows: # # == Using Header-Only libraries from within Boost: == # # find_package( Boost 1.36.0 ) # if(Boost_FOUND) # include_directories(${Boost_INCLUDE_DIRS}) # add_executable(foo foo.cc) # endif() # # # == Using actual libraries from within Boost: == # # set(Boost_USE_STATIC_LIBS ON) # set(Boost_USE_MULTITHREADED ON) # find_package( Boost 1.36.0 COMPONENTS date_time filesystem system ... ) # # if(Boost_FOUND) # include_directories(${Boost_INCLUDE_DIRS}) # add_executable(foo foo.cc) # target_link_libraries(foo ${Boost_LIBRARIES}) # endif() # # # The components list needs to contain actual names of boost libraries only, # such as \"date_time\" for \"libboost_date_time\". If you're using parts of # Boost that contain header files only (e.g. foreach) you do not need to # specify COMPONENTS. # # You should provide a minimum version number that should be used. If you provide this # version number and specify the REQUIRED attribute, this module will fail if it # can't find the specified or a later version. If you specify a version number this is # automatically put into the considered list of version numbers and thus doesn't need # to be specified in the Boost_ADDITIONAL_VERSIONS variable (see below). # # NOTE for Visual Studio Users: # Automatic linking is used on MSVC &amp; Borland compilers by default when # #including things in Boost. It's important to note that setting # Boost_USE_STATIC_LIBS to OFF is NOT enough to get you dynamic linking, # should you need this feature. Automatic linking typically uses static # libraries with a few exceptions (Boost.Python is one). # # Please see the section below near Boost_LIB_DIAGNOSTIC_DEFINITIONS for # more details. Adding a TARGET_LINK_LIBRARIES() as shown in the example # above appears to cause VS to link dynamically if Boost_USE_STATIC_LIBS # gets set to OFF. It is suggested you avoid automatic linking since it # will make your application less portable. [...] # Variables used by this module, they can change the default behaviour and # need to be set before calling find_package: # # Boost_USE_MULTITHREADED Can be set to OFF to use the non-multithreaded # boost libraries. If not specified, defaults # to ON. # # Boost_USE_STATIC_LIBS Can be set to ON to force the use of the static # boost libraries. Defaults to OFF. # # Other Variables used by this module which you may want to set. # # Boost_ADDITIONAL_VERSIONS A list of version numbers to use for searching # the boost include directory. Please see # the documentation above regarding this # annoying, but necessary variable <img src=\"http://s0.wp.com/wp-includes/images/smilies/icon_sad.gif?m=1129645325g\" alt=\":(\" class=\"wp-smiley\"> # [...] # # Boost_INCLUDE_DIRS Boost include directories: not cached # # Boost_INCLUDE_DIR This is almost the same as above, but this one is # cached and may be modified by advanced users # # Boost_LIBRARIES Link to these to use the Boost libraries that you # specified: not cached # # Boost_LIBRARY_DIRS The path to where the Boost library files are. # # Boost_VERSION The version number of the boost libraries that # have been found, same as in version.hpp from Boost [...] # Boost_${COMPONENT}_FOUND True IF the Boost library \"component\" was found. # # Boost_${COMPONENT}_LIBRARY Contains the libraries for the specified Boost # \"component\" (includes debug and optimized keywords # when needed). Grâce aux informations contenues ici, on pourra facilement construite un CMakeFile adapté à nos besoins. Revenons à l'exemple : find_package va utiliser le fichier indiqué plus haut pour rechercher boost, le module va définir de nombreuses variable (comme on voit dans le header ci-dessus), que l'on va utiliser pour la compilation. find_package ( Boost 1.40.0 COMPONENTS regex signals FATAL_ERROR ) link_directories ( ${ Boost_LIBRARY_DIRS } ) include_directories ( ${ Boost_INCLUDE_DIRS } ) k La ligne link_directories indique que cmake devra lier l'exécutable avec la librairie boost, ${Boost_LIBRARY_DIRS} étant une variable définie par le module appelé par find_package. La ligne include_directories fait de même pour le répertoire dans lequel les includes de boost sont. SET ( SOURCES main.cpp autre.cpp ) SET ( EXECUTABLE_NAME executable ) On définit 2 variables SOURCES et EXECUTABLE_NAME, comme ça on aura juste à modifier à un seul endroit, et tout le reste sera modifié en conséquence. add_executable ( ${ EXECUTABLE_NAME } ${ SOURCES } ) target_link_libraries ( ${ EXECUTABLE_NAME } ${ Boost_LIBRARIES } ) add_executable indique à cmake qu'il faut compiler les sources contenues dans la variable SOURCE et créer un exécutable nommé par le nom défini dans la variable EXECUTABLE_NAME target_link_libraries indique à cmake avec quelles librairies il doit lier. Et voilà, vous avez un CMakeList pour compiler avec boost. mkdir build && cd build cmake .. make Et voilà, les sources sont compilés dans le dossier build.","tags":"Programmation","title":"Using CMake"},{"url":"http://arntanguy.no-ip.org/fotowall-09.html","text":"Fotowall 0.9 est enfin sorti ! Pour ceux qui ne le saurait pas encore, Fotowall permet de créer un \"patchwork\" de photos (les assembler, ajouter des effets, cadres…) Nouveautés Un espace de travail simple, robuste et intégré avec un écran d'accueil. Nouveaux contenus : Canevas et \"Nuage de mots\" [Wordcloud] Effets graphiques Système de commentaires [Likeback] Canvevas zommable, avec des barres de défilement (enfin) Plus de 250 autres changements: Autoblend Effect for images SVG export Quick and improved property editors Cursor key movement OpenGL performance tests and auto-tuning Google Images search (by Marco Bavagnoli, reqby. Rossana) Cleanups and Refactors: Selection, Frames, Rendering, Backgrounding, DVD/CD, Print/Export Fixed relative saving (with contents auto-search) Fixed multiple Webcams and bad Colors Fixed the Exact Size modes Fixed licensing Pour le télécharger, c'est par ici .","tags":"FotoWall","title":"FotoWall 0.9"},{"url":"http://arntanguy.no-ip.org/psp-slim-200-chicken-custom-firmware-gen-b.html","text":"J'ai pas mal galéré pour avoir ma PSP Slim 2000 fonctionnelle avec un custom firmware pour pouvoir lancer des homebrew (applications non officielles), notamment bookr permettant de lire des pdf. Installer chickhen r2 Tout d'abord, qu'est-ce que chickhen ? Il s'agit d'un hack exploitant une faille de la lib tiff de la psp pour permettre le lancement d'homebrew. Une fois chickhen \"installé\", une bonne partie des homebrews pourront être lancés. Il n'y a aucun risque pour la psp à installer chicken, en effet celui-ci n'est pas réellement installé, la mémoire flash de la psp n'est pas modifié. Chickhen est seulement chargé en mémoire, ce qui signifie que si vous éteignez totalement la psp (en maintenant le bouton off quelques secondes), il faudra le réinstaller, heureusement, cette étape est très simple. Téléchargez Chickhen Placer le dossier Chickhen dans le dossier PSP/PHOTO Placer le fichier h.bin à la racine de votre PSP Débrancher la psp, mettez l'adaptateur wlan sur on (ça ne fonctionne pas sinon, en tout cas avec ma psp), assurez vosu que le son n'est pas coupé, puis allez dans le menu Photo->memory stick, et faites croix sur le dossier Chickhen. Là, ne touchez plus à rien, ne scrollez pas, attendez quelques secondes. Il y aura un écran vert qui va apparaître, et la psp va redémarrer. Il se peut que ça ne fonctionne pas si la psp est en français, si c'est le cas, mettez la en anglais (ce que j'ai fait). Vérifiez que c'est bien installé, en allant dans le menu Settings->System Information, vous devriez voir 5.03 ChickHEN R2 Là, normalement la plupart des homebrews devraient se lancer, mais ça serait dommage de s'arrêter en si bon chemin. Installer le custom firmware 5.03 gen B Il s'agit d'un hack du système d'exploitation de la PSP pour lui ajouter des fonctionnalités et débloquer des choses délibérément bloquées par la psp (pour éviter le piratage des jeux par exemple). Il permettra de lancer les homebrews, les jeux au format iso, cso, boot… Vous pouvez convertir vos UMD en iso sur votre PSP grâce à ce firmware. Quel intérêt ? Temps de chargement plus rapide, consommation de batterie plus faible, vos UMD ne sont pas abimés. L'installation est expliquée assez clairement sur pspgen , je ne vais donc pas le refaire ici. Informations complémentaires sur l'utilisation. Vous pouvez accéder au recovery menu, ainsi qu'au gen vsh menu, permettant de configurer la psp en appuyant sur la touche Select. Si vous désirez lancer des jeux en iso, il est conseillé de mettre UMS ISO MODE sur Sony NP9960. Si votre iso ne foncitonne pas, essayez M33 driver. J'espère que ce billet permettra d'éclaircir l'installation du custom firmware. Pour l'installer, j'ai été obligé de faire de nombreuses recherches, sur de nombreux sites/forum, alors que c'est extrêmement simple et sur (j'avais peur de bricker ma psp, et il m'a fallu voir plusieurs sites pour être convaincu que le flash0 n'était pas touché).","tags":"Random","title":"Psp SLIM 200 Chicken & Custom Firmware Gen B"},{"url":"http://arntanguy.no-ip.org/vim-my-configuration.html","text":"Tant qu'à m'être fait un vim qui me convient à peu près, je me suis dit que ça pourrait être bien de partager ça. J'utilise un gestionnaire de version (git) pour suivre l'évolution de ma configuration, le dépôt contenant le tout est disponible sur github . Actuellement ma configuration permet : De programmer en c++ : Alternate (:A) pour passer des .cpp aux .h, Surround pour gérer les parenthèses, matchit pour étendre la commande \"%\" (permettant de passer de la parenthèse ouvrante à la fermante) à plus d'éléments (balises xml…), NerdCommenter pour gérer les commentaires, DoxygenToolKit pour gérer la documentation. Et le plugin le plus important : OmniCppComplete qui permet de compléter le code plus intelligemment que Ctrl+N (notemment en utilisant les fichiers tags, que j'ai réalisé pour Qt et boost sur mon ordi). De faire de latex : la latex-suite est installée. Il y a d'autres plugins intéressant, comme Arpeggio par exemple. Arpeggio permet d'utiliser des raccourcis en pressant simultanément plusieurs touches. Par exemple, en ajoutant la ligne suivante dans le .vimrc call arpeggio#map('i', '', 0, 'jk', '') Ça créé un raccourcis en mode insertion, de sorte que \"jk\" pressés simultanément sortent du mode insertion, et que \"j\" et \"k\" pressés séparément aient toujours le même effet. Si vous décidez d'utiliser ma configuration, téléchargez là à l'adresse indiquée plus haut, puis placez le contenu du dossier dans ~/.vim. Ensuite, déplacez le vimrc dans ~/.vimrc et gvimrc dans ~/.gvimrc. J'ai rédigé un mini aide mémoire pour moi, faites dans vim : h arnaud ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ arnaud.txt Arnaud Vim Config 2009-06-21 Author: TANGUY Arnaud < arn . tanguy @ gmail . com > Copyright: © Copyright 2009 TANGUY Arnaud . All Rights Reserved . Licence GNU GPL v2 or later ( at your option ) ============================================================================== 1. Contents * arnaud * * arnaud - contents * {{{ 1 1. Contents ................................. : | arnaud - contents | 2. Key - mappings ............................. : | a - keys | 3. Plugins .................................. : | a - plugins | OmniCppComplete ........................ : | a - omnicppcomplete | Project ................................ : | a - project | SearchInRuntime ........................ : | a - searchinruntime | Surround ............................... : | a - surround | Alternate .............................. : | a - alternate | ManPageView ............................ : | a - manpageview | Matchit ................................ : | a - matchit | NERD_Commenter ......................... : | a - nerdcommenter | PhpDocumentor .......................... : | a - phpdocumentor | DoxygenToolkit ......................... : | a - doxygen | Markdown ............................... : | a - markdown | Indent Guides .......................... : | a - indent - guides | ============================================================================== 2. Key mappings * a - key * * a - keys * {{{ 1 , cd cd to the directory of the current view < F6 > SearchInVar and open in the current view < F7 > SearchInVar and open in a new tab < F1 > Project open the project window < F2 > Ctags rebuild . In insert and normal modes < F9 > Build the file or project . It ' s a ftplugin , so it may not be mapped in every mode < C - D > Generate doc for a function ( or class ). It is used by ftplugins , at least the php one . 3. Plugins * a - plugins * * a - plugin * {{{ 1 OMNICPPCOMPLETE * a - omnicppcomplete * {{{ 2 Omnicppcomplete is a completition plugin . It completes the code , maily the c ++ ones . It is based on ctags , so it requires a tags file , which can be created with: ctags - R -- c ++- kinds =+ p -- fields =+ iaS -- extra =+ q . Then , the autocompletition is with < C - x >< C - o > ( automatically called in my config ) See | omnicppcomplete . txt | PROJECT * a - project * * a - projects * {{{ 2 A project managment plugin . It allows to remember the project structures , and re - open it easily . - \\ c creates a new project - : w saves it - SPACE grow / reduce the project window See | project . cpp | SEARCHINRUNTIME * a - searchinruntime * * a - SIR * {{{ 2 Search a file name or a variable in the PATH . It provides an easy way to load files . See | searchInRuntime . txt | SURROUND * a - surround * {{{ 2 It is a plugin to surround text with caracters like {,(, \"... - cs ({ : replace (...) with { ... } cs (} : replace (...) with {...} ( without spaces ) cs { < q > : replace {...} with < q > ... </ q > - ds { : delete {} - ys [ text element ]{ : surround text element with {} Example : \"_Hello dear friends\" ys2w [ will give you \"[ Hello dear ] friends\" - Visual selection surrounding : press V or v , and then select text . Press S and type your surrounding character ( it can be html tags ). See | surround . txt | ALTERNATE * a - alternate * {{{ 2 Switch between . h and . cpp (. hpp / . cpp . h / . c and so on ). MANPAGEVIEW * a - manpageview * {{{ 2 View php man pages . It requires links to work . Call it with K as for unixes man pages MATCHIT * a - matchit * {{{ 2 It allows you to configure % to match more than just single characters . You can match words and even regular expressions . Also , matching treats strings and comments ( as recognized by the syntax highlighting mechanism ) intelligently . The default ftplugins include settings for several languages : Ada , ASP with VBS , Csh , DTD , Essbase , Fortran , HTML , JSP ( same as HTML ), LaTeX , Lua , Pascal , SGML , Shell , Tcsh , Vim , XML . ( I no longer keep track , so there may be others .) The documentation ( included in the zip file ) explains how to configure the script for a new language and how to modify the defaults . See | matchit . txt | NERDCOMMENTER * a - nerd * * a - nerdcommenter * {{{ 2 Nerd commenter allow to comment code according to the file type . The most useful mappings are : , cc | NERDComComment | Comments out the current line or text selected in visual mode . , cy is the same , but yank before commenting , cl OR , cr OR , cb | NERDComAlignedComment | Same as | NERDComComment | except that the delimiters are aligned down the left side (, cl ), the right side (, cr ) or both sides (, cb ). , cI | NERDComPrependComment | , cA | NERDComAppendComment | Comment before / after the current line . Adds comment delimiters to the end of line and goes into insert mode between them . , c < space > | NERDComToggleComment | Toggles the comment state of the selected line ( s ). If the topmost selected line is commented , all selected lines are uncommented and vice versa . , cu | NERDComUncommentLine | Uncomments the selected line ( s ). , cm | NERDComMinimalComment | Comments the given lines using only one set of multipart delimiters if possible . , ci | NERDComInvertComment | Toggles the comment state of the selected line ( s ) individually . Each selected line that is commented is uncommented and vice versa . , cs | NERDComSexyComment | Comments out the selected lines `` sexily '' . Useful for doc , headers ... , ca | NERDComAltDelim | /*Switches to the alternative set of delimiters.*/ See | NERDCommenter | PHPDOCUMENTOR * a - phpdocumentor * * a - phpd * {{{ 2 PhpDocumentor is a plugin for generating phpDocumentor documentation blocs . In my configuration , it is called with < C - P > , in every mode . DOXYGEN * a - doxygen * {{{ 2 It is a plugin for autocreatin doxygen commenting blocs . Move on a function declaration , and : Dox or < C - P > See http : //www.vim.org/scripts/script.php?script_id=987 for more details and configuration variables MARKDOWN * a - markdown * {{{ 2 Mappings: the following work on normal and visual modes : - ]] : go to next header - [[ : go to previous header - ][ : go to next sibling header if any - [] : go to previous sibling header if any - ] c : go to Current header - ] u : go to parent header ( Up ) INDENT GUIDES * a - indent - guides * {{{ 2 Activate with < Leader > ig (, ig ) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~","tags":"Programmation","title":"VIM : My configuration"},{"url":"http://arntanguy.no-ip.org/vim-un-essai-de-plugin-pour-la-compilation-c.html","text":"J'aime beaucoup utiliser vim pour programmer (je n'ai jamais réussi à me faire à la façon de penser d'emacs et vim me convient très bien une fois configuré), mais jusqu'ici une chose me chagrinait, la compilation en c++. Les principaux points qui me dérangeaient étaient : La liste des erreurs de compilations qui ne reste pas La difficulté pour compiler à partir d'un autre dossier. J'utilise beaucoup ceci, notemment avec l'excellent cmake qui permet de réaliser simplement une compilation dans un dossier séparé. Je ne savais pas trop comment faire d'extensions pour vim, je me suis dit que c'était l'occasion de voir. J'ai donc fait un petit plugin qui résoud partiellement ces défauts. Il permet de Compiler à partir du dossier courant, ou d'un autre dossier Laisser la fenêtre de compilation (utilisation de quickfix) ouverte, et ainsi, sauter facilement aux erreurs * Et en prime, d'ajouter automatiquement une bonne partie des includes manquants ! Cette fonctionnalité est assez bancale, et ne fonctionne quand dans les cas ou le nom de la classe est le même que le nom du fichier la contenant, ce qui correspond à mon style de programmation. L'ajout des includes se fait de façon relativement intelligente : si il y a déjà des includes, c'est ajouté à cet endroit, sinon, le plugin essaye de trouver la fin du header et place les includes après. Au pire, on peut spécifier une ligne pour l'ajout. Installation Il suffit de placer le script suivant dans le dossier ~/.vim/ftplugin/cpp, je l'ai nommé make.vim (vous pouvez mettre le nom que vous voulez, tant qu'il a l'extension .vim). \" Copyright (C) 2008 TANGUY Arnaud <arn.tanguy@gmail.com> \" * \" This program is free software; you can redistribute it and/or modify * \" it under the terms of the GNU General Public License as published by * \" the Free Software Foundation; version 3 of the License * \" * \" This program is distributed in the hope that it will be useful, * \" but WITHOUT ANY WARRANTY; without even the implied warranty of * \" MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the * \" GNU General Public License for more details. * \" * \" You should have received a copy of the GNU General Public License along * \" with this program; if not, write to the Free Software Foundation, Inc., * \" 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. * \"******************************************************************************/ \" \" This is my first vim plugin, so there might be errors or inaccuracies. If \" you see some mistakes, please let me know. \" \" *************** DESCRIPTION ********************** \" This is a make plugin for cpp files. It makes, and parse the results to add \" usefull informations, such as auto-include headers. \" \" **************** FEATURES ************************ \" Features wished but not implemented yet: \" - Auto add includes after compilation (works fine, at least for Qt). \" But : File names must be named like the class. I.e if you have a class \" named TestClass, then the file name must be TestClass.h TestClass.hpp or \" TestClass \" When other includes are already presents: add the includes with them \" Otherwise, guess where to add includes : after the header, or at a default \" position. \" - Show the quickfix window \" \" *************** CONFIGURATION ***************** \" g:default_includes_line the number of the default include line. It is \" used when not better place is found \" g:quickfix_size The number of lines of the quickfix window \" \" ************** TODO ******************* \" - Auto (or ask?) add pre-declaration (class Type;) in the header, and the include in \" the .cpp file. To switch beetween files, use a.vim plugin. \" - Seek for innacuracies, and fix them. Optimize too... let s :cpo_save = & cpo set cpo & vim \" Do not reload if already loaded if exists ( 'g:loaded_make_plugin' ) \\ && ! exists ( 'g:force_reload_make_plugin' ) finish endif let g :loaded_make_plugin = 1 \" Global variables initialisation (if not already set) if ! exists ( 'g:quickfix_size' ) let g :quickfix_size = 6 endif \" Function : SortUnique \" Purpose : Works like sort(), optionally taking in a comparator \" (just like the original), except that duplicate entries will be removed. \" Args : A list, and optionally a comparator \" Returns : The sorted list \" Author : Unknown, found on http://vim.wikia.com/wiki/Unique_sorting function ! SortUnique ( list , ... ) let dictionary = {} for i in a : list execute \"let dictionary[ '\" . i . \"' ] = ''\" endfor let result = [] if ( exists ( 'a:1' ) ) let result = sort ( keys ( dictionary ), a : 1 ) else let result = sort ( keys ( dictionary ) ) endif return result endfunction \" Function : RemoveMatching \" Purpose : Delete items in a list, when they are matching items in an \" another list \" Args : listRef: The list from which you want to remove items \" listMatch: The list to compare with \" Returns : The listRef, without matched items \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> \" Note : This can surely be improved, but I still don't know much viml function ! RemoveMatching ( listRef , listMatch ) let i = 0 let ref_list = copy ( a :listRef ) while i < len ( ref_list ) for j in a :listMatch if ref_list[ i ] == j call remove ( ref_list , i ) endif endfor let i += 1 endwhile return ref_list endfunction \" Function : GetMissingIncludes (PRIVATE) \" Purpose : Find the missing includes in the compilation error list \" Args : None \" Returns : Nothing \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> \" TODO : Check if the include is in the path, otherwise, ask the user to \" know what to do. \" Is there all possible related errors messages here ? Let me know \" if it is not the case function ! s :GetMissingIncludes () \" Get the quickfix errors let errors = getqflist () let includes = [] \" To avoid some errors with variables names let not_includes = [] let l : count = 0 for i in errors if ( i [ \"text\" ] =~ \".* was not declared in this scope\" ) \" Find the possible name in the error \"let include = substitute(i[\"text\"], '.*error:..\\(.*\\)..was not declared in this scope', '\\1', 'g') let includes += [substitute ( i [ \"text\" ] , '.*error:..\\(.*\\)..was not declared in this scope' , '\\1' , 'g' ) ] \" Check if it is really a type, and not a variable name \"let nextError = errors[l:count + 1][\"text\"] \"if(nextError =~ \".* expected .;. before .*\") \"let not_includes += [substitute(nextError, '.* expected .;. before .\\(.*\\).', '\\1', 'g')] \"let includes += [include] \"endif elseif ( i [ \"text\" ] =~ \".*variable .* has initializer but incomplete type\" ) let includes += [substitute ( i [ \"text\" ] , '.*variable .\\(.*\\) .* has initializer but incomplete type' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* aggregate .* has incomplete type and cannot be defined\" ) let includes += [substitute ( i [ \"text\" ] , '.* aggregate .\\(.*\\) .* has incomplete type and cannot be defined' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* has not been declared\" ) let includes += [substitute ( i [ \"text\" ] , '.* .\\(.*\\). has not been declared' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* incomplete type .* used in nested name specifier\" ) let includes += [substitute ( i [ \"text\" ] , '.* incomplete type .\\(.*\\). used in nested name specifier' , '\\1' , 'g' ) ] elseif ( i [ \"text\" ] =~ \".* invalid use of incomplete type .*\" ) let includes += [substitute ( i [ \"text\" ] , '.* invalid use of incomplete type .struct \\(.*\\).' , '\\1' , 'g' ) ] endif let l : count += 1 endfor \" Return the found includes name, and sort them, remove doubles let tmpReturn = RemoveMatching ( includes , not_includes ) let tmpReturn = SortUnique ( tmpReturn ) return s :CheckInPath ( tmpReturn ) endfunction \" Function : CheckInPath \" Purpose : Check if an include exists in path \" Args : The includes names list \" Returns : A dictionnary of the found entry : \" \"global\" => List : The global entry (those included with \" #include <...>) \" \"local\" => List : The local entry (those included with \" #include \"...\" \" \"unmatched\" => List : The includes not found \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function ! s :CheckInPath ( includesList ) let includes = copy ( a :includesList ) let results = { \"global\" : [] , \\ \"local\" : [] , \\ \"unmatched\" : [] } for inc in includes let mpath = \"**,/usr/include/**\" let found = findfile ( inc , mpath ) if found != \"\" let results[ \"global\" ] += [ inc ] else \" XXX : strange, why regex don't works with findfile ? let found = findfile ( inc . \".h\" , mpath ) if ( found != \"\" ) let results[ \"local\" ] += [found] else let found = findfile ( inc . \".hpp\" , mpath ) if found != \"\" let results[ \"local\" ] += [found] else let results[ \"unmatched\" ] += [ inc ] endif endif endif endfor for i in results[ \"global\" ] echomsg \"global : \" . i endfor for j in results[ \"local\" ] echomsg \"local : \" . j endfor for h in results[ \"unmatched\" ] echomsg \"unmatched : \" . h endfor return results endfunction \" Function : SeekPosition \" Purpose : Find the best position where the includes will be placed \" Args : None \" Returns : The found line \" Author : TANGUY Arnaud function ! s :SeekPosition () exe \"normal gg\" \" Seek the existing includes, to add it here if they exists let line = search ( \"&#94;#include\" ) if line > 0 return line endif \" Otherwise, find a default location. Usually, C files are written with a \" header, and space is left between header and code. So, we'll seek the \" first line without anything but white character on it let line = search ( '&#94;\\( ?\\)*$' ) if line > 0 return line endif \" If not found, set a default value if exists ( \"g:default_includes_line\" ) return g :default_includes_line else return 1 endif endfunction \" Function : AddIncludes (PRIVATE) \" Purpose : Add the includes given in args in the file \" Args : includesDict: A list containing the includes name and type \" \"global\" => global includes \" \"local\" => local includes \" \"unmatched\" => not found, so ask \" Returns : Nothing \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function s :AddIncludes ( includesDict ) if ( len ( a :includesDict ) > 0 ) let l = s :SeekPosition () for include in a :includesDict[ \"local\" ] exe \"normal \" . l . 'GO#include \"' . include . '\"' endfor for inc in a :includesDict[ \"global\" ] exe \"normal \" . l . 'GO#include <' . inc . '>' endfor for i in a :includesDict[ \"unmatched\" ] echomsg \"unmatched \" . i endfor \" Once the includes are added, rebuild silent ! execute & makeprg endif endfunction \" Function : MyMake \" Purpose : Build a cpp project, using make, and doing some more cool stuff. \" This function call everything needed for this plugin : autoadd \" includes... \" Args : None \" Returns : 1 if path1 is equal to path2, 0 otherwise. \" Author : TANGUY Arnaud <arn.tanguy@gmail.com> function ! s :MakeIncludes ( dir ) \"exe &makeprg call s :Make ( a : dir ) let includes = s :GetMissingIncludes () call s :AddIncludes ( includes ) endf \" Function : s:Make \" Purpose : \" Args : \" Returns : \" Author : TANGUY Arnaud function s :Make ( dir ) \" Save the old directory, and go to the new one let olddir = getcwd () if ( a : dir != \"\" ) execute \":lcd \" . a : dir endif silent ! exe & makeprg execute \":lcd \" .olddir let winnum = winnr () \" get current window number \" g:quickfix_size lines big for the quickfix window exe \"cope \" . g :quickfix_size \" Open the quickfix window cw \" Go to the first error execute winnum . \"wincmd w\" endfunction com ! - nargs = 0 Mi call s :MakeIncludes ( \".\" ) com ! - nargs = 0 Mid call s :MakeIncludes (< args >) com ! - nargs = 0 Mm call s :Make ( \".\" ) \" Make in an other directory com ! - nargs = 1 Mmd call s :Make (< args >) let & cpo = s :cpo_save Utilisation Le script s'utilise en mode commande: :Mm compile dans le dossier courant :Mmd \"build/\" compile dans le sous dossier. Vous devez mettre le chemin du dossier de compilation dans les guillemets. Le chemin peut être relatif ou absolu. :Mi compile et ajoute les includes :Mid \"build/\" compile dans un autre dossier, et ajoute les includes Il s'agit de mon premier plugin vim, par conséquent il est probablement codé maladroitement par moments. La fonctionnalité permettant d'ajouter automatiquement des includes est loin d'être parfaite, il se peut que vous ayez besoin d'en ajouter manuellement. Parfois, trop d'includes sont ajoutés (par exemple quand un include en inclut un autre, les 2 sont quand même ajouté alors que ce n'est pas nécessaire). Ce système fonctionne bien avec le framwork Qt avec lequel je travaille beaucoup. J'essayerai d'améliorer ça à l'occasion, pour l'instant ça me suffit pour compiler. Une chose que j'aimerai faire, c'est pouvoir faire une compilation non bloquante : pouvoir continuer à utiliser vim durant le temps de compilation, mais ça me semble assez compliqué…","tags":"Programmation","title":"VIM : Un Essai de plugin pour la compilation C++"},{"url":"http://arntanguy.no-ip.org/fotowall-100-000.html","text":"Aujourd'hui, Fotowall a atteind les 100 000 télécharments ! C'est un résultat impressionnant, et c'est encore plus incroyable en considérant que nous n'avons pas de page d'accueil, pas de publicité autre que le bouche à oreille. Et ces téléchargements ne concernent que la version XP/Vista. Il est très difficile d'évaluer le nombre d'utilisateurs parmis les autres sytèmes, en particulier GNU/Linux avec les divers gestionnaires de paquets, clones git, installations à partir des sources… Rien que sur kde-apps , on dénombre plus 5183 téléchargements, il semble donc que Fotowall rencontre un certain succès auprès des utilisateurs de logiciel libres. Pour célébrer ce résultat, voici une petite vidéo de la prochaine version (qui sortira d'ici une semaine) : Un grand merci à toute l'équipe : Enrico Ros, Arnaud Tanguy , Alessandro Portale, Andreas Brech, Georges Dubus, ainsi qu'aux traducteurs Martin Zimmermann and Marcio Moraes.","tags":"FotoWall","title":"FOTOWALL : 100 000 !"},{"url":"http://arntanguy.no-ip.org/fotowall-07.html","text":"FotoWall est un logiciel libre disponible sous licence GPL développé par Enrico Ros et moi-même. Il vous permet de présenter simplement vos photos, en les disposant aisément, appliquant des transformations (rotations, perspectives, effets). Nous venons de réaliser une nouvelle version, d'où cet article pour vous faire découvrir FotoWall pour ceux qui ne connaissent pas, et informer les autres. Voici la liste des principales fonctionnalités (non exhaustive) : disposer facilement vos images redimensionner, faire pivoter des images appliquer des effets aux images : niveau de gris, noir et blanc, inverser les couleurs, contrastes… chaque image peut être enregistrée séparément, ce qui permet d'utiliser ce logiciel pour d'autres usages que celui initial. mettre la photo dans un \"cadre\" (cœur, carré coloré…). imprimer un poster (grâce au logiciel libre posterazor). imprimer vos créations au format voulu (taille réelle, cd, dvd…) faire une recherche sur flickr Pour installer fotowall sous Ubuntu, suivez les instructions de la documentation Ubuntu-fr . La méthode est similaire pour les autres systèmes. Les utilisateurs de Windows trouverons un éxécutable sur google code","tags":"FotoWall","title":"FotoWall 0.7"}]}